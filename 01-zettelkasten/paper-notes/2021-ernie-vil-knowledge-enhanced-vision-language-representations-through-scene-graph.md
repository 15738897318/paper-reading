---
title: ERNIE-ViL - Knowledge Enhanced Vision-Language Representations Through Scene Graph
authors:
- Fei Yu
- Jiji Tang
- Weichong Yin
- Yu Sun
- Hao Tian
- Hua Wu
- Haifeng Wang
fieldsOfStudy:
- Computer Science
meta_key: 2021-ernie-vil-knowledge-enhanced-vision-language-representations-through-scene-graph
numCitedBy: 137
reading_status: TBD
ref_count: 45
tags:
- gen-from-ref
- other-default
- paper
venue: AAAI
year: 2021
---

# ERNIE-ViL - Knowledge Enhanced Vision-Language Representations Through Scene Graph

## Abstract

We propose a knowledge-enhanced approach, ERNIE-ViL, to learn joint representations of vision and language. ERNIE-ViL tries to construct the detailed semantic connections (objects, attributes of objects and relationships between objects in visual scenes) across vision and language, which are essential to vision-language cross-modal tasks. Incorporating knowledge from scene graphs, ERNIE-ViL constructs Scene Graph Prediction tasks, i.e., Object Prediction, Attribute Prediction and Relationship Prediction in the pre-training phase. More specifically, these prediction tasks are implemented by predicting nodes of different types in the scene graph parsed from the sentence. Thus, ERNIE-ViL can model the joint representation characterizing the alignments of the detailed semantics across vision and language. Pre-trained on two large image-text alignment datasets (Conceptual Captions and SBU), ERNIE-ViL learns better and more robust joint representations. It achieves state-of-the-art performance on 5 vision-language downstream tasks after fine-tuning ERNIE-ViL. Furthermore, it ranked the 1st place on the VCR leader-board with an absolute improvement of 3.7%.

## Paper References

1. An Empirical Study on Leveraging Scene Graphs for Visual Question Answering
2. [ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](2019-vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks)
3. [Attention is All you Need](2017-attention-is-all-you-need)
4. [SPICE - Semantic Propositional Image Caption Evaluation](2016-spice-semantic-propositional-image-caption-evaluation)
5. [Conceptual Captions - A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning](2018-conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning)
6. [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](2016-visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations)
7. Im2Text - Describing Images Using 1 Million Captioned Photographs
8. [Large-Scale Adversarial Training for Vision-and-Language Representation Learning](2020-large-scale-adversarial-training-for-vision-and-language-representation-learning)
9. [Oscar - Object-Semantics Aligned Pre-training for Vision-Language Tasks](2020-oscar-object-semantics-aligned-pre-training-for-vision-language-tasks)
10. Pixel-BERT - Aligning Image Pixels with Text by Deep Multi-Modal Transformers
11. Circle Loss - A Unified Perspective of Pair Similarity Optimization
12. ImageBERT - Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data
13. [12-in-1 - Multi-Task Vision and Language Representation Learning](2020-12-in-1-multi-task-vision-and-language-representation-learning)
14. [UNITER - Learning UNiversal Image-TExt Representations](2019-uniter-learning-universal-image-text-representations)
15. [Unified Vision-Language Pre-Training for Image Captioning and VQA](2020-unified-vision-language-pre-training-for-image-captioning-and-vqa)
16. [VL-BERT - Pre-training of Generic Visual-Linguistic Representations](2020-vl-bert-pre-training-of-generic-visual-linguistic-representations)
17. [LXMERT - Learning Cross-Modality Encoder Representations from Transformers](2019-lxmert-learning-cross-modality-encoder-representations-from-transformers)
18. [Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal Pre-training](2020-unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training)
19. [VisualBERT - A Simple and Performant Baseline for Vision and Language](2019-visualbert-a-simple-and-performant-baseline-for-vision-and-language)
20. ERNIE 2.0 - A Continual Pre-training Framework for Language Understanding
21. Unified Visual-Semantic Embeddings - Bridging Vision and Language With Structured Meaning Representations
22. ERNIE - Enhanced Representation through Knowledge Integration
23. [VideoBERT - A Joint Model for Video and Language Representation Learning](2019-videobert-a-joint-model-for-video-and-language-representation-learning)
24. Auto-Encoding Scene Graphs for Image Captioning
25. [From Recognition to Cognition - Visual Commonsense Reasoning](2019-from-recognition-to-cognition-visual-commonsense-reasoning)
26. [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](2019-bert.md)
27. [Improving Language Understanding by Generative Pre-Training](2018-improving-language-understanding-by-generative-pre-training)
28. Image Generation from Scene Graphs
29. [Stacked Cross Attention for Image-Text Matching](2018-stacked-cross-attention-for-image-text-matching)
30. Scene Graph Parsing as Dependency Parsing
31. [MAttNet - Modular Attention Network for Referring Expression Comprehension](2018-mattnet-modular-attention-network-for-referring-expression-comprehension)
32. Neural Motifs - Scene Graph Parsing with Global Context
33. [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](2018-bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering)
34. Scene Graph Generation by Iterative Message Passing
35. [Deep Residual Learning for Image Recognition](2015-resnet.md)
36. Generating Semantically Precise Scene Graphs from Textual Descriptions for Improved Image Retrieval
37. Image retrieval using scene graphs
38. [From image descriptions to visual denotations - New similarity metrics for semantic inference over event descriptions](2014-from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions)
39. [VQA - Visual Question Answering](2015-vqa-visual-question-answering)
40. [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](2015-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks)
41. ReferItGame - Referring to Objects in Photographs of Natural Scenes
42. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context)
