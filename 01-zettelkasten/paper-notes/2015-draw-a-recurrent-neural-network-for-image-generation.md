---
title: DRAW - A Recurrent Neural Network For Image Generation
authors:
- Karol Gregor
- Ivo Danihelka
- A. Graves
- Danilo Jimenez Rezende
- Daan Wierstra
fieldsOfStudy:
- Computer Science
meta_key: 2015-draw-a-recurrent-neural-network-for-image-generation
numCitedBy: 1632
reading_status: TBD
ref_count: 42
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/DRAW:-A-Recurrent-Neural-Network-For-Image-Gregor-Danihelka/a2785f66c20fbdf30ec26c0931584c6d6a0f4fca?sort=total-citations
venue: ICML
year: 2015
---

# DRAW - A Recurrent Neural Network For Image Generation

## Abstract

This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.

## Paper References

1. [Recurrent Models of Visual Attention](2014-recurrent-models-of-visual-attention)
2. Learning Generative Models with Visual Attention
3. Multiple Object Recognition with Visual Attention
4. Optimizing Neural Networks that Generate Iimages
5. Deep AutoRegressive Networks
6. A Neural Autoregressive Approach to Attention-based Recognition
7. [Learning Multiple Layers of Features from Tiny Images](2009-learning-multiple-layers-of-features-from-tiny-images)
8. Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks
9. Attention for Fine-Grained Categorization
10. [Generating Sequences With Recurrent Neural Networks](2013-generating-sequences-with-recurrent-neural-networks)
11. Learning Where to Attend with Deep Architectures for Image Tracking
12. Learning to combine foveal glimpses with a third-order Boltzmann machine
13. [Sequence to Sequence Learning with Neural Networks](2014-sequence-to-sequence-learning-with-neural-networks)
14. Stochastic Backpropagation and Approximate Inference in Deep Generative Models
15. Neural Variational Inference and Learning in Belief Networks
16. Learning to Forget - Continual Prediction with LSTM
17. Deep Boltzmann Machines
18. [Reading Digits in Natural Images with Unsupervised Feature Learning](2011-reading-digits-in-natural-images-with-unsupervised-feature-learning)
19. [Reducing the Dimensionality of Data with Neural Networks](2006-reducing-the-dimensionality-of-data-with-neural-networks)
20. The Helmholtz Machine
21. A Deep and Tractable Density Estimator
22. Iterative Neural Autoregressive Distribution Estimator NADE-k
23. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization)
24. [Neural Turing Machines](2014-neural-turing-machines)
25. On the quantitative analysis of deep belief networks
26. [Long Short-Term Memory](1997-long-short-term-memory)
27. [Gradient-based learning applied to document recognition](1998-lenet5.md)
28. The Neural Autoregressive Distribution Estimator
29. Markov Chain Monte Carlo and Variational Inference - Bridging the Gap
30. Learning where to look
31. Evaluating probabilities under high-dimensional latent variable models
32. [Auto-Encoding Variational Bayes](2014-auto-encoding-variational-bayes)
