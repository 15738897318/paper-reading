---
title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering
authors:
- Peter Anderson
- Xiaodong He
- Chris Buehler
- Damien Teney
- Mark Johnson
- Stephen Gould
- Lei Zhang
fieldsOfStudy:
- Computer Science
meta_key: 2018-bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering
numCitedBy: 2310
reading_status: TBD
ref_count: 67
tags:
- gen-from-ref
- other-default
- paper
venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition
year: 2018
---

# Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering

## Abstract

Top-down visual attention mechanisms have been used extensively in image captioning and visual question answering (VQA) to enable deeper image understanding through fine-grained analysis and even multiple steps of reasoning. In this work, we propose a combined bottom-up and top-down attention mechanism that enables attention to be calculated at the level of objects and other salient image regions. This is the natural basis for attention to be considered. Within our approach, the bottom-up mechanism (based on Faster R-CNN) proposes image regions, each with an associated feature vector, while the top-down mechanism determines feature weightings. Applying this approach to image captioning, our results on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / SPICE / BLEU-4 scores of 117.9, 21.5 and 36.9, respectively. Demonstrating the broad applicability of the method, applying the same approach to VQA we obtain first place in the 2017 VQA Challenge.

## Paper References

1. [Hierarchical Question-Image Co-Attention for Visual Question Answering](2016-hierarchical-question-image-co-attention-for-visual-question-answering)
2. [Knowing When to Look - Adaptive Attention via a Visual Sentinel for Image Captioning](2017-knowing-when-to-look-adaptive-attention-via-a-visual-sentinel-for-image-captioning)
3. Areas of Attention for Image Captioning
4. [Visual7W - Grounded Question Answering in Images](2016-visual7w-grounded-question-answering-in-images)
5. [What Value Do Explicit High Level Concepts Have in Vision to Language Problems?](2016-what-value-do-explicit-high-level-concepts-have-in-vision-to-language-problems)
6. Aligning where to see and what to tell - image caption with region-based attention and scene factorization
7. [Ask, Attend and Answer - Exploring Question-Guided Spatial Attention for Visual Question Answering](2016-ask-attend-and-answer-exploring-question-guided-spatial-attention-for-visual-question-answering)
8. [Image Captioning with Semantic Attention](2016-image-captioning-with-semantic-attention)
9. Show, Ask, Attend, and Answer - A Strong Baseline For Visual Question Answering
10. Zero-Shot Visual Question Answering
11. [Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering](2017-making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering)
12. [Stacked Attention Networks for Image Question Answering](2016-stacked-attention-networks-for-image-question-answering)
13. [Boosting Image Captioning with Attributes](2017-boosting-image-captioning-with-attributes)
14. End-to-End Concept Word Detection for Video Captioning, Retrieval, and Question Answering
15. [Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding](2016-multimodal-compact-bilinear-pooling-for-visual-question-answering-and-visual-grounding)
16. [From captions to visual concepts and back](2015-from-captions-to-visual-concepts-and-back)
17. [DenseCap - Fully Convolutional Localization Networks for Dense Captioning](2016-densecap-fully-convolutional-localization-networks-for-dense-captioning)
18. [Show and tell - A neural image caption generator](2015-show-and-tell-a-neural-image-caption-generator)
19. [VQA - Visual Question Answering](2015-vqa-visual-question-answering)
20. [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](2015-show-attend-and-tell-neural-image-caption-generation-with-visual-attention)
21. [Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)](2015-deep-captioning-with-multimodal-recurrent-neural-networks-m-rnn)
22. Tips and Tricks for Visual Question Answering - Learnings from the 2017 Challenge
23. [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](2016-visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations)
24. [CIDEr - Consensus-based image description evaluation](2015-cider-consensus-based-image-description-evaluation)
25. [SPICE - Semantic Propositional Image Caption Evaluation](2016-spice-semantic-propositional-image-caption-evaluation)
26. [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](2015-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks)
27. [Deep Visual-Semantic Alignments for Generating Image Descriptions](2017-deep-visual-semantic-alignments-for-generating-image-descriptions)
28. Optimization of image description metrics using policy gradient methods
29. [Deep Residual Learning for Image Recognition](2015-resnet.md)
30. [SSD - Single Shot MultiBox Detector](2016-ssd-net.md)
31. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context)
32. [Long-term recurrent convolutional networks for visual recognition and description](2015-long-term-recurrent-convolutional-networks-for-visual-recognition-and-description)
33. [Order-Embeddings of Images and Language](2016-order-embeddings-of-images-and-language)
34. [Review Networks for Caption Generation](2016-review-networks-for-caption-generation)
35. Improved Image Captioning via Policy Gradient optimization of SPIDEr
36. [Self-Critical Sequence Training for Image Captioning](2017-self-critical-sequence-training-for-image-captioning)
37. [ImageNet Large Scale Visual Recognition Challenge](2015-imagenet-large-scale-visual-recognition-challenge)
38. [Language Modeling with Gated Convolutional Networks](2017-language-modeling-with-gated-convolutional-networks)
39. [Selective Search for Object Recognition](2013-selective-search-for-object-recognition)
40. Objects and attention - the state of the art
41. Perceptual grouping and attention in visual search for features and for objects.
42. Maximum Expected BLEU Training of Phrase and Lexicon Translation Models
43. [Edge Boxes - Locating Object Proposals from Edges](2014-edge-boxes-locating-object-proposals-from-edges)
44. [GloVe - Global Vectors for Word Representation](2014-glove-global-vectors-for-word-representation)
45. [Identity Mappings in Deep Residual Networks](2016-identity-mappings-in-deep-residual-networks)
46. Top-Down Versus Bottom-Up Control of Attention in the Prefrontal and Posterior Parietal Cortices
47. [ROUGE - A Package for Automatic Evaluation of Summaries](2004-rouge-a-package-for-automatic-evaluation-of-summaries)
48. [Microsoft COCO Captions - Data Collection and Evaluation Server](2015-microsoft-coco-captions-data-collection-and-evaluation-server)
49. A feature-integration theory of attention
50. [Spatial Transformer Networks](2015-spatial-transformer-networks)
51. [Long Short-Term Memory](1997-long-short-term-memory)
52. Highway Networks
53. Control of goal-directed and stimulus-driven attention in the brain
54. Shifting visual attention between objects and locations - evidence from normal and parietal lesion subjects.
55. [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](2014-learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation)
56. [Bleu - a Method for Automatic Evaluation of Machine Translation](2002-bleu-a-method-for-automatic-evaluation-of-machine-translation)
57. [Meteor Universal - Language Specific Translation Evaluation for Any Target Language](2014-meteor-universal-language-specific-translation-evaluation-for-any-target-language)
58. [Simple statistical gradient-following algorithms for connectionist reinforcement learning](2004-simple-statistical-gradient-following-algorithms-for-connectionist-reinforcement-learning)
59. [ADADELTA - An Adaptive Learning Rate Method](2012-adadelta-an-adaptive-learning-rate-method)
60. and a at
61. [Revisiting Visual Question Answering Baselines](2016-revisiting-visual-question-answering-baselines)
62. [You Only Look Once - Unified, Real-Time Object Detection](2016-you-only-look-once-unified-real-time-object-detection)
