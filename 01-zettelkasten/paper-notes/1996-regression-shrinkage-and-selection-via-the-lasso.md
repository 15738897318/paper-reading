---
title: Regression Shrinkage and Selection via the Lasso
authors:
- R. Tibshirani
fieldsOfStudy:
- Computer Science
meta_key: 1996-regression-shrinkage-and-selection-via-the-lasso
numCitedBy: 36597
reading_status: TBD
ref_count: 27
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Regression-Shrinkage-and-Selection-via-the-Lasso-Tibshirani/b365b8e45b7d81f081de44ac8f9eadf9144f3ca5?sort=total-citations
venue: ''
year: 1996
---

[semanticscholar url](https://www.semanticscholar.org/paper/Regression-Shrinkage-and-Selection-via-the-Lasso-Tibshirani/b365b8e45b7d81f081de44ac8f9eadf9144f3ca5?sort=total-citations)

# Regression Shrinkage and Selection via the Lasso

## Abstract

SUMMARY We propose a new method for estimation in linear models. The 'lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.

## Paper References

1. A proposal for variable selection in the Cox model
2. Variable selection via Gibbs sampling
3. Linear Model Selection by Cross-validation
4. Model Selection Via Multifold Cross Validation
5. Bootstrap Methods - Another Look at the Jackknife
6. Solving least squares problems
7. Ideal spatial adaptation by wavelet shrinkage
8. Wavelet Shrinkage - Asymptopia?
9. A Statistical View of Some Chemometrics Regression Tools
10. Reversible jump Markov chain Monte Carlo computation and Bayesian model determination
11. Maximum Entropy and the Nearly Black Object
12. Classification and Regression Trees
13. Basis pursuit
14. Prostate specific antigen in the diagnosis and treatment of adenocarcinoma of the prostate. II. Radical prostatectomy treated patients.
15. Practical optimization
16. A Statistical View of Some Chemometrics Regression Tools] - Discussion
17. Multivariate Adaptive Regression Splines
18. Submodel selection and evaluation in regression. The X-random case
19. Estimation of the Mean of a Multivariate Normal Distribution
