---
title: A unified architecture for natural language processing - deep neural networks with multitask learning
authors:
- Ronan Collobert
- J. Weston
fieldsOfStudy:
- Computer Science
meta_key: 2008-a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning
numCitedBy: 5042
reading_status: TBD
ref_count: 27
tags:
- gen-from-ref
- other-default
- paper
venue: ICML '08
year: 2008
---

# A unified architecture for natural language processing - deep neural networks with multitask learning

## Abstract

We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.

## Paper References

1. Fast Semantic Extraction Using a Novel Neural Network Architecture
2. A Neural Probabilistic Language Model
3. Composition of Conditional Random Fields for Transfer Learning
4. Connectionist language modeling for large vocabulary continuous speech recognition
5. A discriminative language model with pseudo-negative samples
6. A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data
7. Transductive learning for statistical machine translation
8. Multitask Learning
9. Joint Parsing and Semantic Role Labeling
10. Dynamic conditional random fields - factorized probabilistic models for labeling and segmenting sequence data
11. The Proposition Bank - An Annotated Corpus of Semantic Roles
12. Phoneme recognition using time-delay neural networks
13. Shallow Semantic Parsing using Support Vector Machines
14. Using Corpus Statistics on Entities to Improve Semi-supervised Relation Extraction from the Web
15. [Gradient-based learning applied to document recognition](1998-gradient-based-learning-applied-to-document-recognition)
16. The Necessity of Parsing for Predicate Argument Recognition
17. Robust methods in analysis of natural language data
18. Robust Parsing of the Proposition Bank
19. Transductive Inference for Text Classification using Support Vector Machines
20. Effective Self-Training for Parsing
21. Dynamic Conditional Random Fields - Factorized Probabilistic Models for Labeling and Segmenting Sequence Data
22. A Novel Use of Statistical Parsing to Extract Information from Text
23. Probabilistic Interpretation of Feedforward Classification Network Outputs, with Relationships to Statistical Pattern Recognition
24. Semi-Supervised Learning (Adaptive Computation and Machine Learning)
