---
title: Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis
authors:
- Quoc V. Le
- Will Y. Zou
- S. Yeung
- A. Ng
fieldsOfStudy:
- Computer Science
meta_key: 2011-learning-hierarchical-invariant-spatio-temporal-features-for-action-recognition-with-independent-subspace-analysis
numCitedBy: 1067
reading_status: TBD
ref_count: 49
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Learning-hierarchical-invariant-spatio-temporal-for-Le-Zou/42269d0438c0ae4ca892334946ed779999691074?sort=total-citations
venue: CVPR 2011
year: 2011
---

[semanticscholar url](https://www.semanticscholar.org/paper/Learning-hierarchical-invariant-spatio-temporal-for-Le-Zou/42269d0438c0ae4ca892334946ed779999691074?sort=total-citations)

# Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis

## Abstract

Previous work on action recognition has focused on adapting hand-designed local features, such as SIFT or HOG, from static images to the video domain. In this paper, we propose using unsupervised feature learning as a way to learn features directly from video data. More specifically, we present an extension of the Independent Subspace Analysis algorithm to learn invariant spatio-temporal features from unlabeled video data. We discovered that, despite its simplicity, this method performs surprisingly well when combined with deep learning techniques such as stacking and convolution to learn hierarchical representations. By replacing hand-designed features with our learned features, we achieve classification results superior to all previous published results on the Hollywood2, UCF, KTH and YouTube action recognition datasets. On the challenging Hollywood2 and YouTube action datasets we obtain 53.3% and 75.8% respectively, which are approximately 5% better than the current best published results. Further benefits of this method, such as the ease of training and the efficiency of training and prediction, will also be discussed. You can download our code and learned spatio-temporal features here: http://ai.stanford.edu/∼wzou/

## Paper References

1. Evaluation of Local Spatio-temporal Features for Action Recognition
2. Recognizing realistic actions from videos “in the wild”
3. [Learning realistic human actions from movies](2008-learning-realistic-human-actions-from-movies)
4. [3D Convolutional Neural Networks for Human Action Recognition](2013-3d-convolutional-neural-networks-for-human-action-recognition)
5. Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words
6. Convolutional Learning of Spatio-temporal Features
7. Measuring Invariances in Deep Networks
8. Recognizing human actions - a local SVM approach
9. Actions in context
10. An Efficient Dense and Scale-Invariant Spatio-Temporal Interest Point Detector
11. Detection of human actions from a single example
12. Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition
13. Behavior recognition via sparse spatio-temporal features
14. A Spatio-Temporal Descriptor Based on 3D-Gradients
15. [Learning Multiple Layers of Features from Tiny Images](2009-learning-multiple-layers-of-features-from-tiny-images)
16. A Biologically Inspired System for Action Recognition
17. Robust classification of objects, faces, and flowers using natural image statistics
18. Learning methods for generic object recognition with invariance to pose and lighting
19. Recognizing human actions
20. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations
21. Spatiotemporal salient points for visual recognition of human actions
22. Space-time interest points
23. Tiled convolutional neural networks
24. [Histograms of oriented gradients for human detection](2005-histograms-of-oriented-gradients-for-human-detection)
25. [A performance evaluation of local descriptors](2005-a-performance-evaluation-of-local-descriptors)
26. [Object recognition from local scale-invariant features](1999-object-recognition-from-local-scale-invariant-features)
27. Speeded-Up Robust Features (SURF)
28. [A Fast Learning Algorithm for Deep Belief Nets](2006-a-fast-learning-algorithm-for-deep-belief-nets)
29. Emergence of simple-cell receptive field properties by learning a sparse code for natural images
30. Emergence of Phase- and Shift-Invariant Features by Decomposition of Natural Images into Independent Feature Subspaces
31. Large-scale deep unsupervised learning using graphics processors
32. Independent component analysis of natural image sequences yields spatio-temporal filters similar to simple cells in primary visual cortex
33. [A Comparison of Affine Region Detectors](2005-a-comparison-of-affine-region-detectors)
34. Slow feature analysis yields a rich repertoire of complex cell properties.
35. Greedy Layer-Wise Training of Deep Networks
36. Efficient sparse coding algorithms
37. Topographic independent component analysis as a model of V1 organization and receptive fields
38. Sparse Coding Of Time-Varying Natural Images
39. [SURF - Speeded-Up Robust Features](2009-surf-speeded-up-robust-features)
40. Independent component filters of natural images compared with simple cells in primary visual cortex
41. [Distinctive Image Features from Scale-Invariant Keypoints](2004-distinctive-image-features-from-scale-invariant-keypoints)
42. In the Wild
43. Self-taught learning - transfer learning from unlabeled data
44. SENSC - a Stable and Efficient Algorithm for Nonnegative Sparse Coding - SENSC - a Stable and Efficient Algorithm for Nonnegative Sparse Coding
45. Convolutional networks for images, speech, and time series
