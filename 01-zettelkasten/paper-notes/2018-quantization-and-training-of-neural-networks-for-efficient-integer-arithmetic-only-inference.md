---
title: Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference
authors:
- Benoit Jacob
- S. Kligys
- Bo Chen
- Menglong Zhu
- Matthew Tang
- Andrew G. Howard
- Hartwig Adam
- Dmitry Kalenichenko
fieldsOfStudy:
- Computer Science
meta_key: 2018-quantization-and-training-of-neural-networks-for-efficient-integer-arithmetic-only-inference
numCitedBy: 1284
reading_status: TBD
ref_count: 37
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Quantization-and-Training-of-Neural-Networks-for-Jacob-Kligys/59d0d7ccec2db66cad20cac5721ce54a8a058294?sort=total-citations
venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition
year: 2018
---

[semanticscholar url](https://www.semanticscholar.org/paper/Quantization-and-Training-of-Neural-Networks-for-Jacob-Kligys/59d0d7ccec2db66cad20cac5721ce54a8a058294?sort=total-citations)

# Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference

## Abstract

The rising popularity of intelligent mobile devices and the daunting computational cost of deep learning-based models call for efficient and accurate on-device inference schemes. We propose a quantization scheme that allows inference to be carried out using integer-only arithmetic, which can be implemented more efficiently than floating point inference on commonly available integer-only hardware. We also co-design a training procedure to preserve end-to-end model accuracy post quantization. As a result, the proposed quantization scheme improves the tradeoff between accuracy and on-device latency. The improvements are significant even on MobileNets, a model family known for run-time efficiency, and are demonstrated in ImageNet classification and COCO detection on popular CPUs.

## Paper References

1. [Deep Learning with Limited Numerical Precision](2015-deep-learning-with-limited-numerical-precision.md)
2. Extremely Low Bit Neural Network - Squeeze the Last Bit Out with ADMM
3. [Trained Ternary Quantization](2017-trained-ternary-quantization.md)
4. Improving the speed of neural networks on CPUs
5. Quantized Neural Networks - Training Neural Networks with Low Precision Weights and Activations
6. [ShuffleNet - An Extremely Efficient Convolutional Neural Network for Mobile Devices](2018-shufflenet-an-extremely-efficient-convolutional-neural-network-for-mobile-devices.md)
7. Compressing Neural Networks with the Hashing Trick
8. [Deep Compression - Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding](2016-deep-compression-compressing-deep-neural-network-with-pruning-trained-quantization-and-huffman-coding.md)
9. Compressing Deep Convolutional Networks using Vector Quantization
10. [XNOR-Net - ImageNet Classification Using Binary Convolutional Neural Networks](2016-xnor-net-imagenet-classification-using-binary-convolutional-neural-networks.md)
11. Incremental Network Quantization - Towards Lossless CNNs with Low-Precision Weights
12. [DoReFa-Net - Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients](2016-dorefa-net-training-low-bitwidth-convolutional-neural-networks-with-low-bitwidth-gradients.md)
13. [MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications](2017-mobilenets-efficient-convolutional-neural-networks-for-mobile-vision-applications.md)
14. Binarized Neural Networks
15. [SqueezeNet - AlexNet-level accuracy with 50x fewer parameters and <1MB model size](2016-squeezenet-alexnet-level-accuracy-with-50x-fewer-parameters-and-1mb-model-size.md)
16. [Rethinking the Inception Architecture for Computer Vision](2016-rethinking-the-inception-architecture-for-computer-vision.md)
17. Ternary Neural Networks with Fine-Grained Quantization
18. [Speed/Accuracy Trade-Offs for Modern Convolutional Object Detectors](2017-speed-accuracy-trade-offs-for-modern-convolutional-object-detectors.md)
19. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2015-very-deep-convolutional-networks-for-large-scale-image-recognition.md)
20. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
21. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks.md)
22. [Deep Residual Learning for Image Recognition](2016-deep-residual-learning-for-image-recognition.md)
23. [Going deeper with convolutions](2015-going-deeper-with-convolutions.md)
24. Ternary Weight Networks
25. [Densely Connected Convolutional Networks](2017-densely-connected-convolutional-networks.md)
26. [SSD - Single Shot MultiBox Detector](2016-ssd-single-shot-multibox-detector.md)
27. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context.md)
28. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database.md)
