---
title: Deep Neural Networks for Acoustic Modeling in Speech Recognition - The Shared Views of Four Research Groups
authors:
- Geoffrey E. Hinton
- L. Deng
- Dong Yu
- George E. Dahl
- Abdel-rahman Mohamed
- Navdeep Jaitly
- A. Senior
- Vincent Vanhoucke
- P. Nguyen
- T. Sainath
- Brian Kingsbury
fieldsOfStudy:
- Computer Science
meta_key: 2012-deep-neural-networks-for-acoustic-modeling-in-speech-recognition-the-shared-views-of-four-research-groups
numCitedBy: 7472
reading_status: TBD
ref_count: 73
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Deep-Neural-Networks-for-Acoustic-Modeling-in-The-Hinton-Deng/31868290adf1c000c611dfc966b514d5a34e8d23?sort=total-citations
venue: IEEE Signal Processing Magazine
year: 2012
---

# Deep Neural Networks for Acoustic Modeling in Speech Recognition - The Shared Views of Four Research Groups

## Abstract

Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.

## Paper References

1. Deep Belief Networks using discriminative features for phone recognition
2. [Acoustic Modeling Using Deep Belief Networks](2012-acoustic-modeling-using-deep-belief-networks)
3. Deep Belief Networks for phone recognition
4. Speech Recognition Using Augmented Conditional Random Fields
5. [Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition](2012-context-dependent-pre-trained-deep-neural-networks-for-large-vocabulary-speech-recognition)
6. Lattice-based optimization of sequence classification criteria for neural-network acoustic modeling
7. Applying Convolutional Neural Networks concepts to hybrid NN-HMM model for speech recognition
8. Application of Pretrained Deep Neural Networks to Large Vocabulary Speech Recognition
9. Tandem connectionist feature extraction for conventional HMM systems
10. Large scale discriminative training of hidden Markov models for speech recognition
11. Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine
12. Understanding how Deep Belief Networks perform acoustic modelling
13. Connectionist Speech Recognition - A Hybrid Approach
14. Investigation of full-sequence training of deep belief networks for speech recognition
15. Roles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition
16. Feature engineering in Context-Dependent Deep Neural Networks for conversational speech transcription
17. Structured speech modeling
18. Boosting attribute and phone estimation accuracies with deep neural networks for detection-based speech recognition
19. Heterogeneous measurements and multiple classifiers for speech recognition
20. Global optimization of a neural network-hidden Markov model hybrid
21. Product of Experts for Statistical Parametric Speech Synthesis
22. Deep and Wide - Multiple Layers in Automatic Speech Recognition
23. Conversational Speech Transcription Using Context-Dependent Deep Neural Networks
24. Switching Dynamic System Models for Speech Articulation and Acoustics
25. Speech recognitionwith segmental conditional random fields - A summary of the JHU CLSP 2010 Summer Workshop
26. Unsupervised feature learning for audio classification using convolutional deep belief networks
27. Use of Differential Cepstra as Acoustic Features in Hidden Trajectory Modeling for Phonetic Recognition
28. Sparse Multilayer Perceptron for Phoneme Recognition
29. Deep Convex Net - A Scalable Architecture for Speech Pattern Classification
30. A review of large-vocabulary continuous-speech
31. Pushing the envelope - aside [speech recognition
32. Auto-encoder bottleneck features using deep belief networks
33. Speech recognition using the atomic speech units constructed from overlapping articulatory features
34. Comparing multilayer perceptron to Deep Belief Network Tandem features for robust ASR
35. Backpropagation training for multilayer conditional random field based phone recognition
36. Exemplar-Based Sparse Representation Features - From TIMIT to LVCSR
37. An exploration of large vocabulary tools for small vocabulary phonetic recognition
38. An application of recurrent nets to phone probability estimation
39. Improved phone recognition using Bayesian triphone models
40. Improved pre-training of Deep Belief Networks using Sparse Encoding Symmetric Machines
41. Perceptual linear predictive (PLP) analysis of speech.
42. Boosted MMI for model and feature-space discriminative training
43. Probabilistic and Bottle-Neck Features for LVCSR of Meetings
44. Cepstral analysis technique for automatic speaker verification
45. Scalable stacking and learning for building deep architectures
46. Improving the speed of neural networks on CPUs
47. [Stacked Denoising Autoencoders - Learning Useful Representations in a Deep Network with a Local Denoising Criterion](2010-stacked-denoising-autoencoders-learning-useful-representations-in-a-deep-network-with-a-local-denoising-criterion)
48. [Understanding the difficulty of training deep feedforward neural networks](2010-understanding-the-difficulty-of-training-deep-feedforward-neural-networks)
49. [A Fast Learning Algorithm for Deep Belief Nets](2006-a-fast-learning-algorithm-for-deep-belief-nets)
50. Developments and directions in speech recognition and understanding, Part 1 [DSP Education
51. Maximum mutual information estimation of hidden Markov model parameters for speech recognition
52. An empirical evaluation of deep architectures on problems with many factors of variation
53. Learning representations by back-propagating errors
54. Digital speech processing, synthesis, and recognition
55. On optimization methods for deep learning
56. [Reducing the Dimensionality of Data with Neural Networks](2006-reducing-the-dimensionality-of-data-with-neural-networks)
57. Maximum likelihood estimation for multivariate mixture observations of markov chains
58. Contractive Auto-Encoders - Explicit Invariance During Feature Extraction
59. [Training Products of Experts by Minimizing Contrastive Divergence](2002-training-products-of-experts-by-minimizing-contrastive-divergence)
60. Discriminative learning in sequential pattern recognition
61. Deep, Big, Simple Neural Nets for Handwritten Digit Recognition
62. A Practical Guide to Training Restricted Boltzmann Machines
63. Deep learning via Hessian-free optimization
64. An overlapping-feature-based phonological model incorporating linguistic constraints - applications to speech recognition.
65. A deep architecture with bilinear modeling of hidden representations - Applications to phonetic recognition
66. Large Vocabulary Continuous Speech Recognition - a ReviewSteve
