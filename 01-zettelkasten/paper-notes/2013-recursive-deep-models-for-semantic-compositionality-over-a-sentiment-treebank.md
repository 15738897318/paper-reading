---
title: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
authors:
- R. Socher
- Alex Perelygin
- Jean Wu
- Jason Chuang
- Christopher D. Manning
- A. Ng
- Christopher Potts
fieldsOfStudy:
- Computer Science
meta_key: 2013-recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank
numCitedBy: 5397
reading_status: TBD
ref_count: 55
tags:
- gen-from-ref
- other-default
- paper
venue: EMNLP
year: 2013
---

# Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank

## Abstract

Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.

## Paper References

1. [Semantic Compositionality through Recursive Matrix-Vector Spaces](2012-semantic-compositionality-through-recursive-matrix-vector-spaces)
2. Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks
3. [Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions](2011-semi-supervised-recursive-autoencoders-for-predicting-sentiment-distributions)
4. Compositional Matrix-Space Models for Sentiment Analysis
5. Distributional Memory - A General Framework for Corpus-Based Semantics
6. Multi-entity Sentiment Scoring
7. Dependency Tree-based Sentiment Classification using CRFs with Hidden Variables
8. Sentiment Composition
9. [A unified architecture for natural language processing - deep neural networks with multitask learning](2008-a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning)
10. Seeing Stars - Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales
11. A Neural Probabilistic Language Model
12. [Parsing Natural Scenes and Natural Language with Recursive Neural Networks](2011-parsing-natural-scenes-and-natural-language-with-recursive-neural-networks)
13. Estimating Linear Models for Compositional Distributional Semantics
14. United we Stand - Improving Sentiment Analysis by Joining Machine Learning and Rule Based Methods
15. Composition in Distributional Models of Semantics
16. A Structured Vector Space Model for Word Meaning in Context
17. Large Vocabulary Speech Recognition Using Deep Tensor Neural Networks
18. From machine learning to machine reasoning
19. Dependency-Based Construction of Semantic Space Models
20. A latent factor model for highly multi-relational data
21. Learning to Map Sentences to Logical Form - Structured Classification with Probabilistic Categorial Grammars
22. Semantic Vector Products - Some Initial Investigations
23. Learning task-dependent distributed representations by backpropagation through structure
24. Compositional Matrix-Space Models of Language
25. Combining Symbolic and Distributional Models of Meaning
26. Multiple Aspect Ranking Using the Good Grief Algorithm
27. Minimizers, Maximizers and the Rhetoric of Scalar Reasoning
28. From Frequency to Meaning - Vector Space Models of Semantics
29. Factored 3-Way Restricted Boltzmann Machines For Modeling Natural Images
30. [Accurate Unlexicalized Parsing](2003-accurate-unlexicalized-parsing)
31. Recursive Distributed Representations
32. Modelling Relational Data using Bayesian Clustered Tensor Factorization
33. A natural history of negation
34. Information, relevance, and social decisionmaking - some principles and results of decision-theoretic semantics
35. Mapping Part-Whole Hierarchies into Connectionist Networks
36. A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle
37. Contextual Valence Shifters
38. [Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](2010-adaptive-subgradient-methods-for-online-learning-and-stochastic-optimization)
39. Holographic reduced representations
40. Denial and contrast - A relevance theoretic analysis ofbut
41. [Improving Word Representations via Global Context and Multiple Word Prototypes](2012-improving-word-representations-via-global-context-and-multiple-word-prototypes)
42. Multi-Step Regression Learning for Compositional Distributional Semantics
43. Experimental Support for a Categorical Compositional Distributional Model of Meaning
