---
title: Compact Bilinear Pooling
authors:
- Yang Gao
- Oscar Beijbom
- Ning Zhang
- Trevor Darrell
fieldsOfStudy:
- Computer Science
meta_key: 2016-compact-bilinear-pooling
numCitedBy: 584
reading_status: TBD
ref_count: 51
tags:
- gen-from-ref
- paper
venue: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2016
---

# Compact Bilinear Pooling

## Abstract

Bilinear models has been shown to achieve impressive performance on a wide range of visual tasks, such as semantic segmentation, fine grained recognition and face recognition. However, bilinear features are high dimensional, typically on the order of hundreds of thousands to a few million, which makes them impractical for subsequent analysis. We propose two compact bilinear representations with the same discriminative power as the full bilinear representation but with only a few thousand dimensions. Our compact representations allow back-propagation of classification errors enabling an end-to-end optimization of the visual recognition system. The compact bilinear representations are derived through a novel kernelized analysis of bilinear pooling which provide insights into the discriminative power of bilinear pooling, and a platform for further research in compact pooling methods. Experimentation illustrate the utility of the proposed representations for image classification and few-shot learning across several datasets.

## Paper References

1. Bilinear CNN Models for Fine-Grained Visual Recognition
2. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2015-very-deep-convolutional-networks-for-large-scale-image-recognition)
3. Improving the Fisher Kernel for Large-Scale Image Classification
4. One-to-many face recognition with bilinear CNNs
5. Face Identification with Bilinear CNNs
6. Semantic Segmentation with Second-Order Pooling
7. Deep Filter Banks for Texture Recognition, Description, and Segmentation
8. [Return of the Devil in the Details - Delving Deep into Convolutional Nets](2014-return-of-the-devil-in-the-details-delving-deep-into-convolutional-nets)
9. Aggregating local descriptors into a compact image representation
10. Describing Textures in the Wild
11. Fine-grained recognition without part annotations
12. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks)
13. Generalized RBF feature maps for Efficient Detection
14. [Network In Network](2014-network-in-network)
15. [Beyond Bags of Features - Spatial Pyramid Matching for Recognizing Natural Scene Categories](2006-beyond-bags-of-features-spatial-pyramid-matching-for-recognizing-natural-scene-categories)
16. [Histograms of oriented gradients for human detection](2005-histograms-of-oriented-gradients-for-human-detection)
17. [Object recognition from local scale-invariant features](1999-object-recognition-from-local-scale-invariant-features)
18. Learning Fine-Grained Image Similarity with Deep Ranking
19. Efficient Large-Scale Structured Learning
20. Recognizing indoor scenes
21. [Object Detection with Discriminatively Trained Part Based Models](2009-object-detection-with-discriminatively-trained-part-based-models)
22. Separating Style and Content with Bilinear Models
23. MatConvNet - Convolutional Neural Networks for MATLAB
24. Max-margin additive classifiers for detection
25. Deep Fried Convnets
26. Representing and Recognizing the Visual Appearance of Materials using Three-dimensional Textons
27. Fast and scalable polynomial kernels via explicit feature maps
28. One-shot learning of object categories
29. An Exploration of Parameter Redundancy in Deep Networks with Circulant Projections
30. Random Features for Large-Scale Kernel Machines
31. The Caltech-UCSD Birds-200-2011 Dataset
32. Fast Neural Networks with Circulant Projections
33. [GradientBased Learning Applied to Document Recognition](2001-gradientbased-learning-applied-to-document-recognition)
34. [Gradient-based learning applied to document recognition](1998-gradient-based-learning-applied-to-document-recognition)
35. Random Feature Maps for Dot Product Kernels
36. Very sparse random projections
37. Caltech-UCSD Birds 200
38. Automated annotation of coral reef survey images
39. Frustratingly Easy Domain Adaptation
40. Finding Frequent Items in Data Streams
41. An elementary proof of the Johnson-Lindenstrauss Lemma
42. [The Nature of Statistical Learning Theory](2000-the-nature-of-statistical-learning-theory)
43. Efficient additive kernels via explicit feature maps
