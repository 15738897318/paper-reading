---
title: Modeling Relationships in Referential Expressions with Compositional Modular Networks
authors:
- Ronghang Hu
- Marcus Rohrbach
- Jacob Andreas
- Trevor Darrell
- Kate Saenko
fieldsOfStudy:
- Computer Science
meta_key: 2017-modeling-relationships-in-referential-expressions-with-compositional-modular-networks
numCitedBy: 268
reading_status: TBD
ref_count: 39
tags:
- gen-from-ref
- other-default
- paper
venue: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2017
---

# Modeling Relationships in Referential Expressions with Compositional Modular Networks

## Abstract

People often refer to entities in an image in terms of their relationships with other entities. For example, the black cat sitting under the table refers to both a black cat entity and its relationship with another table entity. Understanding these relationships is essential for interpreting and grounding such natural language expressions. Most prior work focuses on either grounding entire referential expressions holistically to one region, or localizing relationships based on a fixed set of categories. In this paper we instead present a modular deep architecture capable of analyzing referential expressions into their component parts, identifying entities and relationships mentioned in the input expression and grounding them all in the scene. We call this approach Compositional Modular Networks (CMNs): a novel architecture that learns linguistic analysis and visual inference end-to-end. Our approach is built around two types of neural modules that inspect local regions and pairwise interactions between regions. We evaluate CMNs on multiple referential expression datasets, outperforming state-of-the-art approaches on all tasks.

## Paper References

1. VisKE - Visual knowledge extraction and question answering by visual verification of relation phrases
2. [Modeling Context in Referring Expressions](2016-modeling-context-in-referring-expressions)
3. Jointly Learning to Parse and Perceive - Connecting Natural Language to the Physical World
4. Modeling Context Between Objects for Referring Expression Understanding
5. Segmentation from Natural Language Expressions
6. [Grounding of Textual Phrases in Images by Reconstruction](2016-grounding-of-textual-phrases-in-images-by-reconstruction)
7. Visual Relationship Detection with Language Priors
8. [Neural Module Networks](2016-neural-module-networks)
9. [Visual7W - Grounded Question Answering in Images](2016-visual7w-grounded-question-answering-in-images)
10. [Natural Language Object Retrieval](2016-natural-language-object-retrieval)
11. [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](2016-visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations)
12. [Generation and Comprehension of Unambiguous Object Descriptions](2016-generation-and-comprehension-of-unambiguous-object-descriptions)
13. [DenseCap - Fully Convolutional Localization Networks for Dense Captioning](2016-densecap-fully-convolutional-localization-networks-for-dense-captioning)
14. [Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding](2016-multimodal-compact-bilinear-pooling-for-visual-question-answering-and-visual-grounding)
15. The Oxford Handbook of Compositionality
16. [GloVe - Global Vectors for Word Representation](2014-glove-global-vectors-for-word-representation)
17. [Learning to Compose Neural Networks for Question Answering](2016-learning-to-compose-neural-networks-for-question-answering)
18. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context)
19. [You Only Look Once - Unified, Real-Time Object Detection](2016-you-only-look-once-unified-real-time-object-detection)
20. [Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation](2014-rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation)
21. [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](2015-show-attend-and-tell-neural-image-caption-generation-with-visual-attention)
22. [SSD - Single Shot MultiBox Detector](2016-ssd-single-shot-multibox-detector)
23. Stating the Obvious - Extracting Visual Common Sense Knowledge
24. [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](2015-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks)
25. [Edge Boxes - Locating Object Proposals from Edges](2014-edge-boxes-locating-object-proposals-from-edges)
26. [R-FCN - Object Detection via Region-based Fully Convolutional Networks](2016-r-fcn-object-detection-via-region-based-fully-convolutional-networks)
27. Fast and Accurate Shift-Reduce Constituent Parsing
28. [Selective Search for Object Recognition](2013-selective-search-for-object-recognition)
29. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2014-vggnet.md)
30. Multiple Object Recognition with Visual Attention
31. [TensorFlow - Large-Scale Machine Learning on Heterogeneous Distributed Systems](2016-tensorflow-large-scale-machine-learning-on-heterogeneous-distributed-systems)
32. [Multiscale Combinatorial Grouping](2014-multiscale-combinatorial-grouping)
33. Geodesic Object Proposals
34. Bidirectional recurrent neural networks
35. [Understanding the difficulty of training deep feedforward neural networks](2010-understanding-the-difficulty-of-training-deep-feedforward-neural-networks)
36. [The Stanford CoreNLP Natural Language Processing Toolkit](2014-the-stanford-corenlp-natural-language-processing-toolkit)
