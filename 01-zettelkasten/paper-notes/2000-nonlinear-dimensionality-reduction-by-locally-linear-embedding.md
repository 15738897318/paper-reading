---
title: Nonlinear dimensionality reduction by locally linear embedding.
authors:
- S. Roweis
- L. Saul
fieldsOfStudy:
- Computer Science
meta_key: 2000-nonlinear-dimensionality-reduction-by-locally-linear-embedding
numCitedBy: 14001
reading_status: TBD
ref_count: 27
tags:
- gen-from-ref
- other-default
- paper
venue: Science
year: 2000
---

# Nonlinear dimensionality reduction by locally linear embedding.

## Abstract

Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.

## Paper References

1. Dimension Reduction by Local Principal Component Analysis
2. Data visualization by multidimensional scaling - a deterministic annealing approach
3. Nonlinear principal component analysis using autoassociative neural networks
4. GTM - The Generative Topographic Mapping
5. [Learning the parts of objects by non-negative matrix factorization](1999-learning-the-parts-of-objects-by-non-negative-matrix-factorization)
6. Nonmetric individual differences multidimensional scaling - An alternating least squares method with optimal scaling features
7. Topology representing networks
8. Templates for the Solution of Algebraic Eigenvalue Problems
9. Image Representations for Visual Learning
10. Self-Organization and Associative Memory
11. Data structures and network algorithms
12. Neural networks
13. Pattern Recognition
14. Analysis of Additive Dependencies and Concurvities Using Smallest Additive Principal Components
