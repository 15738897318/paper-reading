---
title: A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference
authors:
- Adina Williams
- Nikita Nangia
- Samuel R. Bowman
fieldsOfStudy:
- Computer Science
meta_key: 2018-a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference
numCitedBy: 2075
reading_status: TBD
ref_count: 67
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/A-Broad-Coverage-Challenge-Corpus-for-Sentence-Williams-Nangia/5ded2b8c64491b4a67f6d39ce473d4b9347a672e?sort=total-citations
venue: NAACL
year: 2018
---

# A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference

## Abstract

This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.

## Paper References

1. [A large annotated corpus for learning natural language inference](2015-a-large-annotated-corpus-for-learning-natural-language-inference)
2. [Supervised Learning of Universal Sentence Representations from Natural Language Inference Data](2017-supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data)
3. The American National Corpus - A Standardized Resource for American English
4. Natural language inference
5. The RepEval 2017 Shared Task - Multi-Genre Natural Language Inference with Sentence Representations
6. Learning Natural Language Inference with LSTM
7. Enhanced LSTM for Natural Language Inference
8. Building a Large Annotated Corpus of English - The Penn Treebank
9. Recognising Textual Entailment with Logical Inference
10. A SICK cure for the evaluation of compositional distributional semantic models
11. A Fast Unified Model for Parsing and Sentence Understanding
12. Neural Semantic Encoders
13. A Decomposable Attention Model for Natural Language Inference
14. Natural language inference.
15. SemEval-2014 Task 1 - Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment
16. SICK through the SemEval glasses. Lesson learned from the evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment
17. Domain Adaptation with Structural Correspondence Learning
18. An extended model of natural logic
19. Finding Contradictions in Text
20. [GloVe - Global Vectors for Word Representation](2014-glove-global-vectors-for-word-representation)
21. The PASCAL Recognising Textual Entailment Challenge
22. Natural Language Inference by Tree-Based Convolution and Heuristic Matching
23. [Accurate Unlexicalized Parsing](2003-accurate-unlexicalized-parsing)
24. An American national corpus - a proposal
25. Domain Adaptation for Statistical Classifiers
26. Entailment, intensionality and text understanding
27. Analysis of Representations for Domain Adaptation
28. Multi-task Domain Adaptation for Sequence Tagging
29. A Natural Logic Inference System
30. The Cambridge Handbook of Formal Semantics
31. [Dropout - a simple way to prevent neural networks from overfitting](2014-dropout-a-simple-way-to-prevent-neural-networks-from-overfitting)
32. [DeCAF - A Deep Convolutional Activation Feature for Generic Visual Recognition](2014-decaf-a-deep-convolutional-activation-feature-for-generic-visual-recognition)
33. [Long Short-Term Memory](1997-long-short-term-memory)
34. Semantics in generative grammar
35. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization)
36. [From image descriptions to visual denotations - New similarity metrics for semantic inference over event descriptions](2014-from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions)
37. [ImageNet classification with deep convolutional neural networks](2012-alexnet.md)
38. [Visualizing and Understanding Convolutional Networks](2014-visualizing-and-understanding-convolutional-networks)
39. Quantification
40. Using the Framework
41. Youth
42. The sky is falling
43. Living History
44. Semantics and Philosophy
45. How Transferable are Neural Networks in NLP Applications?
