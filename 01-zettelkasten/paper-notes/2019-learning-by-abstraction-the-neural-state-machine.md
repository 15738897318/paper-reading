---
title: Learning by Abstraction - The Neural State Machine
authors:
- Drew A. Hudson
- Christopher D. Manning
fieldsOfStudy:
- Computer Science
meta_key: 2019-learning-by-abstraction-the-neural-state-machine
numCitedBy: 147
reading_status: TBD
ref_count: 90
tags:
- gen-from-ref
- other-default
- paper
venue: NeurIPS
year: 2019
---

# Learning by Abstraction - The Neural State Machine

## Abstract

We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.

## Paper References

1. [Compositional Attention Networks for Machine Reasoning](2018-compositional-attention-networks-for-machine-reasoning)
2. SCAN - Learning Abstract Hierarchical Compositional Visual Concepts
3. [Relational inductive biases, deep learning, and graph networks](2018-relational-inductive-biases-deep-learning-and-graph-networks)
4. Measuring abstract reasoning in neural networks
5. Neural-Symbolic VQA - Disentangling Reasoning from Vision and Language Understanding
6. SCAN - Learning Hierarchical Compositional Visual Concepts
7. Learning with Latent Language
8. MUREL - Multimodal Relational Reasoning for Visual Question Answering
9. Compositional Obverter Communication Learning From Raw Visual Input
10. [Building machines that learn and think like people](2016-building-machines-that-learn-and-think-like-people)
11. The Neuro-Symbolic Concept Learner - Interpreting Scenes Words and Sentences from Natural Supervision
12. [Neural Module Networks](2016-neural-module-networks)
13. Transparency by Design - Closing the Gap Between Performance and Interpretability in Visual Reasoning
14. Towards Deep Symbolic Reinforcement Learning
15. [Hybrid computing using a neural network with dynamic external memory](2016-hybrid-computing-using-a-neural-network-with-dynamic-external-memory)
16. Early Visual Concept Learning with Unsupervised Deep Learning
17. From machine learning to machine reasoning
18. Measuring Compositionality in Representation Learning
19. Graph-Structured Representations for Visual Question Answering
20. [GQA - A New Dataset for Real-World Visual Reasoning and Compositional Question Answering](2019-gqa-a-new-dataset-for-real-world-visual-reasoning-and-compositional-question-answering)
21. Generalization without Systematicity - On the Compositional Skills of Sequence-to-Sequence Recurrent Networks
22. [Learning to Reason - End-to-End Module Networks for Visual Question Answering](2017-learning-to-reason-end-to-end-module-networks-for-visual-question-answering)
23. [What Value Do Explicit High Level Concepts Have in Vision to Language Problems?](2016-what-value-do-explicit-high-level-concepts-have-in-vision-to-language-problems)
24. Learning Conditioned Graph Structures for Interpretable Visual Question Answering
25. [CLEVR - A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning](2017-clevr-a-diagnostic-dataset-for-compositional-language-and-elementary-visual-reasoning)
26. Relation-Aware Graph Attention Network for Visual Question Answering
27. Neural Motifs - Scene Graph Parsing with Global Context
28. [Dynamic Memory Networks for Visual and Textual Question Answering](2016-dynamic-memory-networks-for-visual-and-textual-question-answering)
29. [Graph Attention Networks](2018-graph-attention-networks)
30. Connectionist AI, symbolic AI, and the brain
31. [Gated Graph Sequence Neural Networks](2016-gated-graph-sequence-neural-networks)
32. The VQA-Machine - Learning How to Use Existing Vision Algorithms to Answer New Questions
33. Analyzing the Behavior of Visual Question Answering Models
34. Image Generation from Scene Graphs
35. [Neural Baby Talk](2018-neural-baby-talk)
36. Scene Graph Generation from Objects, Phrases and Region Captions
37. Knowledge-Embedded Routing Network for Scene Graph Generation
38. [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](2016-visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations)
39. Human-level control through deep reinforcement learning
40. [Stacked Attention Networks for Image Question Answering](2016-stacked-attention-networks-for-image-question-answering)
41. The Consciousness Prior
42. Don't Just Assume; Look and Answer - Overcoming Priors for Visual Question Answering
43. [Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering](2017-making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering)
44. Scene Graph Generation by Iterative Message Passing
45. Semantic Cognition - A Parallel Distributed Processing Approach
46. Answer Them All! Toward Universal Visual Question Answering Models
47. The language capacity - architecture and evolution
48. [VQA - Visual Question Answering](2015-vqa-visual-question-answering)
49. [Knowing When to Look - Adaptive Attention via a Visual Sentinel for Image Captioning](2017-knowing-when-to-look-adaptive-attention-via-a-visual-sentinel-for-image-captioning)
50. [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](2016-google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation)
51. [Bilinear Attention Networks](2018-bilinear-attention-networks)
52. Learning Visual Question Answering by Bootstrapping Hard Attention
53. Semantic Compositional Networks for Visual Captioning
54. Human Attention in Visual Question Answering - Do Humans and Deep Networks look at the same regions?
55. Finite-State Computation in Analog Neural Networks - Steps towards Biologically Plausible Models?
56. Describing objects by their attributes
57. [GloVe - Global Vectors for Word Representation](2014-glove-global-vectors-for-word-representation)
58. Key-Value Memory Networks for Directly Reading Documents
59. Factorizable Net - An Efficient Subgraph-based Framework for Scene Graph Generation
60. Survey of Visual Question Answering - Datasets and Techniques
61. Explaining and Harnessing Adversarial Examples
62. [Deep Residual Learning for Image Recognition](2016-deep-residual-learning-for-image-recognition)
63. [Feature Pyramid Networks for Object Detection](2017-feature-pyramid-networks-for-object-detection)
64. [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](2018-bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering)
65. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization)
66. [Neural Turing Machines](2014-neural-turing-machines)
67. Grounding conceptual knowledge in modality-specific systems
68. [Bottom-Up and Top-Down Attention for Image Captioning and VQA](2017-bottom-up-and-top-down-attention-for-image-captioning-and-vqa)
69. [Semi-Supervised Classification with Graph Convolutional Networks](2017-semi-supervised-classification-with-graph-convolutional-networks)
70. Graph R-CNN for Scene Graph Generation
71. Adversarial Examples for Evaluating Reading Comprehension Systems
72. Physical Symbol Systems
73. The Consciousness of a Neural State Machine
74. Learning to Segment Every Thing
75. Semantic Modeling of Natural Scenes for Content-Based Image Retrieval
76. Forest before trees - The precedence of global features in visual perception
77. Image retrieval using scene graphs
78. The Language of Thought - A New Philosophical Direction
79. Grounding Cognition - Introduction to Grounding Cognition - The Role of Perception and Action in Memory, Language, and Thinking
80. [YOLO9000 - Better, Faster, Stronger](2017-yolo9000-better-faster-stronger)
81. LANGUAGE OF THOUGHT
82. Aspects of the Theory of Syntax
83. Language shapes thought
84. A theory of concepts and concepts possession
85. Thought and language.
86. Introduction to Automata Theory, Languages and Computation
87. A perspective on thinking.
88. Change in View - Principles of Reasoning
89. [Mask R-CNN](2020-mask-r-cnn)
