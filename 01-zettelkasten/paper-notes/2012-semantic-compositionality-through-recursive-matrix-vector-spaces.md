---
title: Semantic Compositionality through Recursive Matrix-Vector Spaces
authors:
- R. Socher
- Brody Huval
- Christopher D. Manning
- A. Ng
fieldsOfStudy:
- Computer Science
meta_key: 2012-semantic-compositionality-through-recursive-matrix-vector-spaces
numCitedBy: 1265
reading_status: TBD
ref_count: 45
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Semantic-Compositionality-through-Recursive-Spaces-Socher-Huval/27e38351e48fe4b7da2775bf94341738bc4da07e?sort=total-citations
venue: EMNLP
year: 2012
---

[semanticscholar url](https://www.semanticscholar.org/paper/Semantic-Compositionality-through-Recursive-Spaces-Socher-Huval/27e38351e48fe4b7da2775bf94341738bc4da07e?sort=total-citations)

# Semantic Compositionality through Recursive Matrix-Vector Spaces

## Abstract

Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them.

## Paper References

1. Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks
2. [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](2013-recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank)
3. Distributional Memory - A General Framework for Corpus-Based Semantics
4. Composition in Distributional Models of Semantics
5. Compositional Matrix-Space Models for Sentiment Analysis
6. Dependency-Based Construction of Semantic Space Models
7. Nouns are Vectors, Adjectives are Matrices - Representing Adjective-Noun Constructions in Semantic Space
8. Topics in semantic representation.
9. [Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions](2011-semi-supervised-recursive-autoencoders-for-predicting-sentiment-distributions)
10. Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection
11. Semantic Vector Products - Some Initial Investigations
12. [A unified architecture for natural language processing - deep neural networks with multitask learning](2008-a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning)
13. [Parsing Natural Scenes and Natural Language with Recursive Neural Networks](2011-parsing-natural-scenes-and-natural-language-with-recursive-neural-networks)
14. From Frequency to Meaning - Vector Space Models of Semantics
15. Dependency Tree-based Sentiment Classification using CRFs with Hidden Variables
16. Distributed representations, simple recurrent networks, and grammatical structure
17. Estimating Linear Models for Compositional Distributional Semantics
18. Combining Symbolic and Distributional Models of Meaning
19. Integrating Logical Representations with Probabilistic Information using Markov Logic
20. Broad-Coverage Sense Disambiguation and Information Extraction with a Supersense Sequence Tagger
21. Automatic Word Sense Discrimination
22. Compositional Matrix-Space Models of Language
23. Learning task-dependent distributed representations by backpropagation through structure
24. Recursive Distributed Representations
25. Seeing Stars - Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales
26. UTD - Classifying Semantic Relations by Combining Lexical and Semantic Resources
27. From machine learning to machine reasoning
28. Local and Global Algorithms for Disambiguation to Wikipedia
29. Automatic Retrieval and Clustering of Similar Words
30. On the negativity of negation
31. [Accurate Unlexicalized Parsing](2003-accurate-unlexicalized-parsing)
32. Mapping Part-Whole Hierarchies into Connectionist Networks
33. Holographic reduced representations
34. Generating query substitutions
35. Names and Similarities on the Web - Fact Extraction in the Fast Lane
36. A composite holographic associative recall model
37. Ãœber Sinn und Bedeutung
38. SemEval-2010 Task 8 - Multi-Way Classification of Semantic Relations between Pairs of Nominals
39. ENGLISH AS A FORMAL LANGUAGE
40. From distributional to semantic similarity
41. Experimental Support for a Categorical Compositional Distributional Model of Meaning
