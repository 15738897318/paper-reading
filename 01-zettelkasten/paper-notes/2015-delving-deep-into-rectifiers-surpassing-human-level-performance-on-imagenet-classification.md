---
title: Delving Deep into Rectifiers - Surpassing Human-Level Performance on ImageNet Classification
authors:
- Kaiming He
- X. Zhang
- Shaoqing Ren
- Jian Sun
fieldsOfStudy:
- Computer Science
meta_key: 2015-delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification
numCitedBy: 12461
reading_status: TBD
ref_count: 48
tags:
- gen-from-ref
- other-default
- paper
venue: 2015 IEEE International Conference on Computer Vision (ICCV)
year: 2015
---

# Delving Deep into Rectifiers - Surpassing Human-Level Performance on ImageNet Classification

## Abstract

Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset. This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1%, [26]) on this dataset.

## Paper References

1. [Deeply-Supervised Nets](2015-deeply-supervised-nets)
2. [ImageNet classification with deep convolutional neural networks](2012-alexnet.md)
3. Convolutional neural networks at constrained time cost
4. [Return of the Devil in the Details - Delving Deep into Convolutional Nets](2014-return-of-the-devil-in-the-details-delving-deep-into-convolutional-nets)
5. [Going deeper with convolutions](2015-going-deeper-with-convolutions)
6. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2015-very-deep-convolutional-networks-for-large-scale-image-recognition)
7. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift)
8. [DeepFace - Closing the Gap to Human-Level Performance in Face Verification](2014-deepface-closing-the-gap-to-human-level-performance-in-face-verification)
9. Some Improvements on Deep Convolutional Neural Network Based Image Classification
10. On rectified linear units for speech processing
11. [Network In Network](2014-network-in-network)
12. Deep Learning Made Easier by Linear Transformations in Perceptrons
13. [Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition](2015-spatial-pyramid-pooling-in-deep-convolutional-networks-for-visual-recognition)
14. [Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation](2014-rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation)
15. [OverFeat - Integrated Recognition, Localization and Detection using Convolutional Networks](2014-overfeat-integrated-recognition-localization-and-detection-using-convolutional-networks)
16. Understanding Deep Architectures using a Recursive Convolutional Network
17. [Understanding the difficulty of training deep feedforward neural networks](2010-understanding-the-difficulty-of-training-deep-feedforward-neural-networks)
18. [Multi-column deep neural networks for image classification](2012-multi-column-deep-neural-networks-for-image-classification)
19. [Caffe - Convolutional Architecture for Fast Feature Embedding](2014-caffe-convolutional-architecture-for-fast-feature-embedding)
20. [Rectifier Nonlinearities Improve Neural Network Acoustic Models](2013-rectifier-nonlinearities-improve-neural-network-acoustic-models)
21. Deep Learning Face Representation by Joint Identification-Verification
22. [Dropout - a simple way to prevent neural networks from overfitting](2014-dropout-a-simple-way-to-prevent-neural-networks-from-overfitting)
23. [Maxout Networks](2013-maxout-networks)
24. [Fast R-CNN](2015-fast-r-cnn)
25. [Regularization of Neural Networks using DropConnect](2013-regularization-of-neural-networks-using-dropconnect)
26. [ImageNet Large Scale Visual Recognition Challenge](2015-imagenet-large-scale-visual-recognition-challenge)
27. Deep Image - Scaling up Image Recognition
28. Learning Activation Functions to Improve Deep Neural Networks
29. [Improving neural networks by preventing co-adaptation of feature detectors](2012-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors)
30. Pushing Stochastic Gradient towards Second-Order Methods -- Backpropagation Learning with Transformations in Nonlinearities
31. [Exact solutions to the nonlinear dynamics of learning in deep linear neural networks](2014-exact-solutions-to-the-nonlinear-dynamics-of-learning-in-deep-linear-neural-networks)
32. [Rectified Linear Units Improve Restricted Boltzmann Machines](2010-rectified-linear-units-improve-restricted-boltzmann-machines)
33. [The Pascal Visual Object Classes (VOC) Challenge](2009-the-pascal-visual-object-classes-voc-challenge)
34. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database)
35. Backpropagation Applied to Handwritten Zip Code Recognition
36. Compete to Compute
37. One weird trick for parallelizing convolutional neural networks
38. Et al
39. Visualizing and Understanding Convolutional Neural Networks
40. [Efficient BackProp](2012-efficient-backprop)
