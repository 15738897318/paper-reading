---
title: On Multiplicative Integration with Recurrent Neural Networks
authors:
- Yuhuai Wu
- Saizheng Zhang
- Y. Zhang
- Yoshua Bengio
- R. Salakhutdinov
fieldsOfStudy:
- Computer Science
meta_key: 2016-on-multiplicative-integration-with-recurrent-neural-networks
numCitedBy: 130
reading_status: TBD
ref_count: 36
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/On-Multiplicative-Integration-with-Recurrent-Neural-Wu-Zhang/136cf66392f1d6bf42da4cc070888996dc472b91?sort=total-citations
venue: NIPS
year: 2016
---

# On Multiplicative Integration with Recurrent Neural Networks

## Abstract

We introduce a general and simple structural design called Multiplicative Integration (MI) to improve recurrent neural networks (RNNs). MI changes the way in which information from difference sources flows and is integrated in the computational building block of an RNN, while introducing almost no extra parameters. The new structure can be easily embedded into many popular RNN models, including LSTMs and GRUs. We empirically analyze its learning behaviour and conduct evaluations on several tasks using different RNN models. Our experimental results demonstrate that Multiplicative Integration can provide a substantial performance boost over many of the existing RNN models.

## Paper References

1. [An Empirical Exploration of Recurrent Network Architectures](2015-an-empirical-exploration-of-recurrent-network-architectures.md)
2. [Generating Text with Recurrent Neural Networks](2011-generating-text-with-recurrent-neural-networks.md)
3. Architectural Complexity Measures of Recurrent Neural Networks
4. Gated Feedback Recurrent Neural Networks
5. [Recurrent Batch Normalization](2017-recurrent-batch-normalization.md)
6. Regularizing RNNs by Stabilizing Activations
7. Regularization and nonlinearities for neural language models - when are they needed?
8. Semi-Supervised Learning with Ladder Network
9. Semi-supervised Learning with Ladder Networks
10. Deconstructing the Ladder Network Architecture
11. SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS
12. [Long Short-Term Memory](1997-long-short-term-memory.md)
13. [Grid Long Short-Term Memory](2016-grid-long-short-term-memory.md)
14. [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](2014-learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation.md)
15. Refining hidden Markov models with recurrent neural networks
16. [Skip-Thought Vectors](2015-skip-thought-vectors.md)
17. Second-order recurrent neural networks for grammatical inference
18. [Generating Sequences With Recurrent Neural Networks](2013-generating-sequences-with-recurrent-neural-networks.md)
19. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
20. [Connectionist temporal classification - labelling unsegmented sequence data with recurrent neural networks](2006-connectionist-temporal-classification-labelling-unsegmented-sequence-data-with-recurrent-neural-networks.md)
21. Embedding Entities and Relations for Learning and Inference in Knowledge Bases
22. First-order versus second-order single-layer recurrent neural networks
23. [Towards End-To-End Speech Recognition with Recurrent Neural Networks](2014-towards-end-to-end-speech-recognition-with-recurrent-neural-networks.md)
24. End-to-end attention-based large vocabulary speech recognition
25. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization.md)
26. EESEN - End-to-end speech recognition using deep RNN models and WFST-based decoding
27. [Deep Residual Learning for Image Recognition](2016-deep-residual-learning-for-image-recognition.md)
28. First-Pass Large Vocabulary Continuous Speech Recognition using Bi-Directional Recurrent DNNs
29. [Teaching Machines to Read and Comprehend](2015-teaching-machines-to-read-and-comprehend.md)
30. [Theano - A Python framework for fast computation of mathematical expressions](2016-theano-a-python-framework-for-fast-computation-of-mathematical-expressions.md)
31. Weighted finite-state transducers in speech recognition
32. Building a Large Annotated Corpus of English - The Penn Treebank
33. An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology
