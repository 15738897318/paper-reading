---
title: TensorFlow - Large-Scale Machine Learning on Heterogeneous Distributed Systems
authors:
- "Mart\xEDn Abadi"
- Ashish Agarwal
- P. Barham
- E. Brevdo
- Z. Chen
- C. Citro
- G. Corrado
- Andy Davis
- J. Dean
- Matthieu Devin
- S. Ghemawat
- Ian J. Goodfellow
- A. Harp
- Geoffrey Irving
- M. Isard
- Yangqing Jia
- "R. J\xF3zefowicz"
- Lukasz Kaiser
- M. Kudlur
- J. Levenberg
- "Dandelion Man\xE9"
- R. Monga
- Sherry Moore
- D. Murray
- C. Olah
- M. Schuster
- Jonathon Shlens
- Benoit Steiner
- Ilya Sutskever
- Kunal Talwar
- P. Tucker
- Vincent Vanhoucke
- Vijay Vasudevan
- "F. Vi\xE9gas"
- Oriol Vinyals
- P. Warden
- M. Wattenberg
- M. Wicke
- Yuan Yu
- Xiaoqiang Zheng
fieldsOfStudy:
- Computer Science
meta_key: 2016-tensorflow-large-scale-machine-learning-on-heterogeneous-distributed-systems
numCitedBy: 9213
reading_status: TBD
ref_count: 70
tags:
- gen-from-ref
- paper
venue: ArXiv
year: 2016
---

# TensorFlow - Large-Scale Machine Learning on Heterogeneous Distributed Systems

## Abstract

TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.

## Paper References

1. Project Adam - Building an Efficient and Scalable Deep Learning Training System
2. [Large Scale Distributed Deep Networks](2012-large-scale-distributed-deep-networks)
3. [Caffe - Convolutional Architecture for Fast Feature Embedding](2014-caffe-convolutional-architecture-for-fast-feature-embedding)
4. An introduction to computational networks and the computational network toolkit (invited talk)
5. [Building high-level features using large scale unsupervised learning](2013-building-high-level-features-using-large-scale-unsupervised-learning)
6. Multilingual acoustic models using distributed deep neural networks
7. cuDNN - Efficient Primitives for Deep Learning
8. On rectified linear units for speech processing
9. [Sequence to Sequence Learning with Neural Networks](2014-sequence-to-sequence-learning-with-neural-networks)
10. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift)
11. [DeViSE - A Deep Visual-Semantic Embedding Model](2013-devise-a-deep-visual-semantic-embedding-model)
12. Pointer Networks
13. Dandelion - a compiler and runtime for heterogeneous systems
14. [Long Short-Term Memory](1997-long-short-term-memory)
15. Massively Multitask Networks for Drug Discovery
16. FlumeJava - easy, efficient data-parallel pipelines
17. Massively Parallel Methods for Deep Reinforcement Learning
18. Dryad - distributed data-parallel programs from sequential building blocks
19. Naiad - a timely dataflow system
20. [Large-Scale Video Classification with Convolutional Neural Networks](2014-large-scale-video-classification-with-convolutional-neural-networks)
21. [Going deeper with convolutions](2015-going-deeper-with-convolutions)
22. Hogwild - A Lock-Free Approach to Parallelizing Stochastic Gradient Descent
23. Halide - a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines
24. Resilient Distributed Datasets - A Fault-Tolerant Abstraction for In-Memory Cluster Computing
25. Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks
26. Pedestrian detection with a Large-Field-Of-View deep network
27. Frame-by-frame language identification in short utterances using deep neural networks
28. [Efficient Estimation of Word Representations in Vector Space](2013-efficient-estimation-of-word-representations-in-vector-space)
29. Learning representations by back-propagating errors
30. Large-scale cluster management at Google with Borg
31. Grammar as a Foreign Language
32. CIEL - A Universal Execution Engine for Distributed Data-Flow Computing
33. Learning representations by backpropagating errors
34. [Deep Neural Networks for Acoustic Modeling in Speech Recognition - The Shared Views of Four Research Groups](2012-deep-neural-networks-for-acoustic-modeling-in-speech-recognition-the-shared-views-of-four-research-groups)
35. Multiple Object Recognition with Visual Attention
36. Move Evaluation in Go Using Deep Convolutional Neural Networks
37. Executing a Program on the MIT Tagged-Token Dataflow Architecture
38. One weird trick for parallelizing convolutional neural networks
39. [The mnist database of handwritten digits](2005-the-mnist-database-of-handwritten-digits)
40. Global code motion/global value numbering
41. A set of level 3 basic linear algebra subprograms
42. Annual review of computer science vol. 1, 1986
43. Torch - a modular machine learning software library
