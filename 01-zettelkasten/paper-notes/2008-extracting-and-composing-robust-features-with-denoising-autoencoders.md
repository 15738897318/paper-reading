---
title: Extracting and composing robust features with denoising autoencoders
authors:
- Pascal Vincent
- H. Larochelle
- Yoshua Bengio
- Pierre-Antoine Manzagol
fieldsOfStudy:
- Computer Science
meta_key: 2008-extracting-and-composing-robust-features-with-denoising-autoencoders
numCitedBy: 5494
reading_status: TBD
ref_count: 39
tags:
- gen-from-ref
- paper
venue: ICML '08
year: 2008
---

# Extracting and composing robust features with denoising autoencoders

## Abstract

Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.

## Paper References

1. Sparse Feature Learning for Deep Belief Networks
2. [Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries](2006-image-denoising-via-sparse-and-redundant-representations-over-learned-dictionaries)
3. Efficient Learning of Sparse Representations with an Energy-Based Model
4. Training with Noise is Equivalent to Tikhonov Regularization
5. [Reducing the Dimensionality of Data with Neural Networks](2006-reducing-the-dimensionality-of-data-with-neural-networks)
6. An empirical evaluation of deep architectures on problems with many factors of variation
7. Fields of Experts - a framework for learning image priors
8. [Greedy Layer-Wise Training of Deep Networks](2006-greedy-layer-wise-training-of-deep-networks)
9. [A Fast Learning Algorithm for Deep Belief Nets](2006-a-fast-learning-algorithm-for-deep-belief-nets)
10. A Machine Learning Framework for Adaptive Combination of Signal Denoising Methods
11. Learning representations by back-propagating errors
12. [Learning Deep Architectures for AI](2007-learning-deep-architectures-for-ai)
13. Scaling learning algorithms towards AI
14. Sparse deep belief net model for visual area V2
15. Non-linear latent factor models for revealing structure in high-dimensional data
16. Connectionist Learning Procedures
17. Many-Layered Learning
18. A Theoretical Analysis of Robust Coding over Noisy Overcomplete Channels
19. Large-scale kernel machines
20. A Theory of Retinal Population Coding
21. Neural networks and physical systems with emergent collective computational abilities.
22. Parallel distributed processing - explorations in the microstructure of cognition, vol. 1 - foundations
23. Parallel Distributed Processing - Explorations in the Microstructure of Cognition, vol 1 - Foundations, vol 2 - Psychological and Biological Models
24. Memoires associatives distribuees - Une comparaison (Distributed associative memories - A comparison)
