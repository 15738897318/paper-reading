---
title: Supervised Learning of Universal Sentence Representations from Natural Language Inference Data
authors:
- A. Conneau
- Douwe Kiela
- Holger Schwenk
- Lo√Øc Barrault
- Antoine Bordes
fieldsOfStudy:
- Computer Science
meta_key: 2017-supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data
numCitedBy: 1528
reading_status: TBD
ref_count: 47
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Supervised-Learning-of-Universal-Sentence-from-Data-Conneau-Kiela/ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c?sort=total-citations
venue: EMNLP
year: 2017
---

[semanticscholar url](https://www.semanticscholar.org/paper/Supervised-Learning-of-Universal-Sentence-from-Data-Conneau-Kiela/ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c?sort=total-citations)

# Supervised Learning of Universal Sentence Representations from Natural Language Inference Data

## Abstract

Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available.

## Paper References

1. [A large annotated corpus for learning natural language inference](2015-a-large-annotated-corpus-for-learning-natural-language-inference)
2. [Learning Distributed Representations of Sentences from Unlabelled Data](2016-learning-distributed-representations-of-sentences-from-unlabelled-data)
3. [Natural Language Processing (Almost) from Scratch](2011-natural-language-processing-almost-from-scratch)
4. Towards Universal Paraphrastic Sentence Embeddings
5. [Skip-Thought Vectors](2015-skip-thought-vectors)
6. [A unified architecture for natural language processing - deep neural networks with multitask learning](2008-a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning)
7. [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](2018-a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference)
8. A Simple but Tough-to-Beat Baseline for Sentence Embeddings
9. Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention
10. [Enriching Word Vectors with Subword Information](2017-enriching-word-vectors-with-subword-information)
11. [Distributed Representations of Sentences and Documents](2014-distributed-representations-of-sentences-and-documents)
12. [Sequence to Sequence Learning with Neural Networks](2014-sequence-to-sequence-learning-with-neural-networks)
13. [Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks](2015-improved-semantic-representations-from-tree-structured-long-short-term-memory-networks)
14. A Neural Probabilistic Language Model
15. SentEval - An Evaluation Toolkit for Universal Sentence Representations
16. [GloVe - Global Vectors for Word Representation](2014-glove-global-vectors-for-word-representation)
17. Self-Adaptive Hierarchical Sentence Model
18. [Distributed Representations of Words and Phrases and their Compositionality](2013-distributed-representations-of-words-and-phrases-and-their-compositionality)
19. [Language Modeling with Gated Convolutional Networks](2017-language-modeling-with-gated-convolutional-networks)
20. Charagram - Embedding Words and Sentences via Character n-grams
21. [On the Properties of Neural Machine Translation - Encoder-Decoder Approaches](2014-on-the-properties-of-neural-machine-translation-encoder-decoder-approaches)
22. [Deep Visual-Semantic Alignments for Generating Image Descriptions](2017-deep-visual-semantic-alignments-for-generating-image-descriptions)
23. Learning Visually Grounded Sentence Representations
24. [Order-Embeddings of Images and Language](2016-order-embeddings-of-images-and-language)
25. Discriminative Improvements to Distributional Sentence Similarity
26. SemEval-2014 Task 10 - Multilingual Semantic Textual Similarity
27. A SICK cure for the evaluation of compositional distributional semantic models
28. A Structured Self-attentive Sentence Embedding
29. Framing Image Description as a Ranking Task - Data, Models and Evaluation Metrics (Extended Abstract)
30. PPDB - The Paraphrase Database
31. [Deep Residual Learning for Image Recognition](2015-resnet.md)
32. [Aligning Books and Movies - Towards Story-Like Visual Explanations by Watching Movies and Reading Books](2015-aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books)
33. [Long Short-Term Memory](1997-long-short-term-memory)
34. The Multiverse Loss for Robust Transfer Learning
35. [VQA - Visual Question Answering](2015-vqa-visual-question-answering)
36. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization)
37. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database)
38. [CNN Features Off-the-Shelf - An Astounding Baseline for Recognition](2014-cnn-features-off-the-shelf-an-astounding-baseline-for-recognition)
39. Multimodal Convolutional Neural Networks for Matching Image and Sentence
40. [Layer Normalization](2016-layer-normalization)
41. [DeepFace - Closing the Gap to Human-Level Performance in Face Verification](2014-deepface-closing-the-gap-to-human-level-performance-in-face-verification)
42. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context)
43. Illinois-LH - A Denotational and Distributional Approach to Semantics
44. How Transferable are Neural Networks in NLP Applications?
