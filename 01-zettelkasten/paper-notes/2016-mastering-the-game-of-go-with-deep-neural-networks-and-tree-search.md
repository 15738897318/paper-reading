---
title: Mastering the game of Go with deep neural networks and tree search
authors:
- David Silver
- Aja Huang
- Chris J. Maddison
- A. Guez
- L. Sifre
- George van den Driessche
- Julian Schrittwieser
- Ioannis Antonoglou
- Vedavyas Panneershelvam
- Marc Lanctot
- S. Dieleman
- Dominik Grewe
- John Nham
- Nal Kalchbrenner
- Ilya Sutskever
- T. Lillicrap
- M. Leach
- K. Kavukcuoglu
- T. Graepel
- D. Hassabis
fieldsOfStudy:
- Computer Science
meta_key: 2016-mastering-the-game-of-go-with-deep-neural-networks-and-tree-search
numCitedBy: 11516
reading_status: TBD
ref_count: 81
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Mastering-the-game-of-Go-with-deep-neural-networks-Silver-Huang/846aedd869a00c09b40f1f1f35673cb22bc87490?sort=total-citations
venue: Nature
year: 2016
---

# Mastering the game of Go with deep neural networks and tree search

## Abstract

The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.

## Paper References

1. Mastering the game of Go without human knowledge
2. Move Evaluation in Go Using Deep Convolutional Neural Networks
3. Training Deep Convolutional Neural Networks to Play Go
4. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play
5. Temporal Difference Learning of Position Evaluation in the Game of Go
6. Temporal-difference search in computer Go
7. Bayesian pattern ranking for move prediction in the game of Go
8. Bootstrapping from Game Tree Search
9. The grand challenge of computer Go
10. Balancing MCTS by Dynamically Adjusting the Komi Value
11. The games computers (and people) play
12. The Power of Forgetting - Improving the Last-Good-Reply Policy in Monte Carlo Go
13. Learning to Play Chess Using Temporal Differences
14. Active Opening Book Application for Monte-Carlo Tree Search in 19×19 Go
15. Computing Elo Ratings of Move Patterns in the Game of Go
16. TD-Gammon, a Self-Teaching Backgammon Program, Achieves Master-Level Play
17. On-line Policy Improvement using Monte-Carlo Search
18. [Reinforcement Learning - An Introduction](2005-reinforcement-learning-an-introduction.md)
19. [Human-level control through deep reinforcement learning](2015-human-level-control-through-deep-reinforcement-learning.md)
20. Monte Carlo Tree Search with heuristic evaluations using implicit minimax backups
21. Games solved - Now and in the future
22. Honte, a go-playing program using neural nets
23. Time Management for Monte-Carlo Tree Search Applied to the Game of Go
24. Fuego-An Open-Source Framework for Board Games and Go Engine Based on Monte Carlo Tree Search
25. Monte-Carlo simulation balancing
26. A Survey of Monte Carlo Tree Search Methods
27. Monte-Carlo Simulation Balancing in Practice
28. Monte-Carlo tree search and rapid action value estimation in computer Go
29. Temporal Difference Learning Applied to a High-Performance Game-Playing Program
30. PACHI - State of the Art Open Source Go Program
31. Evaluation in Go by a Neural Network using Soft Segmentation
32. Markov Games as a Framework for Multi-Agent Reinforcement Learning
33. Combining online and offline knowledge in UCT
34. Deep Blue
35. Monte-Carlo Go Developments
36. [Large Scale Distributed Deep Networks](2012-large-scale-distributed-deep-networks.md)
37. Policy Gradient Methods for Reinforcement Learning with Function Approximation
38. [Simple statistical gradient-following algorithms for connectionist reinforcement learning](2004-simple-statistical-gradient-following-algorithms-for-connectionist-reinforcement-learning.md)
39. Modiﬁcation of UCT with Patterns in Monte-Carlo Go
40. Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search
41. Lessons Learned from AlphaGo
42. Investigating the Limits of Monte-Carlo Tree Search Methods in Computer Go
43. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks.md)
44. Some Studies in Machine Learning Using the Game of Checkers
45. Whole-History Rating - A Bayesian Rating System for Players of Time-Varying Strength
46. Learning to Predict by the Methods of Temporal Differences
47. A Chronology of Computer Chess and its Literature
48. Multi-armed bandits with episode context
49. Deep Learning
50. Where does AlphaGo go - from church-turing thesis to AlphaGo thesis and beyond
51. Face recognition - a convolutional neural-network approach
52. A World Championship Caliber Checkers Program
53. Computational Intelligence in Mind Games
54. From Simple Features to Sophisticated Evaluation Functions
55. On the Scalability of Parallel UCT
56. A Lock-Free Multithreaded Monte-Carlo Tree Search Algorithm
57. Bandit Based Monte-Carlo Planning
58. World-championship-caliber Scrabble
59. An Analysis of Alpha-Beta Pruning
60. Computer Go
61. Artificial Intelligence
62. Faculty Opinions recommendation of Mastering the game of Go with deep neural networks and tree search.
63. 5分で分かる! ? 有名論文ナナメ読み：Silver, D. et al. - Mastering the Game of Go without Human Knowledge
64. All Systems Go
65. Combining Online and Offline Learning in UCT
66. Searching for solutions in games and artificial intelligence
67. Mimicking Go Experts with Convolutional Neural Networks
