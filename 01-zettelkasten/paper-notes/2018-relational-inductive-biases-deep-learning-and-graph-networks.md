---
title: Relational inductive biases, deep learning, and graph networks
authors:
- P. Battaglia
- Jessica B. Hamrick
- V. Bapst
- Alvaro Sanchez-Gonzalez
- V. Zambaldi
- Mateusz Malinowski
- A. Tacchetti
- David Raposo
- Adam Santoro
- R. Faulkner
- "\xC7aglar G\xFCl\xE7ehre"
- H. F. Song
- A. J. Ballard
- J. Gilmer
- George E. Dahl
- Ashish Vaswani
- Kelsey R. Allen
- Charlie Nash
- Victoria Langston
- Chris Dyer
- N. Heess
- Daan Wierstra
- Pushmeet Kohli
- M. Botvinick
- Oriol Vinyals
- Yujia Li
- Razvan Pascanu
fieldsOfStudy:
- Computer Science
meta_key: 2018-relational-inductive-biases-deep-learning-and-graph-networks
numCitedBy: 1563
reading_status: TBD
ref_count: 196
tags:
- gen-from-ref
- other-default
- paper
venue: ArXiv
year: 2018
---

# Relational inductive biases, deep learning, and graph networks

## Abstract

Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. 
The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between "hand-engineering" and "end-to-end" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.

## Paper References

1. [Compositional Attention Networks for Machine Reasoning](2018-compositional-attention-networks-for-machine-reasoning)
2. Relational inductive bias for physical construction in humans and machines
3. Towards Deep Symbolic Reinforcement Learning
4. [Building machines that learn and think like people](2016-building-machines-that-learn-and-think-like-people)
5. [A simple neural network module for relational reasoning](2017-a-simple-neural-network-module-for-relational-reasoning)
6. Relational Deep Reinforcement Learning
7. Relational Neural Expectation Maximization - Unsupervised Discovery of Objects and their Interactions
8. [Graph Attention Networks](2018-graph-attention-networks)
9. Learning Deep Generative Models of Graphs
10. Using Neural Network Formalism to Solve Multiple-Instance Problems
11. Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
12. Schema Networks - Zero-shot Transfer with a Generative Causal Model of Intuitive Physics
13. How to Grow a Mind - Statistics, Structure, and Abstraction
14. Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets
15. [Neural Module Networks](2016-neural-module-networks)
16. Deep Convolutional Networks on Graph-Structured Data
17. [End-To-End Memory Networks](2015-end-to-end-memory-networks)
18. node2vec - Scalable Feature Learning for Networks
19. Geometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs
20. Human-level concept learning through probabilistic program induction
21. [Hybrid computing using a neural network with dynamic external memory](2016-hybrid-computing-using-a-neural-network-with-dynamic-external-memory)
22. Graph networks as learnable physics engines for inference and control
23. [Gated Graph Sequence Neural Networks](2016-gated-graph-sequence-neural-networks)
24. Interaction Networks for Learning about Objects, Relations and Physics
25. Towards a Neural Statistician
26. NerveNet - Learning Structured Policy with Graph Neural Networks
27. Learning to reinforcement learn
28. [Self-Attention with Relative Position Representations](2018-self-attention-with-relative-position-representations)
29. Action Schema Networks - Generalised Policies with Deep Learning
30. Learning to Represent Programs with Graphs
31. Discovering objects and their relations from entangled scene representations
32. [Attention is All you Need](2017-attention-is-all-you-need.md)
33. Learning Explanatory Rules from Noisy Data
34. Can Neural Networks Understand Logical Entailment?
35. Inductive Representation Learning on Large Graphs
36. Adversarial Attacks on Neural Networks for Graph Data
37. [Neural Message Passing for Quantum Chemistry](2017-neural-message-passing-for-quantum-chemistry)
38. Neuro-Symbolic Program Synthesis
39. Deep Models of Interactions Across Sets
40. Geometric Deep Learning - Going beyond Euclidean data
41. [Sequence to Sequence Learning with Neural Networks](2014-sequence-to-sequence-learning-with-neural-networks)
42. Still not systematic after all these years - On the compositional skills of sequence-to-sequence recurrent networks
43. Metacontrol for Adaptive Imagination-Based Optimization
44. Composable Planning with Attributes
45. Attend, Infer, Repeat - Fast Scene Understanding with Generative Models
46. Modular Multitask Reinforcement Learning with Policy Sketches
47. [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](2013-recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank)
48. [Deep learning in neural networks - An overview](2015-deep-learning-in-neural-networks-an-overview)
49. Representation Learning for Visual-Relational Knowledge Graphs
50. Iterative Visual Reasoning Beyond Convolutions
51. Learning to Search with MCTSnets
52. Learning to Transduce with Unbounded Memory
53. MolGAN - An implicit generative model for small molecular graphs
54. Neural Programmer-Interpreters
55. [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](2017-inception-v4-inception-resnet-and-the-impact-of-residual-connections-on-learning)
56. GraphRNN - A Deep Generative Model for Graphs
57. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift)
58. TreeQN and ATreeC - Differentiable Tree Planning for Deep Reinforcement Learning
59. Human-level control through deep reinforcement learning
60. Deep Learning - A Critical Appraisal
61. Innateness, AlphaZero, and Artificial Intelligence
62. Deep Amortized Inference for Probabilistic Programs
63. Failures of Gradient-Based Deep Learning
64. [Effective Approaches to Attention-based Neural Machine Translation](2015-effective-approaches-to-attention-based-neural-machine-translation)
65. Behavior Is Everything - Towards Representing Concepts with Sensorimotor Contingencies
66. Recursive Distributed Representations
67. Differentiable Programs with Neural Libraries
68. Translating Embeddings for Modeling Multi-relational Data
69. Discriminative Embeddings of Latent Variable Models for Structured Data
70. Finding Structure in Time
71. [Dropout - a simple way to prevent neural networks from overfitting](2014-dropout-a-simple-way-to-prevent-neural-networks-from-overfitting)
72. Visual Interaction Networks - Learning a Physics Simulator from Video
73. Learning to Communicate with Deep Multi-Agent Reinforcement Learning
74. subgraph2vec - Learning Distributed Representations of Rooted Sub-graphs from Large Graphs
75. NetGAN - Generating Graphs via Random Walks
76. Neural Relational Inference for Interacting Systems
77. Computational Capabilities of Graph Neural Networks
78. Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution
79. Knowledge Transfer for Out-of-Knowledge-Base Entities - A Graph Neural Network Approach
80. Knowledge Transfer for Out-of-Knowledge-Base Entities - A Graph Neural Network Approach
81. graph2vec - Learning Distributed Representations of Graphs
82. [ImageNet classification with deep convolutional neural networks](2012-alexnet.md)
83. The discovery of structural form
84. Mastering the game of Go with deep neural networks and tree search
85. [Recurrent Models of Visual Attention](2014-recurrent-models-of-visual-attention)
86. Learning model-based planning from scratch
87. Learning a SAT Solver from Single-Bit Supervision
88. Distributed representations, simple recurrent networks, and grammatical structure
89. Fusion, Propagation, and Structuring in Belief Networks
90. A Compositional Object-Based Approach to Learning Physical Dynamics
91. DeepWalk - online learning of social representations
92. DeepStack - Expert-level artificial intelligence in heads-up no-limit poker
93. Inference in Probabilistic Graphical Models by Graph Neural Networks
94. [The Graph Neural Network Model](2009-the-graph-neural-network-model)
95. [Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks](2015-improved-semantic-representations-from-tree-structured-long-short-term-memory-networks)
96. Learning Continuous Semantic Representations of Symbolic Expressions
97. Non-local Neural Networks
98. Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs
99. [Spectral Networks and Locally Connected Networks on Graphs](2014-spectral-networks-and-locally-connected-networks-on-graphs)
100. Learning to See Physics via Visual De-animation
101. Probabilistic models of cognition - exploring representations and inductive biases
102. [Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering](2016-convolutional-neural-networks-on-graphs-with-fast-localized-spectral-filtering)
103. Semantic Code Repair using Neuro-Symbolic Transformation Networks
104. Mapping Part-Whole Hierarchies into Connectionist Networks
105. Learning Convolutional Neural Networks for Graphs
106. A new model for learning in graph domains
107. Hyperbolic Attention Networks
108. Probabilistic reasoning in intelligent systems - networks of plausible inference
109. The Need for Biases in Learning Generalizations
110. [Parsing Natural Scenes and Natural Language with Recursive Neural Networks](2011-parsing-natural-scenes-and-natural-language-with-recursive-neural-networks)
111. Relation Networks for Object Detection
112. Attention Solves Your TSP
113. [Neural Machine Translation by Jointly Learning to Align and Translate](2015-neural-machine-translation-by-jointly-learning-to-align-and-translate)
114. LINE - Large-scale Information Network Embedding
115. Learning Combinatorial Optimization Algorithms over Graphs
116. Hierarchical Representations for Efficient Architecture Search
117. [GloVe - Global Vectors for Word Representation](2014-glove-global-vectors-for-word-representation)
118. [Linguistic Regularities in Continuous Space Word Representations](2013-linguistic-regularities-in-continuous-space-word-representations)
119. On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups
120. Learning Multiagent Communication with Backpropagation
121. Deep Sets
122. Acquisition of cognitive skill.
123. [Semantic Compositionality through Recursive Matrix-Vector Spaces](2012-semantic-compositionality-through-recursive-matrix-vector-spaces)
124. Probabilistic machine learning and artificial intelligence
125. [Layer Normalization](2016-layer-normalization)
126. Diffusion Convolutional Recurrent Neural Network - Data-Driven Traffic Forecasting
127. Learning Graph Representations with Embedding Propagation
128. Prefrontal cortex as a meta-reinforcement learning system
129. Tree-to-tree Neural Networks for Program Translation
130. [Semi-Supervised Classification with Graph Convolutional Networks](2017-semi-supervised-classification-with-graph-convolutional-networks)
131. Graph neural networks for ranking Web pages
132. Dynamic Routing Between Capsules
133. [Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions](2011-semi-supervised-recursive-autoencoders-for-predicting-sentiment-distributions)
134. Connectionism and cognitive architecture - A critical analysis
135. [Probabilistic Graphical Models - Principles and Techniques](2009-probabilistic-graphical-models-principles-and-techniques)
136. High-Order Graph Convolutional Recurrent Neural Network - A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting
137. Neural Networks and the Bias/Variance Dilemma
138. Group Equivariant Convolutional Networks
139. Structure mapping in analogy and similarity.
140. On language and connectionism - Analysis of a parallel distributed processing model of language acquisition
141. PointNet - Deep Learning on Point Sets for 3D Classification and Segmentation
142. A symbolic-connectionist theory of relational inference and generalization.
143. A Structured Self-attentive Sentence Embedding
144. [Dynamic Graph CNN for Learning on Point Clouds](2019-dynamic-graph-cnn-for-learning-on-point-clouds)
145. [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](2014-learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation)
146. Theory-based Bayesian models of inductive learning and reasoning
147. Church - a language for generative models
148. Weisfeiler-Lehman Graph Kernels
149. [Neocognitron - A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position](2004-neocognitron-a-self-organizing-neural-network-model-for-a-mechanism-of-pattern-recognition-unaffected-by-shift-in-position)
150. Simulation as an engine of physical scene understanding
151. Molecular graph convolutions - moving beyond fingerprints
152. [Convolutional Networks on Graphs for Learning Molecular Fingerprints](2015-convolutional-networks-on-graphs-for-learning-molecular-fingerprints)
153. Forest before trees - The precedence of global features in visual perception
154. Core knowledge.
155. A simple rule for the evolution of cooperation on graphs and social networks
156. How to Build a Brain - A Neural Architecture for Biological Cognition
157. Backpropagation Applied to Handwritten Zip Code Recognition
158. Neural Combinatorial Optimization with Reinforcement Learning
159. VAIN - Attentional Multi-agent Predictive Modeling
160. Transition-Based Dependency Parsing with Stack Long Short-Term Memory
161. Reasoning about relations.
162. Understanding normal and impaired word reading - computational principles in quasi-regular domains.
163. Holographic reduced representations
164. Hierarchical models of behavior and prefrontal function
165. Mind Games - Game Engines as an Architecture for Intuitive Physics
166. LANGUAGE OF THOUGHT
167. PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS
168. The Nature of Explanation
169. Artificial intelligence - a modern approach, 2nd Edition
170. Bayesian Nonparametrics I
171. Origins of knowledge.
172. Aspects of the Theory of Syntax
173. On language - on the diversity of human language construction and its influence on the mental development of the human species
174. Concepts in a Probabilistic Language of Thought
175. Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems
176. Causality - Models, Reasoning and Inference
177. STRIPS - A New Approach to the Application of Theorem Proving to Problem Solving
178. Five Rules for the Evolution of Cooperation
179. On the new Riddle of induction
180. An interactive activation model of context effects in letter perception - I. An account of basic findings.
181. Introduction to Statistical Relational Learning
182. Principles of neurodynamics
183. The interaction of nature and nurture.
184. Few-Shot Learning with Graph Neural Networks
185. From Skills to Symbols - Learning Symbolic Representations for Abstract High-Level Planning
186. Covariant Compositional Networks For Learning Graphs
187. A Note on Learning Algorithms for Quadratic Assignment with Graph Neural Networks
188. Learning Graphical State Transitions
189. [Parallel & distributed processing](2005-parallel-distributed-processing)
190. [Deep Learning](2016-deep-learning)
191. Neural Random Access Machines
192. Relational Reinforcement Learning
