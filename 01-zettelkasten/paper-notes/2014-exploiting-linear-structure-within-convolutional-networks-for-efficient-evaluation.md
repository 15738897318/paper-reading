---
title: Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation
authors:
- Emily L. Denton
- Wojciech Zaremba
- Joan Bruna
- Yann LeCun
- R. Fergus
fieldsOfStudy:
- Computer Science
meta_key: 2014-exploiting-linear-structure-within-convolutional-networks-for-efficient-evaluation
numCitedBy: 1281
reading_status: TBD
ref_count: 16
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Exploiting-Linear-Structure-Within-Convolutional-Denton-Zaremba/e5ae8ab688051931b4814f6d32b18391f8d1fa8d?sort=total-citations
venue: NIPS
year: 2014
---

# Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation

## Abstract

We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy, but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the redundancy present within the convolutional filters to derive approximations that significantly reduce the required computation. Using large state-of-the-art models, we demonstrate speedups of convolutional layers on both CPU and GPU by a factor of 2 x, while keeping the accuracy within 1% of the original model.

## Paper References

1. [Speeding up Convolutional Neural Networks with Low Rank Expansions](2014-speeding-up-convolutional-neural-networks-with-low-rank-expansions.md)
2. Fast Training of Convolutional Networks through FFTs
3. [OverFeat - Integrated Recognition, Localization and Detection using Convolutional Networks](2014-overfeat-integrated-recognition-localization-and-detection-using-convolutional-networks.md)
4. [Visualizing and Understanding Convolutional Networks](2014-visualizing-and-understanding-convolutional-networks.md)
5. Improving the speed of neural networks on CPUs
6. [Adaptive deconvolutional networks for mid and high level feature learning](2011-adaptive-deconvolutional-networks-for-mid-and-high-level-feature-learning.md)
7. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks.md)
8. Tiled convolutional neural networks
9. [Building high-level features using large scale unsupervised learning](2013-building-high-level-features-using-large-scale-unsupervised-learning.md)
10. [Predicting Parameters in Deep Learning](2013-predicting-parameters-in-deep-learning.md)
11. [Improving neural networks by preventing co-adaptation of feature detectors](2012-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors.md)
12. [Object recognition from local scale-invariant features](1999-object-recognition-from-local-scale-invariant-features.md)
13. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database.md)
14. Rank-One Approximation to High Order Tensors
15. Visualizing and Understanding Convolutional Neural Networks
