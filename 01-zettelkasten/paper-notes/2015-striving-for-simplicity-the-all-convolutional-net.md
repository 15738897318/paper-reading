---
title: Striving for Simplicity - The All Convolutional Net
authors:
- Jost Tobias Springenberg
- A. Dosovitskiy
- T. Brox
- Martin A. Riedmiller
fieldsOfStudy:
- Computer Science
meta_key: 2015-striving-for-simplicity-the-all-convolutional-net
numCitedBy: 3293
reading_status: TBD
ref_count: 31
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Striving-for-Simplicity:-The-All-Convolutional-Net-Springenberg-Dosovitskiy/0f84a81f431b18a78bd97f59ed4b9d8eda390970?sort=total-citations
venue: ICLR
year: 2015
---

# Striving for Simplicity - The All Convolutional Net

## Abstract

Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.

## Paper References

1. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2014-vggnet.md)
2. [ImageNet classification with deep convolutional neural networks](2012-alexnet.md)
3. [Network In Network](2014-network-in-network)
4. [Deeply-Supervised Nets](2015-deeply-supervised-nets)
5. [Going deeper with convolutions](2015-going-deeper-with-convolutions)
6. Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks
7. Fractional Max-Pooling
8. [Visualizing and Understanding Convolutional Networks](2014-visualizing-and-understanding-convolutional-networks)
9. High-Performance Neural Networks for Visual Object Classification
10. [Learning Multiple Layers of Features from Tiny Images](2009-learning-multiple-layers-of-features-from-tiny-images)
11. Deep Networks with Internal Selective Attention through Feedback Connections
12. [Caffe - Convolutional Architecture for Fast Feature Embedding](2014-caffe-convolutional-architecture-for-fast-feature-embedding)
13. Stochastic Pooling for Regularization of Deep Convolutional Neural Networks
14. [Deep Inside Convolutional Networks - Visualising Image Classification Models and Saliency Maps](2014-deep-inside-convolutional-networks-visualising-image-classification-models-and-saliency-maps)
15. Improving Deep Neural Networks with Probabilistic Maxout Units
16. Beyond spatial pyramids - Receptive field learning for pooled image features
17. Discriminative Transfer Learning with Tree-based Priors
18. What is the best multi-stage architecture for object recognition?
19. [Dropout - a simple way to prevent neural networks from overfitting](2014-dropout-a-simple-way-to-prevent-neural-networks-from-overfitting)
20. [Gradient-based learning applied to document recognition](1998-lenet5.md)
21. [Regularization of Neural Networks using DropConnect](2013-regularization-of-neural-networks-using-dropconnect)
22. [Improving neural networks by preventing co-adaptation of feature detectors](2012-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors)
23. [Maxout Networks](2013-maxout-networks)
24. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database)
25. Signal recovery from Pooling Representations
26. [Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks](2016-under-review-as-a-conference-paper-at-iclr-2017-delving-into-transferable-adversarial-ex-amples-and-black-box-attacks)
27. Hierarchical Neural Networks for Image Interpretation
28. Compete to Compute
