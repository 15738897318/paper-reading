---
title: Grounding of Textual Phrases in Images by Reconstruction
authors:
- Anna Rohrbach
- Marcus Rohrbach
- Ronghang Hu
- Trevor Darrell
- B. Schiele
fieldsOfStudy:
- Computer Science
meta_key: 2016-grounding-of-textual-phrases-in-images-by-reconstruction
numCitedBy: 381
reading_status: TBD
ref_count: 63
tags:
- gen-from-ref
- other-default
- paper
venue: ECCV
year: 2016
---

# Grounding of Textual Phrases in Images by Reconstruction

## Abstract

Grounding (i.e. localizing) arbitrary, free-form textual phrases in visual content is a challenging problem with many applications for human-computer interaction and image-text reference resolution. Few datasets provide the ground truth spatial localization of phrases, thus it is desirable to learn from data with no or little grounding supervision. We propose a novel approach which learns grounding by reconstructing a given phrase using an attention mechanism, which can be either latent or optimized directly. During training our approach encodes the phrase using a recurrent network language model and then learns to attend to the relevant image region in order to reconstruct the input phrase. At test time, the correct attention, i.e., the grounding, is evaluated. If grounding supervision is available it can be directly applied via a loss over the attention mechanism. We demonstrate the effectiveness of our approach on the Flickr 30k Entities and ReferItGame datasets with different levels of supervision, ranging from no supervision over partial supervision to full supervision. Our supervised variant improves by a large margin over the state-of-the-art on both datasets.

## Paper References

1. Weakly-Supervised Alignment of Video with Text
2. [Show and tell - A neural image caption generator](2015-show-and-tell-a-neural-image-caption-generator)
3. Aligning where to see and what to tell - image caption with region-based attention and scene factorization
4. [Deep Visual-Semantic Alignments for Generating Image Descriptions](2017-deep-visual-semantic-alignments-for-generating-image-descriptions)
5. Learning Everything about Anything - Webly-Supervised Visual Concept Learning
6. Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections
7. Flickr30k Entities - Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models
8. Mind's eye - A recurrent visual representation for image caption generation
9. Simultaneous Object Detection and Ranking with Weak Supervision
10. Describing Videos by Exploiting Temporal Structure
11. [Natural Language Object Retrieval](2016-natural-language-object-retrieval)
12. [Learning Deep Structure-Preserving Image-Text Embeddings](2016-learning-deep-structure-preserving-image-text-embeddings)
13. Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
14. What Are You Talking About? Text-to-Image Coreference
15. VisKE - Visual knowledge extraction and question answering by visual verification of relation phrases
16. [Aligning Books and Movies - Towards Story-Like Visual Explanations by Watching Movies and Reading Books](2015-aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books)
17. [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](2015-show-attend-and-tell-neural-image-caption-generation-with-visual-attention)
18. Open-vocabulary Object Retrieval
19. Sentence Directed Video Object Codetection
20. [Long-term recurrent convolutional networks for visual recognition and description](2015-long-term-recurrent-convolutional-networks-for-visual-recognition-and-description)
21. Grounding Action Descriptions in Videos
22. [Sequence to Sequence Learning with Neural Networks](2014-sequence-to-sequence-learning-with-neural-networks)
23. Jointly Learning to Parse and Perceive - Connecting Natural Language to the Physical World
24. Multi-fold MIL Training for Weakly Supervised Object Localization
25. Conditional Random Field Autoencoders for Unsupervised Structured Prediction
26. Visual Semantic Search - Retrieving Videos via Complex Textual Queries
27. On learning to localize objects with minimal supervision
28. Book2Movie - Aligning video scenes with book chapters
29. Co-localization in Real-World Images
30. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context)
31. Unsupervised Object Discovery and Tracking in Video Collections
32. Webly Supervised Learning of Convolutional Networks
33. [Delving Deep into Rectifiers - Surpassing Human-Level Performance on ImageNet Classification](2015-delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification)
34. [Neural Machine Translation by Jointly Learning to Align and Translate](2015-neural-machine-translation-by-jointly-learning-to-align-and-translate)
35. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database)
36. Every Moment Counts - Dense Detailed Labeling of Actions in Complex Videos
37. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2014-vggnet.md)
38. Image retrieval using scene graphs
39. Grounded Language Learning from Video Described with Sentences
40. [Selective Search for Object Recognition](2013-selective-search-for-object-recognition)
41. Efficient Image and Video Co-localization with Frank-Wolfe Algorithm
42. A Joint Model of Language and Perception for Grounded Attribute Learning
43. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization)
44. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift)
45. [Extracting and composing robust features with denoising autoencoders](2008-extracting-and-composing-robust-features-with-denoising-autoencoders)
46. The New Data and New Challenges in Multimedia Research
47. [Caffe - Convolutional Architecture for Fast Feature Embedding](2014-caffe-convolutional-architecture-for-fast-feature-embedding)
48. What's Cookin'? Interpreting Cooking Videos using Text, Speech and Vision
49. [Long Short-Term Memory](1997-long-short-term-memory)
50. [The Pascal Visual Object Classes (VOC) Challenge](2009-the-pascal-visual-object-classes-voc-challenge)
51. [From image descriptions to visual denotations - New similarity metrics for semantic inference over event descriptions](2014-from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions)
52. [Edge Boxes - Locating Object Proposals from Edges](2014-edge-boxes-locating-object-proposals-from-edges)
53. [Understanding the difficulty of training deep feedforward neural networks](2010-understanding-the-difficulty-of-training-deep-feedforward-neural-networks)
54. [Fast R-CNN](2015-fast-r-cnn)
55. ReferItGame - Referring to Objects in Photographs of Natural Scenes
56. International Conference on Computer Vision (ICCV 2017)
57. [Generation and Comprehension of Unambiguous Object Descriptions](2016-generation-and-comprehension-of-unambiguous-object-descriptions)
