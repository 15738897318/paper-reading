---
title: Recurrent Batch Normalization
authors:
- Tim Cooijmans
- Nicolas Ballas
- "C\xE9sar Laurent"
- Aaron C. Courville
fieldsOfStudy:
- Computer Science
meta_key: 2017-recurrent-batch-normalization
numCitedBy: 344
reading_status: TBD
ref_count: 36
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Recurrent-Batch-Normalization-Cooijmans-Ballas/952454718139dba3aafc6b3b67c4f514ac3964af?sort=total-citations
venue: ICLR
year: 2017
---

# Recurrent Batch Normalization

## Abstract

We propose a reparameterization of LSTM that brings the benefits of batch normalization to recurrent neural networks. Whereas previous works only apply batch normalization to the input-to-hidden transformation of RNNs, we demonstrate that it is both possible and beneficial to batch-normalize the hidden-to-hidden transition, thereby reducing internal covariate shift between time steps. We evaluate our proposal on various sequential problems such as sequence classification, language modeling and question answering. Our empirical results show that our batch-normalized LSTM consistently leads to faster convergence and improved generalization.

## Paper References

1. Batch normalized recurrent neural networks
2. A Simple Way to Initialize Recurrent Networks of Rectified Linear Units
3. [Zoneout - Regularizing RNNs by Randomly Preserving Hidden Activations](2017-zoneout-regularizing-rnns-by-randomly-preserving-hidden-activations.md)
4. Regularizing RNNs by Stabilizing Activations
5. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
6. Unitary Evolution Recurrent Neural Networks
7. [Layer Normalization](2016-layer-normalization.md)
8. Learning long-term dependencies with gradient descent is difficult
9. Regularization and nonlinearities for neural language models - when are they needed?
10. [On the difficulty of training recurrent neural networks](2013-on-the-difficulty-of-training-recurrent-neural-networks.md)
11. Learning Recurrent Neural Networks with Hessian-Free Optimization
12. SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS
13. Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex
14. Architectural Complexity Measures of Recurrent Neural Networks
15. [Hierarchical Multiscale Recurrent Neural Networks](2017-hierarchical-multiscale-recurrent-neural-networks.md)
16. [Teaching Machines to Read and Comprehend](2015-teaching-machines-to-read-and-comprehend.md)
17. [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](2014-learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation.md)
18. [Long Short-Term Memory](1997-long-short-term-memory.md)
19. Describing Videos by Exploiting Temporal Structure
20. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization.md)
21. [Deep Speech 2 - End-to-End Speech Recognition in English and Mandarin](2016-deep-speech-2-end-to-end-speech-recognition-in-english-and-mandarin.md)
22. [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](2015-show-attend-and-tell-neural-image-caption-generation-with-visual-attention.md)
23. [Neural Machine Translation by Jointly Learning to Align and Translate](2015-neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
24. Persistent Contextual Neural Networks for learning symbolic data sequences
25. [Theano - new features and speed improvements](2012-theano-new-features-and-speed-improvements.md)
26. [Generating Sequences With Recurrent Neural Networks](2013-generating-sequences-with-recurrent-neural-networks.md)
27. Blocks and Fuel - Frameworks for deep learning
28. [Published as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS](2018-published-as-a-conference-paper-at-iclr-2018-s-imulating-a-ction-d-ynamics-with-n-eural-p-rocess-n-etworks.md)
29. [Theano - A Python framework for fast computation of mathematical expressions](2016-theano-a-python-framework-for-fast-computation-of-mathematical-expressions.md)
30. Building a Large Annotated Corpus of English - The Penn Treebank
31. Improving predictive inference under covariate shift by weighting the log-likelihood function
32. Untersuchungen zu dynamischen neuronalen Netzen
