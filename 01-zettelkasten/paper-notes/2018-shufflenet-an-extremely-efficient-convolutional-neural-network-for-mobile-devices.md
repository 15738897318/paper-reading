---
title: ShuffleNet - An Extremely Efficient Convolutional Neural Network for Mobile Devices
authors:
- X. Zhang
- Xinyu Zhou
- Mengxiao Lin
- Jian Sun
fieldsOfStudy:
- Computer Science
meta_key: 2018-shufflenet-an-extremely-efficient-convolutional-neural-network-for-mobile-devices
numCitedBy: 3251
reading_status: TBD
ref_count: 53
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/ShuffleNet:-An-Extremely-Efficient-Convolutional-Zhang-Zhou/9da734397acd7ff7c557960c62fb1b400b27bd89?sort=total-citations
venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition
year: 2018
---

[semanticscholar url](https://www.semanticscholar.org/paper/ShuffleNet:-An-Extremely-Efficient-Convolutional-Zhang-Zhou/9da734397acd7ff7c557960c62fb1b400b27bd89?sort=total-citations)

# ShuffleNet - An Extremely Efficient Convolutional Neural Network for Mobile Devices

## Abstract

We introduce an extremely computation-efficient CNN architecture named ShuffleNet, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs). The new architecture utilizes two new operations, pointwise group convolution and channel shuffle, to greatly reduce computation cost while maintaining accuracy. Experiments on ImageNet classification and MS COCO object detection demonstrate the superior performance of ShuffleNet over other structures, e.g. lower top-1 error (absolute 7.8%) than recent MobileNet [12] on ImageNet classification task, under the computation budget of 40 MFLOPs. On an ARM-based mobile device, ShuffleNet achieves ~13Ã— actual speedup over AlexNet while maintaining comparable accuracy.

## Paper References

1. Quantized Convolutional Neural Networks for Mobile Devices
2. [MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications](2017-mobilenets-efficient-convolutional-neural-networks-for-mobile-vision-applications.md)
3. LCNN - Lookup-Based Convolutional Neural Network
4. [XNOR-Net - ImageNet Classification Using Binary Convolutional Neural Networks](2016-xnor-net-imagenet-classification-using-binary-convolutional-neural-networks.md)
5. Fast Convolutional Nets With fbfft - A GPU Performance Evaluation
6. [Speeding up Convolutional Neural Networks with Low Rank Expansions](2014-speeding-up-convolutional-neural-networks-with-low-rank-expansions.md)
7. Convolutional neural networks at constrained time cost
8. PVANET - Deep but Lightweight Neural Networks for Real-time Object Detection
9. [Accelerating Very Deep Convolutional Networks for Classification and Detection](2016-accelerating-very-deep-convolutional-networks-for-classification-and-detection.md)
10. Flattened Convolutional Neural Networks for Feedforward Acceleration
11. Fast Training of Convolutional Networks through FFTs
12. [Going deeper with convolutions](2015-going-deeper-with-convolutions.md)
13. Deep Roots - Improving CNN Efficiency with Hierarchical Filter Groups
14. Learning Structured Sparsity in Deep Neural Networks
15. [Rethinking the Inception Architecture for Computer Vision](2016-rethinking-the-inception-architecture-for-computer-vision.md)
16. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2015-very-deep-convolutional-networks-for-large-scale-image-recognition.md)
17. [DoReFa-Net - Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients](2016-dorefa-net-training-low-bitwidth-convolutional-neural-networks-with-low-bitwidth-gradients.md)
18. [Learning Transferable Architectures for Scalable Image Recognition](2018-learning-transferable-architectures-for-scalable-image-recognition.md)
19. Efficient and accurate approximations of nonlinear convolutional networks
20. [Xception - Deep Learning with Depthwise Separable Convolutions](2017-xception-deep-learning-with-depthwise-separable-convolutions.md)
21. [Caffe - Convolutional Architecture for Fast Feature Embedding](2014-caffe-convolutional-architecture-for-fast-feature-embedding.md)
22. [Deep Compression - Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding](2016-deep-compression-compressing-deep-neural-network-with-pruning-trained-quantization-and-huffman-coding.md)
23. Incremental Network Quantization - Towards Lossless CNNs with Low-Precision Weights
24. [SqueezeNet - AlexNet-level accuracy with 50x fewer parameters and <1MB model size](2016-squeezenet-alexnet-level-accuracy-with-50x-fewer-parameters-and-1mb-model-size.md)
25. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks.md)
26. Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition
27. Design of Efficient Convolutional Layers using Single Intra-channel Convolution, Topological Subdivisioning and Spatial Bottleneck Structure
28. [Aggregated Residual Transformations for Deep Neural Networks](2017-aggregated-residual-transformations-for-deep-neural-networks.md)
29. Swish - a Self-Gated Activation Function
30. [Learning both Weights and Connections for Efficient Neural Network](2015-learning-both-weights-and-connections-for-efficient-neural-network.md)
31. Interleaved Group Convolutions for Deep Neural Networks
32. [Squeeze-and-Excitation Networks](2020-squeeze-and-excitation-networks.md)
33. [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](2015-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.md)
34. [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](2017-inception-v4-inception-resnet-and-the-impact-of-residual-connections-on-learning.md)
35. [Deep Residual Learning for Image Recognition](2016-deep-residual-learning-for-image-recognition.md)
36. [Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation](2014-rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.md)
37. [Fully Convolutional Networks for Semantic Segmentation](2017-fully-convolutional-networks-for-semantic-segmentation.md)
38. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
39. [TensorFlow - Large-Scale Machine Learning on Heterogeneous Distributed Systems](2016-tensorflow-large-scale-machine-learning-on-heterogeneous-distributed-systems.md)
40. [Identity Mappings in Deep Residual Networks](2016-identity-mappings-in-deep-residual-networks.md)
41. Searching for Activation Functions
42. [Show and tell - A neural image caption generator](2015-show-and-tell-a-neural-image-caption-generator.md)
43. [ImageNet Large Scale Visual Recognition Challenge](2015-imagenet-large-scale-visual-recognition-challenge.md)
44. [Distilling the Knowledge in a Neural Network](2015-distilling-the-knowledge-in-a-neural-network.md)
45. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context.md)
46. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database.md)
47. Expectation Backpropagation - Parameter-Free Training of Multilayer Neural Networks with Continuous or Discrete Weights
48. Et al
