---
title: NetAdapt - Platform-Aware Neural Network Adaptation for Mobile Applications
authors:
- Tien-Ju Yang
- Andrew G. Howard
- Bo Chen
- Xiao Zhang
- Alec Go
- V. Sze
- Hartwig Adam
fieldsOfStudy:
- Computer Science
meta_key: 2018-netadapt-platform-aware-neural-network-adaptation-for-mobile-applications
numCitedBy: 324
reading_status: TBD
ref_count: 31
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/NetAdapt:-Platform-Aware-Neural-Network-Adaptation-Yang-Howard/d16b21f3e99171c86365679435f9f03766750639?sort=total-citations
venue: ECCV
year: 2018
---

# NetAdapt - Platform-Aware Neural Network Adaptation for Mobile Applications

## Abstract

This work proposes an algorithm, called NetAdapt, that automatically adapts a pre-trained deep neural network to a mobile platform given a resource budget. While many existing algorithms simplify networks based on the number of MACs or weights, optimizing those indirect metrics may not necessarily reduce the direct metrics, such as latency and energy consumption. To solve this problem, NetAdapt incorporates direct metrics into its adaptation algorithm. These direct metrics are evaluated using empirical measurements, so that detailed knowledge of the platform and toolchain is not required. NetAdapt automatically and progressively simplifies a pre-trained network until the resource budget is met while maximizing the accuracy. Experiment results show that NetAdapt achieves better accuracy versus latency trade-offs on both mobile CPU and mobile GPU, compared with the state-of-the-art automated network simplification algorithms. For image classification on the ImageNet dataset, NetAdapt achieves up to a 1.7$\times$ speedup in measured inference latency with equal or higher accuracy on MobileNets (V1&V2).

## Paper References

1. [AMC - AutoML for Model Compression and Acceleration on Mobile Devices](2018-amc-automl-for-model-compression-and-acceleration-on-mobile-devices.md)
2. A method to estimate the energy consumption of deep neural networks
3. [Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications](2016-compression-of-deep-convolutional-neural-networks-for-fast-and-low-power-mobile-applications.md)
4. Designing Energy-Efficient Convolutional Neural Networks Using Energy-Aware Pruning
5. Scalpel - Customizing DNN pruning to the underlying hardware parallelism
6. [ShuffleNet - An Extremely Efficient Convolutional Neural Network for Mobile Devices](2018-shufflenet-an-extremely-efficient-convolutional-neural-network-for-mobile-devices.md)
7. Not All Ops Are Created Equal!
8. [Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference](2018-quantization-and-training-of-neural-networks-for-efficient-integer-arithmetic-only-inference.md)
9. [Learning both Weights and Connections for Efficient Neural Network](2015-learning-both-weights-and-connections-for-efficient-neural-network.md)
10. Network Trimming - A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures
11. ADC - Automated Deep Compression and Acceleration with Reinforcement Learning
12. Efficient Processing of Deep Neural Networks - A Tutorial and Survey
13. Eyeriss - a spatial architecture for energy-efficient dataflow for convolutional neural networks
14. [XNOR-Net - ImageNet Classification Using Binary Convolutional Neural Networks](2016-xnor-net-imagenet-classification-using-binary-convolutional-neural-networks.md)
15. Pruning Convolutional Neural Networks for Resource Efficient Inference
16. [MobileNetV2 - Inverted Residuals and Linear Bottlenecks](2018-mobilenetv2-inverted-residuals-and-linear-bottlenecks.md)
17. [MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications](2017-mobilenets-efficient-convolutional-neural-networks-for-mobile-vision-applications.md)
18. Binarized Neural Networks
19. Pruning Convolutional Neural Networks for Resource Efficient Transfer Learning
20. Hierarchical Compression of Deep Convolutional Neural Networks on Large Scale Visual Recognition for Mobile Applications
21. Data-free Parameter Pruning for Deep Neural Networks
22. [Deep Residual Learning for Image Recognition](2016-deep-residual-learning-for-image-recognition.md)
23. MorphNet - Fast & Simple Resource-Constrained Structure Learning of Deep Networks
24. Deep Fried Convnets
25. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2015-very-deep-convolutional-networks-for-large-scale-image-recognition.md)
26. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database.md)
27. A Progressive Barrier for Derivative-Free Nonlinear Programming
28. Optimal Brain Damage
29. [Inverted Residuals and Linear Bottlenecks - Mobile Networks for Classification, Detection and Segmentation](2018-inverted-residuals-and-linear-bottlenecks-mobile-networks-for-classification-detection-and-segmentation.md)
30. Eyeriss - An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks
