---
title: Linking Image and Text with 2-Way Nets
authors:
- Aviv Eisenschtat
- Lior Wolf
fieldsOfStudy:
- Computer Science
meta_key: 2017-linking-image-and-text-with-2-way-nets
numCitedBy: 135
reading_status: TBD
ref_count: 60
tags:
- gen-from-ref
- other-default
- paper
venue: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2017
---

# Linking Image and Text with 2-Way Nets

## Abstract

Linking two data sources is a basic building block in numerous computer vision problems. Canonical Correlation Analysis (CCA) achieves this by utilizing a linear optimizer in order to maximize the correlation between the two views. Recent work makes use of non-linear models, including deep learning techniques, that optimize the CCA loss in some feature space. In this paper, we introduce a novel, bi-directional neural network architecture for the task of matching vectors from two data sources. Our approach employs two tied neural network channels that project the two views into a common, maximally correlated space using the Euclidean loss. We show a direct link between the correlation-based loss and Euclidean loss, enabling the use of Euclidean loss for correlation maximization. To overcome common Euclidean regression optimization problems, we modify well-known techniques to our problem, including batch normalization and dropout. We show state of the art results on a number of computer vision matching tasks including MNIST image matching and sentence-image matching on the Flickr8k, Flickr30k and COCO datasets.

## Paper References

1. [Learning Deep Structure-Preserving Image-Text Embeddings](2016-learning-deep-structure-preserving-image-text-embeddings)
2. Deep correlation for matching images and text
3. Associating neural word embeddings with deep image representations using Fisher Vectors
4. [Show and tell - A neural image caption generator](2015-show-and-tell-a-neural-image-caption-generator)
5. [Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models](2014-unifying-visual-semantic-embeddings-with-multimodal-neural-language-models)
6. Explain Images with Multimodal Recurrent Neural Networks
7. Framing Image Description as a Ranking Task - Data, Models and Evaluation Metrics (Extended Abstract)
8. Deep Canonical Correlation Analysis
9. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2014-vggnet.md)
10. Generalized Multiview Analysis - A discriminative latent space
11. Multimodal Convolutional Neural Networks for Matching Image and Sentence
12. Canonical Correlation Analysis of Video Volume Tensors for Action Categorization and Detection
13. On Deep Multi-View Representation Learning
14. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift)
15. [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](2015-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks)
16. Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition
17. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context)
18. [Dropout - a simple way to prevent neural networks from overfitting](2014-dropout-a-simple-way-to-prevent-neural-networks-from-overfitting)
19. Correlational Neural Networks
20. Nonparametric Canonical Correlation Analysis
21. [Delving Deep into Rectifiers - Surpassing Human-Level Performance on ImageNet Classification](2015-delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification)
22. Leveraging Visual Question Answering for Image-Caption Ranking
23. [Identity Mappings in Deep Residual Networks](2016-identity-mappings-in-deep-residual-networks)
24. [Stacked Denoising Autoencoders - Learning Useful Representations in a Deep Network with a Local Denoising Criterion](2010-stacked-denoising-autoencoders-learning-useful-representations-in-a-deep-network-with-a-local-denoising-criterion)
25. [Multimodal Deep Learning](2011-multimodal-deep-learning)
26. [Greedy Layer-Wise Training of Deep Networks](2006-greedy-layer-wise-training-of-deep-networks)
27. Cross-scene crowd counting via deep convolutional neural networks
28. [Extracting and composing robust features with denoising autoencoders](2008-extracting-and-composing-robust-features-with-denoising-autoencoders)
29. Reducing Overfitting in Deep Networks by Decorrelating Representations
30. RNN Fisher Vectors for Action Recognition and Image Annotation
31. Multimodal human behavior analysis - learning correlation and interaction across modalities
32. Autoencoders, Minimum Description Length and Helmholtz Free Energy
33. Nonlinear Feature Extraction Using Generalized Canonical Correlation Analysis
34. [Reducing the Dimensionality of Data with Neural Networks](2006-reducing-the-dimensionality-of-data-with-neural-networks)
35. Kernel independent component analysis
36. A kernel method for canonical correlation analysis
37. [Rectified Linear Units Improve Restricted Boltzmann Machines](2010-rectified-linear-units-improve-restricted-boltzmann-machines)
38. Live Repetition Counting
39. Relations Between Two Sets of Variates
40. [Rectifier Nonlinearities Improve Neural Network Acoustic Models](2013-rectifier-nonlinearities-improve-neural-network-acoustic-models)
41. [From image descriptions to visual denotations - New similarity metrics for semantic inference over event descriptions](2014-from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions)
42. X‚Äêray microbeam speech production database
43. Canonical ridge and econometrics of joint production
44. Multivariate Analysis
45. Regularized Generalized Canonical Correlation Analysis
46. [The mnist database of handwritten digits](2005-the-mnist-database-of-handwritten-digits)
47. A Randomized Algorithm for CCA
48. Kendall's Advanced Theory of Statistics, Volume 1 - Distribution Theory
49. Kendall's Advanced Theory of Statistics. Volume 1. Distribution Theory
50. Mel Frequency Cepstral Coefficients for Music Modeling
