---
title: Hierarchical Multiscale Recurrent Neural Networks
authors:
- Junyoung Chung
- Sungjin Ahn
- Yoshua Bengio
fieldsOfStudy:
- Computer Science
meta_key: 2017-hierarchical-multiscale-recurrent-neural-networks
numCitedBy: 442
reading_status: TBD
ref_count: 88
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Hierarchical-Multiscale-Recurrent-Neural-Networks-Chung-Ahn/65eee67dee969fdf8b44c87c560d66ad4d78e233?sort=total-citations
venue: ICLR
year: 2017
---

[semanticscholar url](https://www.semanticscholar.org/paper/Hierarchical-Multiscale-Recurrent-Neural-Networks-Chung-Ahn/65eee67dee969fdf8b44c87c560d66ad4d78e233?sort=total-citations)

# Hierarchical Multiscale Recurrent Neural Networks

## Abstract

Learning both hierarchical and temporal representation has been among the long-standing challenges of recurrent neural networks. Multiscale recurrent neural networks have been considered as a promising approach to resolve this issue, yet there has been a lack of empirical evidence showing that this type of models can actually capture the temporal dependencies by discovering the latent hierarchical structure of the sequence. In this paper, we propose a novel multiscale approach, called the hierarchical multiscale recurrent neural networks, which can capture the latent hierarchical structure in the sequence by encoding the temporal dependencies with different timescales using a novel update mechanism. We show some evidence that our proposed multiscale architecture can discover underlying hierarchical structure in the sequences without using explicit boundary information. We evaluate our proposed model on character-level language modelling and handwriting sequence modelling.

## Paper References

1. Hierarchical Recurrent Neural Networks for Long-Term Dependencies
2. Sequence Labelling in Structured Domains with Hierarchical Recurrent Neural Networks
3. Learning Complex, Extended Sequences Using the Principle of History Compression
4. Architectural Complexity Measures of Recurrent Neural Networks
5. Gated Feedback Recurrent Neural Networks
6. [On Multiplicative Integration with Recurrent Neural Networks](2016-on-multiplicative-integration-with-recurrent-neural-networks.md)
7. Learning long-term dependencies in NARX recurrent neural networks
8. [Recurrent Highway Networks](2017-recurrent-highway-networks.md)
9. Neural Sequence Chunkers
10. [On the difficulty of training recurrent neural networks](2013-on-the-difficulty-of-training-recurrent-neural-networks.md)
11. Segmental Recurrent Neural Networks
12. [Generating Text with Recurrent Neural Networks](2011-generating-text-with-recurrent-neural-networks.md)
13. One-shot Learning with Memory-Augmented Neural Networks
14. Surprisal-Driven Feedback in Recurrent Networks
15. [Deep learning in neural networks - An overview](2015-deep-learning-in-neural-networks-an-overview.md)
16. Induction of Multiscale Temporal Structure
17. A Clockwork RNN
18. [Grid Long Short-Term Memory](2016-grid-long-short-term-memory.md)
19. Neural Variational Inference and Learning in Belief Networks
20. A Recurrent Latent Variable Model for Sequential Data
21. SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS
22. [Generating Sequences With Recurrent Neural Networks](2013-generating-sequences-with-recurrent-neural-networks.md)
23. [Long Short-Term Memory](1997-long-short-term-memory.md)
24. Regularization and nonlinearities for neural language models - when are they needed?
25. [Speech recognition with deep recurrent neural networks](2013-speech-recognition-with-deep-recurrent-neural-networks.md)
26. [How transferable are features in deep neural networks?](2014-how-transferable-are-features-in-deep-neural-networks.md)
27. [Auto-Encoding Variational Bayes](2014-auto-encoding-variational-bayes.md)
28. [Recurrent Batch Normalization](2017-recurrent-batch-normalization.md)
29. Strategic Attentive Writer for Learning Macro-Actions
30. [Sequence to Sequence Learning with Neural Networks](2014-sequence-to-sequence-learning-with-neural-networks.md)
31. [Learning Deep Architectures for AI](2007-learning-deep-architectures-for-ai.md)
32. [Character-Aware Neural Language Models](2016-character-aware-neural-language-models.md)
33. [Recurrent neural network based language model](2010-recurrent-neural-network-based-language-model.md)
34. [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](2014-learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation.md)
35. [Zoneout - Regularizing RNNs by Randomly Preserving Hidden Activations](2017-zoneout-regularizing-rnns-by-randomly-preserving-hidden-activations.md)
36. [Dropout - a simple way to prevent neural networks from overfitting](2014-dropout-a-simple-way-to-prevent-neural-networks-from-overfitting.md)
37. [Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation](2013-estimating-or-propagating-gradients-through-stochastic-neurons-for-conditional-computation.md)
38. Recurrent Memory Array Structures
39. End-to-end attention-based large vocabulary speech recognition
40. [Human-level control through deep reinforcement learning](2015-human-level-control-through-deep-reinforcement-learning.md)
41. Character-based Neural Machine Translation
42. [Deep Networks with Stochastic Depth](2016-deep-networks-with-stochastic-depth.md)
43. [Simple statistical gradient-following algorithms for connectionist reinforcement learning](2004-simple-statistical-gradient-following-algorithms-for-connectionist-reinforcement-learning.md)
44. Regularizing RNNs by Stabilizing Activations
45. [Layer Normalization](2016-layer-normalization.md)
46. A Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion
47. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks.md)
48. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
49. [Convolutional Neural Networks for Sentence Classification](2014-convolutional-neural-networks-for-sentence-classification.md)
50. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization.md)
51. [Show and tell - A neural image caption generator](2015-show-and-tell-a-neural-image-caption-generator.md)
52. [Binarized Neural Networks - Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1](2016-binarized-neural-networks-training-deep-neural-networks-with-weights-and-activations-constrained-to-1-or-1.md)
53. Mixture density networks
54. One-Shot Adaptation of Supervised Deep Convolutional Models
55. Bursty and Hierarchical Structure in Streams
56. [Theano - A Python framework for fast computation of mathematical expressions](2016-theano-a-python-framework-for-fast-computation-of-mathematical-expressions.md)
57. Unconstrained On-line Handwriting Recognition with Recurrent Neural Networks
58. A Character-level Decoder without Explicit Segmentation for Neural Machine Translation
59. [Mastering the game of Go with deep neural networks and tree search](2016-mastering-the-game-of-go-with-deep-neural-networks-and-tree-search.md)
60. Listen, attend and spell - A neural network for large vocabulary conversational speech recognition
61. Adaptive weighing of context models for lossless data compression
62. [BinaryConnect - Training Deep Neural Networks with binary weights during propagations](2015-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.md)
63. [Published as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS](2018-published-as-a-conference-paper-at-iclr-2018-s-imulating-a-ction-d-ynamics-with-n-eural-p-rocess-n-etworks.md)
64. [Rectified Linear Units Improve Restricted Boltzmann Machines](2010-rectified-linear-units-improve-restricted-boltzmann-machines.md)
65. Neural Networks in Machine Learning
66. Building a Large Annotated Corpus of English - The Penn Treebank
67. IAM-OnDB - an on-line English sentence database acquired from handwritten text on a whiteboard
68. References
69. [Deep Learning](2016-deep-learning.md)
