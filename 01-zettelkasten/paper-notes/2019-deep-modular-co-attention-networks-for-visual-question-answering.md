---
title: Deep Modular Co-Attention Networks for Visual Question Answering
authors:
- Zhou Yu
- Jun Yu
- Yuhao Cui
- D. Tao
- Q. Tian
fieldsOfStudy:
- Computer Science
meta_key: 2019-deep-modular-co-attention-networks-for-visual-question-answering
numCitedBy: 324
reading_status: TBD
ref_count: 39
tags:
- gen-from-ref
- other-default
- paper
venue: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2019
---

# Deep Modular Co-Attention Networks for Visual Question Answering

## Abstract

Visual Question Answering (VQA) requires a fine-grained and simultaneous understanding of both the visual content of images and the textual content of questions. Therefore, designing an effective `co-attention' model to associate key words in questions with key objects in images is central to VQA performance. So far, most successful attempts at co-attention learning have been achieved by using shallow models, and deep co-attention models show little improvement over their shallow counterparts. In this paper, we propose a deep Modular Co-Attention Network (MCAN) that consists of Modular Co-Attention (MCA) layers cascaded in depth. Each MCA layer models the self-attention of questions and images, as well as the question-guided-attention of images jointly using a modular composition of two basic attention units. We quantitatively and qualitatively evaluate MCAN on the benchmark VQA-v2 dataset and conduct extensive ablation studies to explore the reasons behind MCAN's effectiveness. Experimental results demonstrate that MCAN significantly outperforms the previous state-of-the-art. Our best single model delivers 70.63% overall accuracy on the test-dev set.

## Paper References

1. [Hierarchical Question-Image Co-Attention for Visual Question Answering](2016-hierarchical-question-image-co-attention-for-visual-question-answering)
2. Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering
3. Improved Fusion of Visual and Language Representations by Dense Symmetric Co-attention for Visual Question Answering
4. Beyond Bilinear - Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering
5. ABC-CNN - An Attention Based Convolutional Neural Network for Visual Question Answering
6. [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](2018-bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering)
7. Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering
8. [Dual Attention Networks for Multimodal Reasoning and Matching](2017-dual-attention-networks-for-multimodal-reasoning-and-matching)
9. [Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding](2016-multimodal-compact-bilinear-pooling-for-visual-question-answering-and-visual-grounding)
10. [Stacked Attention Networks for Image Question Answering](2016-stacked-attention-networks-for-image-question-answering)
11. Learning to Count Objects in Natural Images for Visual Question Answering
12. [Bilinear Attention Networks](2018-bilinear-attention-networks)
13. [VQA - Visual Question Answering](2015-vqa-visual-question-answering)
14. Rethinking Diversified and Discriminative Proposal Generation for Visual Grounding
15. Multimodal Residual Learning for Visual QA
16. Tips and Tricks for Visual Question Answering - Learnings from the 2017 Challenge
17. [Attention is All you Need](2017-transformer.md)
18. [Long-term recurrent convolutional networks for visual recognition and description](2015-long-term-recurrent-convolutional-networks-for-visual-recognition-and-description)
19. [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](2016-visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations)
20. Open-Ended Long-form Video Question Answering via Adaptive Hierarchical Reinforced Networks
21. Simple Baseline for Visual Question Answering
22. [Where to Look - Focus Regions for Visual Question Answering](2016-where-to-look-focus-regions-for-visual-question-answering)
23. [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](2015-show-attend-and-tell-neural-image-caption-generation-with-visual-attention)
24. [Deep Residual Learning for Image Recognition](2015-resnet.md)
25. [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](2015-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks)
26. Training Deeper Neural Machine Translation Models with Transparent Attention
27. [Attention-Based Models for Speech Recognition](2015-attention-based-models-for-speech-recognition)
28. [Recurrent Models of Visual Attention](2014-recurrent-models-of-visual-attention)
29. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context)
30. A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input
31. [GloVe - Global Vectors for Word Representation](2014-glove-global-vectors-for-word-representation)
32. [Neural Machine Translation by Jointly Learning to Align and Translate](2015-neural-machine-translation-by-jointly-learning-to-align-and-translate)
33. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization)
34. [Long Short-Term Memory](1997-long-short-term-memory)
35. Advances in Neural Information Processing Systems (NIPS)
36. MUTAN - Multimodal Tucker Fusion for Visual Question Answering
