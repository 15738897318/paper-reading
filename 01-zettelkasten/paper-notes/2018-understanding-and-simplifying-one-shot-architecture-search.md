---
title: Understanding and Simplifying One-Shot Architecture Search
authors:
- Gabriel Bender
- Pieter-Jan Kindermans
- Barret Zoph
- Vijay Vasudevan
- Quoc V. Le
fieldsOfStudy:
- Computer Science
meta_key: 2018-understanding-and-simplifying-one-shot-architecture-search
numCitedBy: 508
reading_status: TBD
ref_count: 30
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Understanding-and-Simplifying-One-Shot-Architecture-Bender-Kindermans/45b7b5514a65126d39a51d5a68da53e7aa244c1f?sort=total-citations
venue: ICML
year: 2018
---

# Understanding and Simplifying One-Shot Architecture Search

## Abstract

There is growing interest in automating neural network architecture design. Existing architecture search methods can be computationally expensive, requiring thousands of different architectures to be trained from scratch. Recent work has explored weight sharing across models to amortize the cost of training. Although previous methods reduced the cost of architecture search by orders of magnitude, they remain complex, requiring hypernetworks or reinforcement learning controllers. We aim to understand weight sharing for one-shot architecture search. With careful experimental analysis, we show that it is possible to efficiently identify promising architectures from a complex search space without either hypernetworks or RL.

## Paper References

1. [SMASH - One-Shot Model Architecture Search through HyperNetworks](2018-smash-one-shot-model-architecture-search-through-hypernetworks.md)
2. Reinforcement Learning for Architecture Search by Network Transformation
3. [Progressive Neural Architecture Search](2018-progressive-neural-architecture-search.md)
4. [Neural Architecture Search with Reinforcement Learning](2017-neural-architecture-search-with-reinforcement-learning.md)
5. Simple And Efficient Architecture Search for Convolutional Neural Networks
6. [Designing Neural Network Architectures using Reinforcement Learning](2017-designing-neural-network-architectures-using-reinforcement-learning.md)
7. [Hierarchical Representations for Efficient Architecture Search](2018-hierarchical-representations-for-efficient-architecture-search.md)
8. Neural Optimizer Search with Reinforcement Learning
9. Learned Optimizers that Scale and Generalize
10. Searching for Activation Functions
11. MorphNet - Fast & Simple Resource-Constrained Structure Learning of Deep Networks
12. Faster Discovery of Neural Architectures by Searching for Paths in a Large Model
13. [An Empirical Exploration of Recurrent Network Architectures](2015-an-empirical-exploration-of-recurrent-network-architectures.md)
14. [Large-Scale Evolution of Image Classifiers](2017-large-scale-evolution-of-image-classifiers.md)
15. Population Based Training of Neural Networks
16. [Algorithms for Hyper-Parameter Optimization](2011-algorithms-for-hyper-parameter-optimization.md)
17. [Learning to learn by gradient descent by gradient descent](2016-learning-to-learn-by-gradient-descent-by-gradient-descent.md)
18. [Making a Science of Model Search - Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures](2013-making-a-science-of-model-search-hyperparameter-optimization-in-hundreds-of-dimensions-for-vision-architectures.md)
19. [Learning Transferable Architectures for Scalable Image Recognition](2018-learning-transferable-architectures-for-scalable-image-recognition.md)
20. Scalable Bayesian Optimization Using Deep Neural Networks
21. Learning to Learn Using Gradient Descent
22. Train longer, generalize better - closing the generalization gap in large batch training of neural networks
23. Evolving Neural Networks through Augmenting Topologies
24. [Practical Bayesian Optimization of Machine Learning Algorithms](2012-practical-bayesian-optimization-of-machine-learning-algorithms.md)
25. Learning to Learn
26. Evolving Memory Cell Structures for Sequence Learning
27. [TensorFlow - A system for large-scale machine learning](2016-tensorflow-a-system-for-large-scale-machine-learning.md)
28. Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning
29. [MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications](2017-mobilenets-efficient-convolutional-neural-networks-for-mobile-vision-applications.md)
30. [Random Search for Hyper-Parameter Optimization](2012-random-search-for-hyper-parameter-optimization.md)
