---
title: 12-in-1 - Multi-Task Vision and Language Representation Learning
authors:
- Jiasen Lu
- Vedanuj Goswami
- Marcus Rohrbach
- Devi Parikh
- Stefan Lee
fieldsOfStudy:
- Computer Science
meta_key: 2020-12-in-1-multi-task-vision-and-language-representation-learning
numCitedBy: 234
reading_status: TBD
ref_count: 69
tags:
- gen-from-ref
- other-default
- paper
venue: 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2020
---

# 12-in-1 - Multi-Task Vision and Language Representation Learning

## Abstract

Much of vision-and-language research focuses on a small but diverse set of independent tasks and supporting datasets often studied in isolation; however, the visually-grounded language understanding skills required for success at these tasks overlap significantly. In this work, we investigate these relationships between vision-and-language tasks by developing a large-scale, multi-task model. Our approach culminates in a single model on 12 datasets from four broad categories of task including visual question answering, caption-based image retrieval, grounding referring expressions, and multimodal verification. Compared to independently trained single-task models, this represents a reduction from approximately 3 billion parameters to 270 million while simultaneously improving performance by 2.05 points on average across tasks. We use our multi-task framework to perform in-depth analysis of the effect of joint training diverse tasks. Further, we show that finetuning task-specific models from our single multi-task model can lead to further improvements, achieving performance at or above the state-of-the-art.

## Paper References

1. Multi-Task Learning of Hierarchical Vision-Language Representation
2. [ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](2019-vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks)
3. [Unified Vision-Language Pre-Training for Image Captioning and VQA](2020-unified-vision-language-pre-training-for-image-captioning-and-vqa)
4. [Visual7W - Grounded Question Answering in Images](2016-visual7w-grounded-question-answering-in-images)
5. [VisualBERT - A Simple and Performant Baseline for Vision and Language](2019-visualbert-a-simple-and-performant-baseline-for-vision-and-language)
6. [LXMERT - Learning Cross-Modality Encoder Representations from Transformers](2019-lxmert-learning-cross-modality-encoder-representations-from-transformers)
7. [VL-BERT - Pre-training of Generic Visual-Linguistic Representations](2020-vl-bert-pre-training-of-generic-visual-linguistic-representations)
8. [Multi-Task Deep Neural Networks for Natural Language Understanding](2019-multi-task-deep-neural-networks-for-natural-language-understanding)
9. OmniNet - A unified architecture for multi-modal multi-task learning
10. UberNet - Training a Universal Convolutional Neural Network for Low-, Mid-, and High-Level Vision Using Diverse Datasets and Limited Memory
11. Many Task Learning With Task Routing
12. Which Tasks Should Be Learned Together in Multi-task Learning?
13. [Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal Pre-training](2020-unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training)
14. Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval
15. [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](2020-exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer)
16. [Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering](2017-making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering)
17. Cross-Stitch Networks for Multi-task Learning
18. [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](2016-visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations)
19. [MAttNet - Modular Attention Network for Referring Expression Comprehension](2018-mattnet-modular-attention-network-for-referring-expression-comprehension)
20. BAM! Born-Again Multi-Task Networks for Natural Language Understanding
21. [UNITER - Learning UNiversal Image-TExt Representations](2019-uniter-learning-universal-image-text-representations)
22. Visual Entailment Task for Visually-Grounded Language Learning
23. [Attention is All you Need](2017-transformer.md)
24. [A unified architecture for natural language processing - deep neural networks with multitask learning](2008-a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning)
25. Visual Dialog
26. [Hierarchical Question-Image Co-Attention for Visual Question Answering](2016-hierarchical-question-image-co-attention-for-visual-question-answering)
27. [Fusion of Detected Objects in Text for Visual Question Answering](2019-fusion-of-detected-objects-in-text-for-visual-question-answering)
28. [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](2019-bert.md)
29. [From Recognition to Cognition - Visual Commonsense Reasoning](2019-from-recognition-to-cognition-visual-commonsense-reasoning)
30. [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](2018-bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering)
31. Stochastic Filter Groups for Multi-Task CNNs - Learning Specialist and Generalist Convolution Kernels
32. [Stacked Cross Attention for Image-Text Matching](2018-stacked-cross-attention-for-image-text-matching)
33. The Dialogue Dodecathlon - Open-Domain Knowledge and Image Grounded Conversational Agents
34. [Neural Baby Talk](2018-neural-baby-talk)
35. Flickr30k Entities - Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models
36. GuessWhat?! Visual Object Discovery through Multi-modal Dialogue
37. GQA - a new dataset for compositional question answering over real-world images
38. [SpanBERT - Improving Pre-training by Representing and Predicting Spans](2020-spanbert-improving-pre-training-by-representing-and-predicting-spans)
39. Multitask Learning
40. [Modeling Relationships in Referential Expressions with Compositional Modular Networks](2017-modeling-relationships-in-referential-expressions-with-compositional-modular-networks)
41. [GQA - A New Dataset for Real-World Visual Reasoning and Compositional Question Answering](2019-gqa-a-new-dataset-for-real-world-visual-reasoning-and-compositional-question-answering)
42. [Generation and Comprehension of Unambiguous Object Descriptions](2016-generation-and-comprehension-of-unambiguous-object-descriptions)
43. An Overview of Multi-task Learning
44. [Cross-lingual Language Model Pretraining](2019-cross-lingual-language-model-pretraining)
45. Embodied Question Answering
46. [Aggregated Residual Transformations for Deep Neural Networks](2017-aggregated-residual-transformations-for-deep-neural-networks)
47. An Overview of Multi-Task Learning in Deep Neural Networks
48. Vision-and-Language Navigation - Interpreting Visually-Grounded Navigation Instructions in Real Environments
49. Distral - Robust multitask reinforcement learning
50. [XLNet - Generalized Autoregressive Pretraining for Language Understanding](2019-xlnet-generalized-autoregressive-pretraining-for-language-understanding)
51. [A Corpus for Reasoning about Natural Language Grounded in Photographs](2019-a-corpus-for-reasoning-about-natural-language-grounded-in-photographs)
52. Facial Landmark Detection by Deep Multi-task Learning
53. [RoBERTa - A Robustly Optimized BERT Pretraining Approach](2019-roberta-a-robustly-optimized-bert-pretraining-approach)
54. Reinforcement Learning with Unsupervised Auxiliary Tasks
55. [Curriculum learning](2009-curriculum-learning)
56. Robust Visual Tracking via Structured Multi-Task Sparse Learning
57. [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](2015-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks)
58. Actor-Mimic - Deep Multitask and Transfer Reinforcement Learning
59. [Conceptual Captions - A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning](2018-conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning)
60. [Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network](2003-feature-rich-part-of-speech-tagging-with-a-cyclic-dependency-network)
61. ReferItGame - Referring to Objects in Photographs of Natural Scenes
62. Fixing Weight Decay Regularization in Adam
63. Im2Text - Describing Images Using 1 Million Captioned Photographs
64. [Decoupled Weight Decay Regularization](2019-decoupled-weight-decay-regularization)
65. [Microsoft COCO Captions - Data Collection and Evaluation Server](2015-microsoft-coco-captions-data-collection-and-evaluation-server)
66. The Natural Language Decathlon - Multitask Learning as Question Answering
