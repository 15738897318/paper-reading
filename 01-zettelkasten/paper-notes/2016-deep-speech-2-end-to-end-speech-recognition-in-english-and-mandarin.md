---
title: Deep Speech 2 - End-to-End Speech Recognition in English and Mandarin
authors:
- Dario Amodei
- S. Ananthanarayanan
- Rishita Anubhai
- Jin Bai
- Eric Battenberg
- Carl Case
- J. Casper
- Bryan Catanzaro
- Jingdong Chen
- Mike Chrzanowski
- Adam Coates
- G. Diamos
- Erich Elsen
- Jesse Engel
- Linxi (Jim) Fan
- Christopher Fougner
- Awni Y. Hannun
- Billy Jun
- T. Han
- P. LeGresley
- Xiangang Li
- Libby Lin
- Sharan Narang
- A. Ng
- Sherjil Ozair
- R. Prenger
- Sheng Qian
- Jonathan Raiman
- S. Satheesh
- David Seetapun
- Shubho Sengupta
- Anuroop Sriram
- Chong-Jun Wang
- Yi Wang
- Zhiqian Wang
- Bo Xiao
- Yan Xie
- Dani Yogatama
- J. Zhan
- Zhenyao Zhu
fieldsOfStudy:
- Computer Science
meta_key: 2016-deep-speech-2-end-to-end-speech-recognition-in-english-and-mandarin
numCitedBy: 2236
reading_status: TBD
ref_count: 85
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Deep-Speech-2-:-End-to-End-Speech-Recognition-in-Amodei-Ananthanarayanan/8ff840a40d3f1557c55c19d4d636da77103168ce?sort=total-citations
venue: ICML
year: 2016
---

[semanticscholar url](https://www.semanticscholar.org/paper/Deep-Speech-2-:-End-to-End-Speech-Recognition-in-Amodei-Ananthanarayanan/8ff840a40d3f1557c55c19d4d636da77103168ce?sort=total-citations)

# Deep Speech 2 - End-to-End Speech Recognition in English and Mandarin

## Abstract

We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech-two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks, end-to-end learning allows us to handle a diverse variety of speech including noisy environments, accents and different languages. Key to our approach is our application of HPC techniques, enabling experiments that previously took weeks to now run in days. This allows us to iterate more quickly to identify superior architectures and algorithms. As a result, in several cases, our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally, using a technique called Batch Dispatch with GPUs in the data center, we show that our system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.

## Paper References

1. Deep Speech - Scaling up end-to-end speech recognition
2. EESEN - End-to-end speech recognition using deep RNN models and WFST-based decoding
3. End-to-end attention-based large vocabulary speech recognition
4. A big data approach to acoustic model training corpus selection
5. First-Pass Large Vocabulary Continuous Speech Recognition using Bi-Directional Recurrent DNNs
6. [Towards End-To-End Speech Recognition with Recurrent Neural Networks](2014-towards-end-to-end-speech-recognition-with-recurrent-neural-networks.md)
7. [Speech recognition with deep recurrent neural networks](2013-speech-recognition-with-deep-recurrent-neural-networks.md)
8. Lexicon-Free Conversational Speech Recognition with Neural Networks
9. Listen, Attend and Spell
10. [Sequence to Sequence Learning with Neural Networks](2014-sequence-to-sequence-learning-with-neural-networks.md)
11. [Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition](2012-context-dependent-pre-trained-deep-neural-networks-for-large-vocabulary-speech-recognition.md)
12. Vocal Tract Length Perturbation (VTLP) improves speech recognition
13. Size matters - an empirical study of neural network training for large vocabulary continuous speech recognition
14. Context-dependent deep neural networks for commercial Mandarin speech recognition applications
15. Convolutional, Long Short-Term Memory, fully connected Deep Neural Networks
16. Application of Pretrained Deep Neural Networks to Large Vocabulary Speech Recognition
17. End-to-end Continuous Speech Recognition using Attention-based Recurrent NN - First Results
18. The NTT CHiME-3 system - Advances in speech enhancement and recognition for mobile multi-microphone devices
19. Librispeech - An ASR corpus based on public domain audio books
20. Applying Convolutional Neural Networks concepts to hybrid NN-HMM model for speech recognition
21. Learning to Execute
22. Long short-term memory recurrent neural network architectures for large scale acoustic modeling
23. Batch normalized recurrent neural networks
24. Fast and accurate recurrent neural network acoustic models for speech recognition
25. Sequence-discriminative training of deep neural networks
26. [Deep Neural Networks for Acoustic Modeling in Speech Recognition](2012-deep-neural-networks-for-acoustic-modeling-in-speech-recognition.md)
27. Speech recognition by machines and humans
28. Audio augmentation for speech recognition
29. [Neural Machine Translation by Jointly Learning to Align and Translate](2015-neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
30. [Deep convolutional neural networks for LVCSR](2013-deep-convolutional-neural-networks-for-lvcsr.md)
31. [Connectionist temporal classification - labelling unsegmented sequence data with recurrent neural networks](2006-connectionist-temporal-classification-labelling-unsegmented-sequence-data-with-recurrent-neural-networks.md)
32. The third â€˜CHiME' speech separation and recognition challenge - Dataset, task and baselines
33. Large vocabulary continuous speech recognition with context-dependent DBN-HMMS
34. Project Adam - Building an Efficient and Scalable Deep Learning Training System
35. Conversational Speech Transcription Using Context-Dependent Deep Neural Networks
36. [An Empirical Exploration of Recurrent Network Architectures](2015-an-empirical-exploration-of-recurrent-network-architectures.md)
37. Phoneme recognition using time-delay neural networks
38. Sequence discriminative distributed training of long short-term memory recurrent neural networks
39. Connectionist Speech Recognition - A Hybrid Approach
40. Support vector machines for noise robust ASR
41. Search by voice in Mandarin Chinese
42. THE USE OF RECURRENT NEURAL NETWORKS IN CONTINUOUS SPEECH RECOGNITION
43. The Fisher Corpus - a Resource for the Next Generations of Speech-to-Text
44. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
45. [Long Short-Term Memory](1997-long-short-term-memory.md)
46. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks.md)
47. [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](2014-learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation.md)
48. Bidirectional recurrent neural networks
49. [Building high-level features using large scale unsupervised learning](2013-building-high-level-features-using-large-scale-unsupervised-learning.md)
50. [Going deeper with convolutions](2015-going-deeper-with-convolutions.md)
51. [On the importance of initialization and momentum in deep learning](2013-on-the-importance-of-initialization-and-momentum-in-deep-learning.md)
52. Scalable Modified Kneser-Ney Language Model Estimation
53. [Large Scale Distributed Deep Networks](2012-large-scale-distributed-deep-networks.md)
54. Large-scale deep unsupervised learning using graphics processors
55. Deep learning with COTS HPC systems
56. [cuDNN - Efficient Primitives for Deep Learning](2014-cudnn-efficient-primitives-for-deep-learning.md)
57. [Acoustic Modeling Using Deep Belief Networks](2012-acoustic-modeling-using-deep-belief-networks.md)
58. [Hogwild - A Lock-Free Approach to Parallelizing Stochastic Gradient Descent](2011-hogwild-a-lock-free-approach-to-parallelizing-stochastic-gradient-descent.md)
59. Joint training of convolutional and non-convolutional neural networks
60. A Fast Data Collection and Augmentation Procedure for Object Recognition
61. [Curriculum learning](2009-curriculum-learning.md)
62. [On the difficulty of training recurrent neural networks](2013-on-the-difficulty-of-training-recurrent-neural-networks.md)
63. Learning methods for generic object recognition with invariance to pose and lighting
64. Text Detection and Character Recognition in Scene Images with Unsupervised Feature Learning
65. Connectionist probability estimators in HMM speech recognition
66. An Efficient Gradient-Based Algorithm for On-Line Training of Recurrent Network Trajectories
67. Optimization of Collective Communication Operations in MPICH
68. A fast storage allocator
69. Bandwidth optimal all-reduce algorithms for clusters of workstations
70. Advances in Neural Information Processing Systems 25
