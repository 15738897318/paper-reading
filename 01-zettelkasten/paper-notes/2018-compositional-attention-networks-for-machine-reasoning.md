---
title: Compositional Attention Networks for Machine Reasoning
authors:
- Drew A. Hudson
- Christopher D. Manning
fieldsOfStudy:
- Computer Science
meta_key: 2018-compositional-attention-networks-for-machine-reasoning
numCitedBy: 408
reading_status: TBD
ref_count: 31
tags:
- gen-from-ref
- paper
venue: ICLR
year: 2018
---

# Compositional Attention Networks for Machine Reasoning

## Abstract

We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition (MAC) cell that maintains a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9% accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.

## Paper References

1. [A simple neural network module for relational reasoning](2017-a-simple-neural-network-module-for-relational-reasoning)
2. Towards Deep Symbolic Reinforcement Learning
3. [Inferring and Executing Programs for Visual Reasoning](2017-inferring-and-executing-programs-for-visual-reasoning)
4. [Learning to Reason - End-to-End Module Networks for Visual Question Answering](2017-learning-to-reason-end-to-end-module-networks-for-visual-question-answering)
5. [Building machines that learn and think like people](2016-building-machines-that-learn-and-think-like-people)
6. [Neural Module Networks](2016-neural-module-networks)
7. [Hybrid computing using a neural network with dynamic external memory](2016-hybrid-computing-using-a-neural-network-with-dynamic-external-memory)
8. [Dynamic Memory Networks for Visual and Textual Question Answering](2016-dynamic-memory-networks-for-visual-and-textual-question-answering)
9. [CLEVR - A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning](2017-clevr-a-diagnostic-dataset-for-compositional-language-and-elementary-visual-reasoning)
10. From machine learning to machine reasoning
11. [Learning to Compose Neural Networks for Question Answering](2016-learning-to-compose-neural-networks-for-question-answering)
12. [FiLM - Visual Reasoning with a General Conditioning Layer](2018-film-visual-reasoning-with-a-general-conditioning-layer)
13. Analyzing the Behavior of Visual Question Answering Models
14. [Hierarchical Question-Image Co-Attention for Visual Question Answering](2016-hierarchical-question-image-co-attention-for-visual-question-answering)
15. [Stacked Attention Networks for Image Question Answering](2016-stacked-attention-networks-for-image-question-answering)
16. [Neural Machine Translation by Jointly Learning to Align and Translate](2015-neural-machine-translation-by-jointly-learning-to-align-and-translate)
17. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift)
18. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization)
19. Key-Value Memory Networks for Directly Reading Documents
20. [Deep Residual Learning for Image Recognition](2016-deep-residual-learning-for-image-recognition)
21. [VQA - Visual Question Answering](2015-vqa-visual-question-answering)
22. [Neural Turing Machines](2014-neural-turing-machines)
23. Survey of Visual Question Answering - Datasets and Techniques
24. A Simple Method to Determine if a Music Information Retrieval System is a “Horse”
25. Counting Everyday Objects in Everyday Scenes
26. [ImageNet Large Scale Visual Recognition Challenge](2015-imagenet-large-scale-visual-recognition-challenge)
27. [Ask Me Anything - Dynamic Memory Networks for Natural Language Processing](2016-ask-me-anything-dynamic-memory-networks-for-natural-language-processing)
