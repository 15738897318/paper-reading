---
title: Single Path One-Shot Neural Architecture Search with Uniform Sampling
authors:
- Zichao Guo
- X. Zhang
- Haoyuan Mu
- Wen Heng
- Zechun Liu
- Yichen Wei
- Jian Sun
fieldsOfStudy:
- Computer Science
meta_key: 2020-single-path-one-shot-neural-architecture-search-with-uniform-sampling
numCitedBy: 464
reading_status: TBD
ref_count: 48
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Single-Path-One-Shot-Neural-Architecture-Search-Guo-Zhang/79e523beb1e1411a241edde0464b07c2ebc231d1?sort=total-citations
venue: ECCV
year: 2020
---

# Single Path One-Shot Neural Architecture Search with Uniform Sampling

## Abstract

We revisit the one-shot Neural Architecture Search (NAS) paradigm and analyze its advantages over existing NAS approaches. Existing one-shot method, however, is hard to train and not yet effective on large scale datasets like ImageNet. This work propose a Single Path One-Shot model to address the challenge in the training. Our central idea is to construct a simplified supernet, where all architectures are single paths so that weight co-adaption problem is alleviated. Training is performed by uniform path sampling. All architectures (and their weights) are trained fully and equally. 
Comprehensive experiments verify that our approach is flexible and effective. It is easy to train and fast to search. It effortlessly supports complex search spaces (e.g., building blocks, channel, mixed-precision quantization) and different search constraints (e.g., FLOPs, latency). It is thus convenient to use for various needs. It achieves start-of-the-art performance on the large dataset ImageNet.

## Paper References

1. You Only Search Once - Single Shot Neural Architecture Search via Direct Sparse Optimization
2. Single-Path NAS - Designing Hardware-Efficient ConvNets in less than 4 Hours
3. BlockQNN - Efficient Block-Wise Neural Network Architecture Generation
4. [Practical Block-Wise Neural Network Architecture Generation](2018-practical-block-wise-neural-network-architecture-generation.md)
5. [Learning Transferable Architectures for Scalable Image Recognition](2018-learning-transferable-architectures-for-scalable-image-recognition.md)
6. [SMASH - One-Shot Model Architecture Search through HyperNetworks](2018-smash-one-shot-model-architecture-search-through-hypernetworks.md)
7. Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search
8. [MnasNet - Platform-Aware Neural Architecture Search for Mobile](2019-mnasnet-platform-aware-neural-architecture-search-for-mobile.md)
9. Efficient Neural Architecture Search via Proximal Iterations
10. Learning Time/Memory-Efficient Deep Architectures with Budgeted Super Networks
11. [Understanding and Simplifying One-Shot Architecture Search](2018-understanding-and-simplifying-one-shot-architecture-search.md)
12. Differentiable Neural Architecture Search via Proximal Iterations
13. LQ-Nets - Learned Quantization for Highly Accurate and Compact Deep Neural Networks
14. NAS evaluation is frustratingly hard
15. [FBNet - Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search](2019-fbnet-hardware-aware-efficient-convnet-design-via-differentiable-neural-architecture-search.md)
16. [ProxylessNAS - Direct Neural Architecture Search on Target Task and Hardware](2019-proxylessnas-direct-neural-architecture-search-on-target-task-and-hardware.md)
17. SNAS - Stochastic Neural Architecture Search
18. NAS-Bench-201 - Extending the Scope of Reproducible Neural Architecture Search
19. [Genetic CNN](2017-genetic-cnn.md)
20. NAS-Bench-102 - Extending the Scope of Reproducible Neural Architecture Search
21. [Progressive Neural Architecture Search](2018-progressive-neural-architecture-search.md)
22. [PACT - Parameterized Clipping Activation for Quantized Neural Networks](2018-pact-parameterized-clipping-activation-for-quantized-neural-networks.md)
23. [Efficient Neural Architecture Search via Parameter Sharing](2018-efficient-neural-architecture-search-via-parameter-sharing.md)
24. Searching for a Robust Neural Architecture in Four GPU Hours
25. [Large-Scale Evolution of Image Classifiers](2017-large-scale-evolution-of-image-classifiers.md)
26. [Neural Architecture Search with Reinforcement Learning](2017-neural-architecture-search-with-reinforcement-learning.md)
27. Evaluating the Search Phase of Neural Architecture Search
28. [MobileNetV2 - Inverted Residuals and Linear Bottlenecks](2018-mobilenetv2-inverted-residuals-and-linear-bottlenecks.md)
29. [ShuffleNet V2 - Practical Guidelines for Efficient CNN Architecture Design](2018-shufflenet-v2-practical-guidelines-for-efficient-cnn-architecture-design.md)
30. [DARTS - Differentiable Architecture Search](2019-darts-differentiable-architecture-search.md)
31. [Regularized Evolution for Image Classifier Architecture Search](2019-regularized-evolution-for-image-classifier-architecture-search.md)
32. Random Search and Reproducibility for Neural Architecture Search
33. [Channel Pruning for Accelerating Very Deep Neural Networks](2017-channel-pruning-for-accelerating-very-deep-neural-networks.md)
34. [Deep Residual Learning for Image Recognition](2016-deep-residual-learning-for-image-recognition.md)
35. Bi-Real Net - Enhancing the Performance of 1-bit CNNs With Improved Representational Capability and Advanced Training Algorithm
36. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
37. [AMC - AutoML for Model Compression and Acceleration on Mobile Devices](2018-amc-automl-for-model-compression-and-acceleration-on-mobile-devices.md)
38. [Designing Neural Network Architectures using Reinforcement Learning](2017-designing-neural-network-architectures-using-reinforcement-learning.md)
39. [Evolving Deep Neural Networks](2019-evolving-deep-neural-networks.md)
40. [Hierarchical Representations for Efficient Architecture Search](2018-hierarchical-representations-for-efficient-architecture-search.md)
41. [DoReFa-Net - Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients](2016-dorefa-net-training-low-bitwidth-convolutional-neural-networks-with-low-bitwidth-gradients.md)
42. [MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications](2017-mobilenets-efficient-convolutional-neural-networks-for-mobile-vision-applications.md)
43. [ShuffleNet - An Extremely Efficient Convolutional Neural Network for Mobile Devices](2018-shufflenet-an-extremely-efficient-convolutional-neural-network-for-mobile-devices.md)
44. ChamNet - Towards Efficient Network Design Through Platform-Aware Model Adaptation
45. Exploring Randomly Wired Neural Networks for Image Recognition
46. [NetAdapt - Platform-Aware Neural Network Adaptation for Mobile Applications](2018-netadapt-platform-aware-neural-network-adaptation-for-mobile-applications.md)
47. [ImageNet Large Scale Visual Recognition Challenge](2015-imagenet-large-scale-visual-recognition-challenge.md)
48. Et al
