---
title: Meteor Universal - Language Specific Translation Evaluation for Any Target Language
authors:
- Michael J. Denkowski
- A. Lavie
fieldsOfStudy:
- Computer Science
meta_key: 2014-meteor-universal-language-specific-translation-evaluation-for-any-target-language
numCitedBy: 1358
reading_status: TBD
ref_count: 19
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Meteor-Universal:-Language-Specific-Translation-for-Denkowski-Lavie/26adb749fc5d80502a6d889966e50b31391560d3?sort=total-citations
venue: WMT@ACL
year: 2014
---

[semanticscholar url](https://www.semanticscholar.org/paper/Meteor-Universal:-Language-Specific-Translation-for-Denkowski-Lavie/26adb749fc5d80502a6d889966e50b31391560d3?sort=total-citations)

# Meteor Universal - Language Specific Translation Evaluation for Any Target Language

## Abstract

This paper describes Meteor Universal, released for the 2014 ACL Workshop on Statistical Machine Translation. Meteor Universal brings language specific evaluation to previously unsupported target languages by (1) automatically extracting linguistic resources (paraphrase tables and function word lists) from the bitext used to train MT systems and (2) using a universal parameter set learned from pooling human judgments of translation quality from several language directions. Meteor Universal is shown to significantly outperform baseline BLEU on two new languages, Russian (WMT13) and Hindi (WMT14).

## Paper References

1. Meteor 1.3 - Automatic Metric for Reliable Optimization and Evaluation of Machine Translation Systems
2. [Moses - Open Source Toolkit for Statistical Machine Translation](2007-moses-open-source-toolkit-for-statistical-machine-translation)
3. [Bleu - a Method for Automatic Evaluation of Machine Translation](2002-bleu-a-method-for-automatic-evaluation-of-machine-translation)
4. Findings of the 2012 Workshop on Statistical Machine Translation
5. Paraphrasing with Bilingual Parallel Corpora
6. SPEDE - Probabilistic Edit Distance Metrics for MT Evaluation
7. [Statistical Phrase-Based Translation](2003-statistical-phrase-based-translation)
8. Findings of the 2011 Workshop on Statistical Machine Translation
9. Fluency, Adequacy, or HTER? Exploring Different Human Judgments with a Tunable MT Metric
10. TESLA at WMT 2011 - Translation Evaluation and Tunable Metric
11. Improving AMBER, an MT Evaluation Metric
12. Results of the WMT13 Metrics Shared Task
13. Results of the WMT14 Metrics Shared Task
14. Snowball - A language for stemming algorithms
