---
title: Neural Architecture Search with Reinforcement Learning
authors:
- Barret Zoph
- Quoc V. Le
fieldsOfStudy:
- Computer Science
meta_key: 2017-neural-architecture-search-with-reinforcement-learning
numCitedBy: 3482
reading_status: TBD
ref_count: 72
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Neural-Architecture-Search-with-Reinforcement-Zoph-Le/67d968c7450878190e45ac7886746de867bf673d?sort=total-citations
venue: ICLR
year: 2017
---

# Neural Architecture Search with Reinforcement Learning

## Abstract

Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214.

## Paper References

1. [Sequence to Sequence Learning with Neural Networks](2014-sequence-to-sequence-learning-with-neural-networks.md)
2. [An Empirical Exploration of Recurrent Network Architectures](2015-an-empirical-exploration-of-recurrent-network-architectures.md)
3. How to Construct Deep Recurrent Neural Networks
4. Sequence Level Training with Recurrent Neural Networks
5. Neural Programmer - Inducing Latent Programs with Gradient Descent
6. Context dependent recurrent neural network language model
7. [Network In Network](2014-network-in-network.md)
8. [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](2016-a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks.md)
9. [Character-Aware Neural Language Models](2016-character-aware-neural-language-models.md)
10. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks.md)
11. [Deep Residual Learning for Image Recognition](2016-deep-residual-learning-for-image-recognition.md)
12. [Recurrent Highway Networks](2017-recurrent-highway-networks.md)
13. [On the importance of initialization and momentum in deep learning](2013-on-the-importance-of-initialization-and-momentum-in-deep-learning.md)
14. [Tying Word Vectors and Word Classifiers - A Loss Framework for Language Modeling](2017-tying-word-vectors-and-word-classifiers-a-loss-framework-for-language-modeling.md)
15. [Wide Residual Networks](2016-wide-residual-networks.md)
16. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
17. [Large Scale Distributed Deep Networks](2012-large-scale-distributed-deep-networks.md)
18. Human-level concept learning through probabilistic program induction
19. [Learning to Compose Neural Networks for Question Answering](2016-learning-to-compose-neural-networks-for-question-answering.md)
20. [Striving for Simplicity - The All Convolutional Net](2015-striving-for-simplicity-the-all-convolutional-net.md)
21. [Recurrent Neural Network Regularization](2014-recurrent-neural-network-regularization.md)
22. [Deep Networks with Stochastic Depth](2016-deep-networks-with-stochastic-depth.md)
23. [Neural Machine Translation by Jointly Learning to Align and Translate](2015-neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
24. [Pointer Sentinel Mixture Models](2017-pointer-sentinel-mixture-models.md)
25. Scalable Bayesian Optimization Using Deep Neural Networks
26. [Densely Connected Convolutional Networks](2017-densely-connected-convolutional-networks.md)
27. [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](2016-google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
28. [Algorithms for Hyper-Parameter Optimization](2011-algorithms-for-hyper-parameter-optimization.md)
29. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization.md)
30. [Identity Mappings in Deep Residual Networks](2016-identity-mappings-in-deep-residual-networks.md)
31. [Practical Bayesian Optimization of Machine Learning Algorithms](2012-practical-bayesian-optimization-of-machine-learning-algorithms.md)
32. [Using the Output Embedding to Improve Language Models](2017-using-the-output-embedding-to-improve-language-models.md)
33. [Learning to learn by gradient descent by gradient descent](2016-learning-to-learn-by-gradient-descent-by-gradient-descent.md)
34. Neural Programmer-Interpreters
35. A Neural Probabilistic Language Model
36. [Deep Neural Networks for Acoustic Modeling in Speech Recognition - The Shared Views of Four Research Groups](2012-deep-neural-networks-for-acoustic-modeling-in-speech-recognition-the-shared-views-of-four-research-groups.md)
37. Language modeling with sum-product networks
38. [Going deeper with convolutions](2015-going-deeper-with-convolutions.md)
39. Towards Automatically-Tuned Neural Networks
40. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2015-very-deep-convolutional-networks-for-large-scale-image-recognition.md)
41. [Long Short-Term Memory](1997-long-short-term-memory.md)
42. [Gradient-based learning applied to document recognition](1998-gradient-based-learning-applied-to-document-recognition.md)
43. [Making a Science of Model Search - Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures](2013-making-a-science-of-model-search-hyperparameter-optimization-in-hundreds-of-dimensions-for-vision-architectures.md)
44. [Convolutional Neural Fabrics](2016-convolutional-neural-fabrics.md)
45. Neuroevolution - from architectures to learning
46. A Hypercube-Based Encoding for Evolving Large-Scale Neural Networks
47. Minimum Risk Training for Neural Machine Translation
48. Modeling systems with internal state using evolino
49. [FractalNet - Ultra-Deep Neural Networks without Residuals](2017-fractalnet-ultra-deep-neural-networks-without-residuals.md)
50. [Simple statistical gradient-following algorithms for connectionist reinforcement learning](2004-simple-statistical-gradient-following-algorithms-for-connectionist-reinforcement-learning.md)
51. What is the best multi-stage architecture for object recognition?
52. Three new graphical models for statistical language modelling
53. Learning Programs - A Hierarchical Bayesian Approach
54. [Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks](2016-under-review-as-a-conference-paper-at-iclr-2017-delving-into-transferable-adversarial-ex-amples-and-black-box-attacks.md)
55. [Random Search for Hyper-Parameter Optimization](2012-random-search-for-hyper-parameter-optimization.md)
56. [Rectified Linear Units Improve Restricted Boltzmann Machines](2010-rectified-linear-units-improve-restricted-boltzmann-machines.md)
57. Learning to Optimize âˆ—
58. Learning to Learn
59. [Object recognition from local scale-invariant features](1999-object-recognition-from-local-scale-invariant-features.md)
60. [Histograms of oriented gradients for human detection](2005-histograms-of-oriented-gradients-for-human-detection.md)
61. The Inference of Regular LISP Programs from Examples
62. A Methodology for LISP Program Construction from Examples
