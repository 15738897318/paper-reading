---
title: Long-term recurrent convolutional networks for visual recognition and description
authors:
- Jeff Donahue
- Lisa Anne Hendricks
- Marcus Rohrbach
- Subhashini Venugopalan
- S. Guadarrama
- Kate Saenko
- Trevor Darrell
fieldsOfStudy:
- Computer Science
meta_key: 2015-long-term-recurrent-convolutional-networks-for-visual-recognition-and-description
numCitedBy: 4113
reading_status: TBD
ref_count: 95
tags:
- gen-from-ref
- other-default
- paper
venue: 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2015
---

# Long-term recurrent convolutional networks for visual recognition and description

## Abstract

Models based on deep convolutional networks have dominated recent image interpretation tasks; we investigate whether models which are also recurrent, or “temporally deep”, are effective for tasks involving sequences, visual and otherwise. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image description and retrieval problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are “doubly deep” in that they can be compositional in spatial and temporal “layers”. Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable-length inputs (e.g., video frames) to variable length outputs (e.g., natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to modern visual convnet models and can be jointly trained to simultaneously learn temporal dynamics and convolutional perceptual representations. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.

## Paper References

1. Describing Videos by Exploiting Temporal Structure
2. Beyond short snippets - Deep networks for video classification
3. Explain Images with Multimodal Recurrent Neural Networks
4. [Large-Scale Video Classification with Convolutional Neural Networks](2014-large-scale-video-classification-with-convolutional-neural-networks)
5. [Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)](2015-deep-captioning-with-multimodal-recurrent-neural-networks-m-rnn)
6. [Two-Stream Convolutional Networks for Action Recognition in Videos](2014-two-stream-convolutional-networks-for-action-recognition-in-videos)
7. Translating Videos to Natural Language Using Deep Recurrent Neural Networks
8. [Show and tell - A neural image caption generator](2015-show-and-tell-a-neural-image-caption-generator)
9. [DeViSE - A Deep Visual-Semantic Embedding Model](2013-devise-a-deep-visual-semantic-embedding-model)
10. Sequence discriminative distributed training of long short-term memory recurrent neural networks
11. [Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models](2014-unifying-visual-semantic-embeddings-with-multimodal-neural-language-models)
12. [3D Convolutional Neural Networks for Human Action Recognition](2013-3d-convolutional-neural-networks-for-human-action-recognition)
13. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2014-vggnet.md)
14. [Sequence to Sequence Learning with Neural Networks](2014-sequence-to-sequence-learning-with-neural-networks)
15. [ImageNet classification with deep convolutional neural networks](2012-alexnet.md)
16. Sequence to Sequence -- Video to Text
17. [Generating Text with Recurrent Neural Networks](2011-generating-text-with-recurrent-neural-networks)
18. A Thousand Frames in Just a Few Words - Lingual Description of Videos through Latent Topics and Sparse Object Stitching
19. Integrating Language and Vision to Generate Natural Language Descriptions of Videos in the Wild
20. Language Models for Image Captioning - The Quirks and What Works
21. [Grounding of Textual Phrases in Images by Reconstruction](2016-grounding-of-textual-phrases-in-images-by-reconstruction)
22. [Long Short-Term Memory](1997-long-short-term-memory)
23. [From captions to visual concepts and back](2015-from-captions-to-visual-concepts-and-back)
24. Grounded Compositional Semantics for Finding and Describing Images with Sentences
25. Multimodal Neural Language Models
26. [Visualizing and Understanding Convolutional Networks](2014-visualizing-and-understanding-convolutional-networks)
27. Sequential Deep Learning for Human Action Recognition
28. Deep Compositional Captioning - Describing Novel Object Categories without Paired Training Data
29. Revisiting Recurrent Neural Networks for robust ASR
30. [Going deeper with convolutions](2015-going-deeper-with-convolutions)
31. Learning to Execute
32. Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
33. Action Classification in Soccer Videos with Long Short-Term Memory Recurrent Neural Networks
34. [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](2015-show-attend-and-tell-neural-image-caption-generation-with-visual-attention)
35. Framing Image Description as a Ranking Task - Data, Models and Evaluation Metrics (Extended Abstract)
36. [Caffe - Convolutional Architecture for Fast Feature Embedding](2014-caffe-convolutional-architecture-for-fast-feature-embedding)
37. [Natural Language Object Retrieval](2016-natural-language-object-retrieval)
38. Every Moment Counts - Dense Detailed Labeling of Actions in Complex Videos
39. YouTube2Text - Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition
40. Translating Video Content to Natural Language Descriptions
41. HMDB - A large video database for human motion recognition
42. [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](2014-learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation)
43. Corpus-Guided Sentence Generation of Natural Images
44. [Towards End-To-End Speech Recognition with Recurrent Neural Networks](2014-towards-end-to-end-speech-recognition-with-recurrent-neural-networks)
45. [On the Properties of Neural Machine Translation - Encoder-Decoder Approaches](2014-on-the-properties-of-neural-machine-translation-encoder-decoder-approaches)
46. [CIDEr - Consensus-based image description evaluation](2015-cider-consensus-based-image-description-evaluation)
47. Collective Generation of Natural Image Descriptions
48. A Learning Algorithm for Continually Running Fully Recurrent Neural Networks
49. [Generating Sequences With Recurrent Neural Networks](2013-generating-sequences-with-recurrent-neural-networks)
50. [ImageNet Large Scale Visual Recognition Challenge](2015-imagenet-large-scale-visual-recognition-challenge)
51. Coherent Multi-sentence Video Description with Variable Level of Detail
52. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context)
53. Dense Trajectories and Motion Boundary Descriptors for Action Recognition
54. Human Focused Video Description
55. Every Picture Tells a Story - Generating Sentences from Images
56. Towards textually describing complex video contents with audio-visual concept classifiers
57. TreeTalk - Composition and Compression of Trees for Image Descriptions
58. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database)
59. Baby talk - Understanding and generating simple image descriptions
60. Midge - Generating Image Descriptions From Computer Vision Detections
61. [From image descriptions to visual denotations - New similarity metrics for semantic inference over event descriptions](2014-from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions)
62. High Accuracy Optical Flow Estimation Based on a Theory for Warping
63. Video In Sentences Out
64. Exploring Nearest Neighbor Approaches for Image Captioning
65. [ROUGE - A Package for Automatic Evaluation of Summaries](2004-rouge-a-package-for-automatic-evaluation-of-summaries)
66. [Moses - Open Source Toolkit for Statistical Machine Translation](2007-moses-open-source-toolkit-for-statistical-machine-translation)
67. [Bleu - a Method for Automatic Evaluation of Machine Translation](2002-bleu-a-method-for-automatic-evaluation-of-machine-translation)
68. Learning Like a Child - Fast Novel Visual Concept Learning from Sentence Descriptions of Images
69. [Deep Visual-Semantic Alignments for Generating Image Descriptions](2017-deep-visual-semantic-alignments-for-generating-image-descriptions)
70. Action Recognition with Improved Trajectories
71. [METEOR - An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments](2005-meteor-an-automatic-metric-for-mt-evaluation-with-improved-correlation-with-human-judgments)
72. Framing image description as a ranking task
73. Learning internal representations by error propagation
74. [Recurrent Neural Network Regularization](2014-recurrent-neural-network-regularization)
75. IEEE Transactions on Pattern Analysis and Machine Intelligence
76. UCF101 - A Dataset of 101 Human Actions Classes From Videos in The Wild
