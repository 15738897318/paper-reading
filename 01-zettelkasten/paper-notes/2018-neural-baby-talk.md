---
title: Neural Baby Talk
authors:
- Jiasen Lu
- Jianwei Yang
- Dhruv Batra
- Devi Parikh
fieldsOfStudy:
- Computer Science
meta_key: 2018-neural-baby-talk
numCitedBy: 309
reading_status: TBD
ref_count: 52
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Neural-Baby-Talk-Lu-Yang/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e?sort=total-citations
venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition
year: 2018
---

[semanticscholar url](https://www.semanticscholar.org/paper/Neural-Baby-Talk-Lu-Yang/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e?sort=total-citations)

# Neural Baby Talk

## Abstract

We introduce a novel framework for image captioning that can produce natural language explicitly grounded in entities that object detectors find in the image. Our approach reconciles classical slot filling approaches (that are generally better grounded in images) with modern neural captioning approaches (that are generally more natural sounding and accurate). Our approach first generates a sentence 'template' with slot locations explicitly tied to specific image regions. These slots are then filled in by visual concepts identified in the regions by object detectors. The entire architecture (sentence template generation and slot filling with object detectors) is end-to-end differentiable. We verify the effectiveness of our proposed model on different image captioning tasks. On standard image captioning and novel object captioning, our model reaches state-of-the-art on both COCO and Flickr30k datasets. We also demonstrate that our model has unique advantages when the train and test distributions of scene compositions - and hence language priors of associated captions - are different. Code has been made available at: https://github.com/jiasenlu/NeuralBabyTalk.

## Paper References

1. Deep Compositional Captioning - Describing Novel Object Categories without Paired Training Data
2. Captioning Images with Diverse Objects
3. [Show and tell - A neural image caption generator](2015-show-and-tell-a-neural-image-caption-generator)
4. Guided Open Vocabulary Image Captioning with Constrained Beam Search
5. Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects
6. [DenseCap - Fully Convolutional Localization Networks for Dense Captioning](2016-densecap-fully-convolutional-localization-networks-for-dense-captioning)
7. [From captions to visual concepts and back](2015-from-captions-to-visual-concepts-and-back)
8. [Deep Visual-Semantic Alignments for Generating Image Descriptions](2017-deep-visual-semantic-alignments-for-generating-image-descriptions)
9. Mind's eye - A recurrent visual representation for image caption generation
10. [Knowing When to Look - Adaptive Attention via a Visual Sentinel for Image Captioning](2017-knowing-when-to-look-adaptive-attention-via-a-visual-sentinel-for-image-captioning)
11. [Image Captioning with Semantic Attention](2016-image-captioning-with-semantic-attention)
12. Self-Critical Sequence Training for Image Captioning
13. Flickr30k Entities - Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models
14. [Grounding of Textual Phrases in Images by Reconstruction](2016-grounding-of-textual-phrases-in-images-by-reconstruction)
15. [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](2015-show-attend-and-tell-neural-image-caption-generation-with-visual-attention)
16. [Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)](2015-deep-captioning-with-multimodal-recurrent-neural-networks-m-rnn)
17. [Natural Language Object Retrieval](2016-natural-language-object-retrieval)
18. Visual Dialog
19. BabyTalk - Understanding and Generating Simple Image Descriptions
20. [CIDEr - Consensus-based image description evaluation](2015-cider-consensus-based-image-description-evaluation)
21. [Modeling Context in Referring Expressions](2016-modeling-context-in-referring-expressions)
22. [SPICE - Semantic Propositional Image Caption Evaluation](2016-spice-semantic-propositional-image-caption-evaluation)
23. [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](2018-bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering)
24. Every Picture Tells a Story - Generating Sentences from Images
25. [VQA - Visual Question Answering](2015-vqa-visual-question-answering)
26. Comprehension-Guided Referring Expressions
27. [Microsoft COCO - Common Objects in Context](2014-microsoft-coco-common-objects-in-context)
28. [Long-term recurrent convolutional networks for visual recognition and description](2015-long-term-recurrent-convolutional-networks-for-visual-recognition-and-description)
29. Multimodal Neural Language Models
30. Collective Generation of Natural Image Descriptions
31. [Self-Critical Sequence Training for Image Captioning](2017-self-critical-sequence-training-for-image-captioning)
32. Baby talk - Understanding and generating simple image descriptions
33. Human Attention in Visual Question Answering - Do Humans and Deep Networks look at the same regions?
34. [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](2015-faster-r-cnn.md)
35. [Deep Residual Learning for Image Recognition](2015-resnet.md)
36. Encode, Review, and Decode - Reviewer Module for Caption Generation
37. [GloVe - Global Vectors for Word Representation](2014-glove-global-vectors-for-word-representation)
38. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2014-vggnet.md)
39. Pointer Networks
40. Midge - Generating Image Descriptions From Computer Vision Detections
41. [Adam - A Method for Stochastic Optimization](2015-adam-a-method-for-stochastic-optimization)
42. [Efficient Estimation of Word Representations in Vector Space](2013-efficient-estimation-of-word-representations-in-vector-space)
43. [Meteor Universal - Language Specific Translation Evaluation for Any Target Language](2014-meteor-universal-language-specific-translation-evaluation-for-any-target-language)
44. [A Fast and Accurate Dependency Parser using Neural Networks](2014-a-fast-and-accurate-dependency-parser-using-neural-networks)
45. [Long Short-Term Memory](1997-long-short-term-memory)
46. [The Stanford CoreNLP Natural Language Processing Toolkit](2014-the-stanford-corenlp-natural-language-processing-toolkit)
47. [Bleu - a Method for Automatic Evaluation of Machine Translation](2002-bleu-a-method-for-automatic-evaluation-of-machine-translation)
48. [Mask R-CNN](2017-mask-r-cnn.md)
49. [Modeling Relationships in Referential Expressions with Compositional Modular Networks](2017-modeling-relationships-in-referential-expressions-with-compositional-modular-networks)
50. [Generation and Comprehension of Unambiguous Object Descriptions](2016-generation-and-comprehension-of-unambiguous-object-descriptions)
51. ReferItGame - Referring to Objects in Photographs of Natural Scenes
