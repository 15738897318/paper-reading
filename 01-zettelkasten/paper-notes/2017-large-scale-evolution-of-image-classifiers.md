---
title: Large-Scale Evolution of Image Classifiers
authors:
- Esteban Real
- Sherry Moore
- Andrew Selle
- Saurabh Saxena
- Y. Suematsu
- Jie Tan
- Quoc V. Le
- A. Kurakin
fieldsOfStudy:
- Computer Science
meta_key: 2017-large-scale-evolution-of-image-classifiers
numCitedBy: 1118
reading_status: TBD
ref_count: 51
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Large-Scale-Evolution-of-Image-Classifiers-Real-Moore/f108b65fe0003e387e1cd7e50f537af0531818e4?sort=total-citations
venue: ICML
year: 2017
---

[semanticscholar url](https://www.semanticscholar.org/paper/Large-Scale-Evolution-of-Image-Classifiers-Real-Moore/f108b65fe0003e387e1cd7e50f537af0531818e4?sort=total-citations)

# Large-Scale Evolution of Image Classifiers

## Abstract

Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Our goal is to minimize human participation, so we employ evolutionary algorithms to discover such networks automatically. Despite significant computational requirements, we show that it is now possible to evolve models with accuracies within the range of those published in the last year. Specifically, we employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions and reaching accuracies of 94.6% (95.6% for ensemble) and 77.0%, respectively. To do this, we use novel and intuitive mutation operators that navigate large search spaces; we stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.

## Paper References

1. Generative NeuroEvolution for Deep Learning
2. [Neural Architecture Search with Reinforcement Learning](2017-neural-architecture-search-with-reinforcement-learning.md)
3. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2015-very-deep-convolutional-networks-for-large-scale-image-recognition.md)
4. Convolution by Evolution - Differentiable Pattern Producing Networks
5. [Deeply-Supervised Nets](2015-deeply-supervised-nets.md)
6. [Learning Multiple Layers of Features from Tiny Images](2009-learning-multiple-layers-of-features-from-tiny-images.md)
7. [Deep Residual Learning for Image Recognition](2016-deep-residual-learning-for-image-recognition.md)
8. [Striving for Simplicity - The All Convolutional Net](2015-striving-for-simplicity-the-all-convolutional-net.md)
9. Deep Clustered Convolutional Kernels
10. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks.md)
11. [Deep Networks with Stochastic Depth](2016-deep-networks-with-stochastic-depth.md)
12. [Convolutional Neural Fabrics](2016-convolutional-neural-fabrics.md)
13. [Delving Deep into Rectifiers - Surpassing Human-Level Performance on ImageNet Classification](2015-delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification.md)
14. Simple Evolutionary Optimization Can Rival Stochastic Gradient Descent in Neural Networks
15. [Wide Residual Networks](2016-wide-residual-networks.md)
16. [Learning both Weights and Connections for Efficient Neural Network](2015-learning-both-weights-and-connections-for-efficient-neural-network.md)
17. [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](2015-batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
18. PlaNet - Photo Geolocation with Convolutional Neural Networks
19. [Going deeper with convolutions](2015-going-deeper-with-convolutions.md)
20. [Densely Connected Convolutional Networks](2017-densely-connected-convolutional-networks.md)
21. [Practical Bayesian Optimization of Machine Learning Algorithms](2012-practical-bayesian-optimization-of-machine-learning-algorithms.md)
22. [Designing Neural Network Architectures using Reinforcement Learning](2017-designing-neural-network-architectures-using-reinforcement-learning.md)
23. [Network In Network](2014-network-in-network.md)
24. [An Empirical Exploration of Recurrent Network Architectures](2015-an-empirical-exploration-of-recurrent-network-architectures.md)
25. A Hypercube-Based Encoding for Evolving Large-Scale Neural Networks
26. [On the importance of initialization and momentum in deep learning](2013-on-the-importance-of-initialization-and-momentum-in-deep-learning.md)
27. [Maxout Networks](2013-maxout-networks.md)
28. Evolving Neural Networks through Augmenting Topologies
29. Designing Neural Networks using Genetic Algorithms
30. [TensorFlow - Large-Scale Machine Learning on Heterogeneous Distributed Systems](2016-tensorflow-large-scale-machine-learning-on-heterogeneous-distributed-systems.md)
31. [Training Very Deep Networks](2015-training-very-deep-networks.md)
32. Evolving multimodal controllers with HyperNEAT
33. [Mastering the game of Go with deep neural networks and tree search](2016-mastering-the-game-of-go-with-deep-neural-networks-and-tree-search.md)
34. [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](2016-google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
35. Learning representations by back-propagating errors
36. Compositional pattern producing networks - A novel abstraction of development
37. Evolving Memory Cell Structures for Sequence Learning
38. [Random Search for Hyper-Parameter Optimization](2012-random-search-for-hyper-parameter-optimization.md)
39. RAPID EVOLUTIONARY ESCAPE BY LARGE POPULATIONS FROM LOCAL FITNESS PEAKS IS LIKELY IN NATURE
40. Adapting Operator Settings in Genetic Algorithms
41. [The mnist database of handwritten digits](2005-the-mnist-database-of-handwritten-digits.md)
42. A Comparative Analysis of Selection Schemes Used in Genetic Algorithms
43. F1000Prime recommendation of False-positive psychology - undisclosed flexibility in data collection and analysis allows presenting anything as significant.
44. Genetic Synthesis of Modular Neural Networks
45. Genetic Algorithms with Sharing for Multimodalfunction Optimization
