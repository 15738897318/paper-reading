---
title: Ask Me Anything - Free-Form Visual Question Answering Based on Knowledge from External Sources
authors:
- Qi Wu
- Peng Wang
- Chunhua Shen
- A. Dick
- A. V. Hengel
fieldsOfStudy:
- Computer Science
meta_key: 2016-ask-me-anything-free-form-visual-question-answering-based-on-knowledge-from-external-sources
numCitedBy: 307
reading_status: TBD
ref_count: 41
tags:
- gen-from-ref
- other-default
- paper
venue: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2016
---

# Ask Me Anything - Free-Form Visual Question Answering Based on Knowledge from External Sources

## Abstract

We propose a method for visual question answering which combines an internal representation of the content of an image with information extracted from a general knowledge base to answer a broad range of image-based questions. This allows more complex questions to be answered using the predominant neural network-based approach than has previously been possible. It particularly allows questions to be asked about the contents of an image, even when the image itself does not contain the whole answer. The method constructs a textual representation of the semantic content of an image, and merges it with textual information sourced from a knowledge base, to develop a deeper understanding of the scene viewed. Priming a recurrent neural network with this combined information, and the submitted question, leads to a very flexible visual question answering approach. We are specifically able to answer questions posed in natural language, that refer to information not contained in the image. We demonstrate the effectiveness of our model on two publicly available datasets, Toronto COCO-QA [23] and VQA [1] and show that it produces the best reported results in both cases.

## Paper References

1. Ask Your Neurons - A Neural-Based Approach to Answering Questions about Images
2. Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question
3. [VQA - Visual Question Answering](2015-vqa-visual-question-answering)
4. VisKE - Visual knowledge extraction and question answering by visual verification of relation phrases
5. Building a Large-scale Multimodal Knowledge Base for Visual Question Answering
6. [What Value Do Explicit High Level Concepts Have in Vision to Language Problems?](2016-what-value-do-explicit-high-level-concepts-have-in-vision-to-language-problems)
7. Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries
8. Image Question Answering - A Visual Semantic Embedding Model and a New Dataset
9. [Show and tell - A neural image caption generator](2015-show-and-tell-a-neural-image-caption-generator)
10. A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input
11. Don't just listen, use your imagination - Leveraging visual common sense for non-visual tasks
12. Learning a Recurrent Visual Representation for Image Caption Generation
13. [Semantic Parsing on Freebase from Question-Answer Pairs](2013-semantic-parsing-on-freebase-from-question-answer-pairs)
14. [Learning to Answer Questions from Image Using Convolutional Neural Network](2016-learning-to-answer-questions-from-image-using-convolutional-neural-network)
15. Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
16. What value high level concepts in vision to language problems
17. Towards a Visual Turing Challenge
18. Visual Turing test for computer vision systems
19. [Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)](2015-deep-captioning-with-multimodal-recurrent-neural-networks-m-rnn)
20. [Sequence to Sequence Learning with Neural Networks](2014-sequence-to-sequence-learning-with-neural-networks)
21. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database)
22. Joint Video and Text Parsing for Understanding Events and Answering Queries
23. Describing Videos by Exploiting Temporal Structure
24. [Long-term recurrent convolutional networks for visual recognition and description](2015-long-term-recurrent-convolutional-networks-for-visual-recognition-and-description)
25. [Distributed Representations of Sentences and Documents](2014-distributed-representations-of-sentences-and-documents)
26. CNN - Single-label to Multi-label
27. [Very Deep Convolutional Networks for Large-Scale Image Recognition](2015-very-deep-convolutional-networks-for-large-scale-image-recognition)
28. [HCP - A Flexible CNN Framework for Multi-Label Image Classification](2016-hcp-a-flexible-cnn-framework-for-multi-label-image-classification)
29. [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](2014-learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation)
30. [Long Short-Term Memory](1997-long-short-term-memory)
31. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks)
32. Verb Semantics and Lexical Selection
33. Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation
34. [Freebase - a collaboratively created graph database for structuring human knowledge](2008-freebase-a-collaboratively-created-graph-database-for-structuring-human-knowledge)
35. [Microsoft COCO Captions - Data Collection and Evaluation Server](2015-microsoft-coco-captions-data-collection-and-evaluation-server)
36. Et al
37. DBpedia - A Nucleus for a Web of Open Data
38. (b)
39. Building Watson - An Overview of the DeepQA Project
