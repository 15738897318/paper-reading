---
title: Predicting Parameters in Deep Learning
authors:
- Misha Denil
- B. Shakibi
- Laurent Dinh
- Marc'Aurelio Ranzato
- N. D. Freitas
fieldsOfStudy:
- Computer Science
meta_key: 2013-predicting-parameters-in-deep-learning
numCitedBy: 1009
reading_status: TBD
ref_count: 40
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Predicting-Parameters-in-Deep-Learning-Denil-Shakibi/e8650503ab80ad7299f0845b1843abf3a97f313a?sort=total-citations
venue: NIPS
year: 2013
---

# Predicting Parameters in Deep Learning

## Abstract

We demonstrate that there is significant redundancy in the parameterization of several deep learning models. Given only a few weight values for each feature it is possible to accurately predict the remaining values. Moreover, we show that not only can the parameter values be predicted, but many of them need not be learned at all. We train several different architectures by learning only a small number of weights and predicting the rest. In the best case we are able to predict more than 95% of the weights of a network without any drop in accuracy.

## Paper References

1. [An Analysis of Single-Layer Networks in Unsupervised Feature Learning](2011-an-analysis-of-single-layer-networks-in-unsupervised-feature-learning.md)
2. Deep Learning of Representations - Looking Forward
3. Selecting Receptive Fields in Deep Networks
4. [Maxout Networks](2013-maxout-networks.md)
5. Scalable stacking and learning for building deep architectures
6. [Building high-level features using large scale unsupervised learning](2013-building-high-level-features-using-large-scale-unsupervised-learning.md)
7. ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning
8. [Large Scale Distributed Deep Networks](2012-large-scale-distributed-deep-networks.md)
9. [Acoustic Modeling Using Deep Belief Networks](2012-acoustic-modeling-using-deep-belief-networks.md)
10. [Improving neural networks by preventing co-adaptation of feature detectors](2012-improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors.md)
11. Learning representations by back-propagating errors
12. High-Performance Neural Networks for Visual Object Classification
13. On Autoencoders and Score Matching for Energy Based Models
14. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks.md)
15. Optimal Brain Damage
16. Emergence of Object-Selective Features in Unsupervised Feature Learning
17. Dimensionality Reduction and Prior Knowledge in E-Set Recognition
18. Tiled convolutional neural networks
19. Factored 3-Way Restricted Boltzmann Machines For Modeling Natural Images
20. Learning to Represent Spatial Transformations with Factored Higher-Order Boltzmann Machines
21. [A Fast Learning Algorithm for Deep Belief Nets](2006-a-fast-learning-algorithm-for-deep-belief-nets.md)
22. [Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition](2012-context-dependent-pre-trained-deep-neural-networks-for-large-vocabulary-speech-recognition.md)
23. Learning Separable Filters
24. [Multi-column deep neural networks for image classification](2012-multi-column-deep-neural-networks-for-image-classification.md)
25. Deep learning with COTS HPC systems
26. Emergence of Complex-Like Cells in a Temporal Product Network with Local Receptive Fields
27. A Neural Support Vector Network architecture with adaptive kernels
28. [Rectified Linear Units Improve Restricted Boltzmann Machines](2010-rectified-linear-units-improve-restricted-boltzmann-machines.md)
29. Deep, Big, Simple Neural Nets for Handwritten Digit Recognition
30. Double Sparsity - Learning Sparse Dictionaries for Sparse Signal Approximation
31. [Gradient-based learning applied to document recognition](1998-gradient-based-learning-applied-to-document-recognition.md)
32. [ImageNet - A large-scale hierarchical image database](2009-imagenet-a-large-scale-hierarchical-image-database.md)
33. On the limited memory BFGS method for large scale optimization
34. Speaker-independent phone recognition using hidden Markov models
35. [Neocognitron - A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position](2004-neocognitron-a-self-organizing-neural-network-model-for-a-mechanism-of-pattern-recognition-unaffected-by-shift-in-position.md)
36. [Kernel Methods for Pattern Analysis](2003-kernel-methods-for-pattern-analysis.md)
37. [The mnist database of handwritten digits](2005-the-mnist-database-of-handwritten-digits.md)
