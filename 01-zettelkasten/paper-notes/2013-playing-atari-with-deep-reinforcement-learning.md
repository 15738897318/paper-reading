---
title: Playing Atari with Deep Reinforcement Learning
authors:
- Volodymyr Mnih
- K. Kavukcuoglu
- David Silver
- A. Graves
- Ioannis Antonoglou
- Daan Wierstra
- Martin A. Riedmiller
fieldsOfStudy:
- Computer Science
meta_key: 2013-playing-atari-with-deep-reinforcement-learning
numCitedBy: 6930
reading_status: TBD
ref_count: 37
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Playing-Atari-with-Deep-Reinforcement-Learning-Mnih-Kavukcuoglu/2319a491378867c7049b3da055c5df60e1671158?sort=total-citations
venue: ArXiv
year: 2013
---

# Playing Atari with Deep Reinforcement Learning

## Abstract

We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.

## Paper References

1. Deep auto-encoder neural networks in reinforcement learning
2. Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method
3. Actor-Critic Reinforcement Learning with Energy-Based Policies
4. Reinforcement learning for robots using neural networks
5. Learning multiple layers of representation
6. Reinforcement Learning with Factored States and Actions
7. Bayesian Learning of Recursively Factored Environments
8. [Reinforcement Learning - An Introduction](2005-reinforcement-learning-an-introduction.md)
9. A Neuroevolution Approach to General Atari Game Playing
10. Why did TD-Gammon Work?
11. The Arcade Learning Environment - An Evaluation Platform for General Agents (Extended Abstract)
12. Toward Off-Policy Learning Control with Function Approximation
13. [ImageNet classification with deep convolutional neural networks](2012-imagenet-classification-with-deep-convolutional-neural-networks.md)
14. [Q-learning](2004-q-learning.md)
15. [Speech recognition with deep recurrent neural networks](2013-speech-recognition-with-deep-recurrent-neural-networks.md)
16. Prioritized Sweeping - Reinforcement Learning with Less Data and Less Time
17. New types of deep neural network learning for speech recognition and related applications - an overview
18. Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation
19. Residual Algorithms - Reinforcement Learning with Function Approximation
20. Prioritized Sweeping - Reinforcement Learning with Less Data and Less Real Time
21. Pedestrian Detection with Unsupervised Multi-stage Feature Learning
22. [Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition](2012-context-dependent-pre-trained-deep-neural-networks-for-large-vocabulary-speech-recognition.md)
23. Sketch-Based Linear Value Function Approximation
24. Analysis of Temporal-Diffference Learning with Function Approximation
25. Investigating Contingency Awareness Using Atari 2600 Games
26. Temporal Difference Learning and TD-Gammon
27. [Rectified Linear Units Improve Restricted Boltzmann Machines](2010-rectified-linear-units-improve-restricted-boltzmann-machines.md)
28. Machine learning for aerial image labeling
29. What is the best multi-stage architecture for object recognition?
30. and
31. Reinforcement Learning - - An Introduction
32. Convolutional networks for images, speech, and time series
